<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Advanced Econometrics with Examples - 3&nbsp; Hypothesis Testing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./exp_fam.html" rel="next">
<link href="./asymptotics.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./estimators.html">Statistical Theory</a></li><li class="breadcrumb-item"><a href="./testing.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Advanced Econometrics with Examples</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preliminaries</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Statistical Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimators.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Finite Sample Properties of Estimators</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./asymptotics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Asymptotic Properties of Estimators</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./testing.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./exp_fam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Exponential Families</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stochastic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Stochastic Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./adv_asymptotics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Advanced Asymptotics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Linear Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">The Classical Linear Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./endog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Endogeniety I: IV and 2SLS</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gls.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Generalized Least Squares</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./simul.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Endogeniety II: Simultaneity and Multiple Regressions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Estimation Frameworks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./extremum.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Extremum Estimators</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gmm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">The Generalized Method of Moments</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Maximum Likelihood Estimation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Basic Microeconometrics and Time Series</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./binary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Binary Choice</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./panel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Panel Data I: The Basics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./time_series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Basic Time Series</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nonpar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Nonparametrics I: Distribution and Density Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nonpar_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Nonparametrics II: Functional Forms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./semipar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Semiparametrics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sieve.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Sieve Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./partial_id.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Partial Identification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./endog_nonlinear.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Endogeniety III: Nonlinear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./weak_inst.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Endogeniety IV: Weak Instruments</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Microeconometrics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./discrete_choice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Discrete Choice</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tobit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Tobit</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Survival Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./count.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Count Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mixed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Mixed and Multilevel Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./GLM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./panel2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Panel Methods II</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Time Series</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./time_math.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Math Review</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Causal Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./causal1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Potential Outcomes Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./matching.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Matching Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rdd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Regression Discontinuity Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./did.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Difference in Differences</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LATE.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Non-Compliance and LATE</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hetero.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Heterogeneous Treatment Effects</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">More Statistical Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bayes1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Bayesian Estimation I: Theory</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bayes2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Bayesian Estimation II: Computation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bayes3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Bayesian Estimation III: Applications</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modelselection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Model Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./robust.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Robust Statistics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./learning_theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Statistical Learning Theory</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ML1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Supervised Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ML2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Dimmension Reduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ML3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Unsupervised Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ML4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Text Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ML5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">ML meets Causal Inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#decision-theory" id="toc-decision-theory" class="nav-link active" data-scroll-target="#decision-theory"><span class="header-section-number">3.1</span> Decision Theory</a></li>
  <li><a href="#size-and-power" id="toc-size-and-power" class="nav-link" data-scroll-target="#size-and-power"><span class="header-section-number">3.2</span> Size and Power</a></li>
  <li><a href="#neyman-pearson-lemma-and-ump-tests" id="toc-neyman-pearson-lemma-and-ump-tests" class="nav-link" data-scroll-target="#neyman-pearson-lemma-and-ump-tests"><span class="header-section-number">3.3</span> Neyman-Pearson Lemma and UMP Tests</a></li>
  <li><a href="#asymptotics" id="toc-asymptotics" class="nav-link" data-scroll-target="#asymptotics"><span class="header-section-number">3.4</span> Asymptotics</a></li>
  <li><a href="#confidence-intervals" id="toc-confidence-intervals" class="nav-link" data-scroll-target="#confidence-intervals"><span class="header-section-number">3.5</span> Confidence Intervals</a></li>
  <li><a href="#wald-test-and-t-test" id="toc-wald-test-and-t-test" class="nav-link" data-scroll-target="#wald-test-and-t-test"><span class="header-section-number">3.6</span> Wald Test and t-Test</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./estimators.html">Statistical Theory</a></li><li class="breadcrumb-item"><a href="./testing.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-testing" class="quarto-section-identifier"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Until now, we’ve focused on point estimation, but that’s only half the picture when it comes to statistics. The other half is inference. How do we test hypotheses about the true <span class="math inline">\(\boldsymbol{\theta}_0\)</span>, and make inferences about the underling data generating process <span class="math inline">\(P_{\boldsymbol{\theta}_0}\in \mathcal P\)</span>? An exhaustive treatment of inference is due to <span class="citation" data-cites="lehmann2005testing">Romano and Lehmann (<a href="#ref-lehmann2005testing" role="doc-biblioref">2005</a>)</span>, while <span class="citation" data-cites="bickel2015mathematical">Bickel and Doksum (<a href="#ref-bickel2015mathematical" role="doc-biblioref">2015</a>)</span> offer an equally technical, yet briefer, treatment.</p>
<section id="decision-theory" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="decision-theory"><span class="header-section-number">3.1</span> Decision Theory</h2>
<p>In <a href="#sec-est" class="quarto-xref"><span class="quarto-unresolved-ref">sec-est</span></a> we defined a (point) estimator as a function from a sample space <span class="math inline">\(\mathcal X\)</span> to the parameter space <span class="math inline">\(\Theta\)</span>. For some specified model <span class="math inline">\(\mathcal P\)</span>, we observe a realization of the random vector <span class="math inline">\(\mathbf{X}\sim P_{\boldsymbol{\theta}_0}\)</span> for <span class="math inline">\(P_{\boldsymbol{\theta}_0}\in \mathcal P\)</span>, and then calculate an estimate <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>. This process is a special case of a more general framework that unifies point estimation and hypothesis testing.</p>
<p>Consider an <strong><em>action space</em></strong> <span class="math inline">\(\mathcal A\)</span>. A <strong><em>decision process/rule</em></strong> <span class="math inline">\(\delta:\mathcal X\to \mathcal A\)</span> prescribes an action given an observation of a random vector <span class="math inline">\(\mathbf{X}\)</span> defined on <span class="math inline">\(\mathcal X\)</span>. The set of all decision rules is <span class="math inline">\(\mathcal D\)</span>. If the true data generating process is <span class="math inline">\(P_\boldsymbol{\theta}\in\mathcal P\)</span>, the cost of taking the action <span class="math inline">\(a\)</span> is given by the <strong><em>loss function</em></strong> <span class="math inline">\(l(P_\boldsymbol{\theta}, a)\)</span> where <span class="math inline">\(l:\mathcal P\times \mathcal A\to\mathbb R^+\)</span>. The loss associated with a decision rule is <span class="math inline">\(l(P_\boldsymbol{\theta}, \delta(\mathbf{X}))\)</span>. We cannot calculate this loss, as we do not know <span class="math inline">\(P_\boldsymbol{\theta}\)</span>. Instead we average the loss over <span class="math inline">\(\Theta\)</span> (which is the same as over all <span class="math inline">\(P_\theta\)</span> if <span class="math inline">\(\mathcal P\)</span> is identified), giving a <strong><em>risk function</em></strong> <span class="math inline">\(R:\mathcal P\to \mathbb R^+\)</span> defined as <span class="math inline">\(\text{E}\left[l(P_\boldsymbol{\theta}, \delta(\mathbf{X}))\right]\)</span>.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.1 (Point Estimation)</strong></span> In the case of Section <a href="#sec-est" class="quarto-xref"><span class="quarto-unresolved-ref">sec-est</span></a>, we took <span class="math inline">\(\mathcal A = \Theta\)</span>. Our space of actions where simply parameter values. We also defined a quadratic loss function which resulted in the risk function taking the form of the MSE of an estimator.</p>
</div>
<p>We can also define hypothesis testing using decision theory.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.1</strong></span> Let <span class="math inline">\(\mathcal X\)</span> and <span class="math inline">\(\mathcal P\)</span> be the sample space and model, respectively, and partition <span class="math inline">\(\mathcal P\)</span> into <span class="math inline">\(\mathcal P_0\)</span> and <span class="math inline">\(\mathcal P_1\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> A <span style="color:red"><strong><em>test function</em></strong></span> is a decision rule defined on <span class="math inline">\(\mathcal A =\{\mathcal P_0,\mathcal P_1\}\)</span> given as <span class="math display">\[\delta(\mathbf{X}) = \begin{cases}\mathcal P_1 &amp; T(\mathbf{X}) \in C \\ \mathcal P_0 &amp; T(\mathbf{X})\notin C\end{cases}\]</span> for some <span style="color:red"><strong><em>critical region</em></strong></span> <span class="math inline">\(C\subseteq \mathcal X\)</span> and <span style="color:red"><strong><em>test statistic</em></strong></span> <span class="math inline">\(T:\mathcal X\to\mathcal X\)</span>.</p>
</div>
<p>Of the set of models <span class="math inline">\(\mathcal P_0\)</span> and <span class="math inline">\(\mathcal P_1\)</span>, one is often easier to specify. For example, suppose <span class="math inline">\(\mathbf{X}= (X_1,\ldots,X_n)\)</span> captures the effectiveness of a drug on a series of patients <span class="math inline">\(i=1,\ldots,n\)</span>, and <span class="math inline">\(\mathbf{X}\sim P_\boldsymbol{\theta}\in \mathcal P\)</span>. If we want to test whether this drug has an effect on patients’ health, then we want to partition <span class="math inline">\(\mathcal P\)</span> into two groups: one group corresponding to the drug having no effect, and one where the drug has an effect. It’s <em>much</em> easier to specify the models which correspond to no effect than the models that correspond to the drug having an effect, as there are nearly infinite possibilities when it comes to the type and degree of effectiveness. The easier of the two groups to specify is traditionally denoted <span class="math inline">\(\mathcal P_0\)</span>, and is often associated with some well formed <strong><em>(null) hypothesis</em></strong>. This hypothesis is often written as <span class="math inline">\(H_0:P_\theta\in \mathcal P_0\)</span>. Our decision <span class="math inline">\(\delta(\mathbf{X})\)</span> prescribed whether we <strong><em>fail to reject/reject</em></strong> <span class="math inline">\(H_0:P_\boldsymbol{\theta}\in\mathcal P_0\)</span>. If we reject of the hypothesis <span class="math inline">\(H_0:P_\boldsymbol{\theta}\in\mathcal P_0\)</span>, we conclude that <span class="math inline">\(P_\boldsymbol{\theta}\)</span> belongs to the <strong><em>class of alternative</em></strong> <span class="math inline">\(H_1:P_\boldsymbol{\theta}\in \mathcal P_1\)</span>. We often think of <span class="math inline">\(H_0:P_\boldsymbol{\theta}\in\mathcal P_0\)</span> as a statement we assume to be true, with the burden of proof being on <span class="math inline">\(H_1:P_\boldsymbol{\theta}\in \mathcal P_1\)</span>.</p>
<div class="hypothesis" name="Different Conventions">
<p>There exist two other popular ways of writing the decision problem associated with testing a hypothesis:</p>
<ol type="1">
<li><p>Assuming <span class="math inline">\(\mathcal P\)</span> is identified and each <span class="math inline">\(P_\boldsymbol{\theta}\)</span> is uniquely determined by a <span class="math inline">\(\boldsymbol{\theta}\in \Theta\)</span>, then we can partition <span class="math inline">\(\Theta\)</span> into <span class="math inline">\(\Theta_1\)</span> and <span class="math inline">\(\Theta_0\)</span>, and define <span class="math inline">\(\delta(\mathbf{X}) = \begin{cases}\Theta_1 &amp; T(\mathbf{X}) \in C \\ \Theta_0 &amp; T(\mathbf{X})\notin C\end{cases},\)</span> where <span class="math inline">\(\mathcal A = \{\Theta_0, \Theta_1\}\)</span> The hypothesis and class of alternatives are now written as <span class="math inline">\(H_0: \boldsymbol{\theta}\in\Theta_0\)</span> and <span class="math inline">\(H_1: \boldsymbol{\theta}\in\Theta_1\)</span>, respectively.</p></li>
<li><p>We could define <span class="math inline">\(\mathcal A = \{0,1\}\)</span>, where <span class="math inline">\(1\)</span> corresponds to rejecting <span class="math inline">\(H_0:P_\boldsymbol{\theta}\in\mathcal P_0\)</span> and <span class="math inline">\(0\)</span> failing to reject <span class="math inline">\(H_0:P_\boldsymbol{\theta}\in\mathcal P_0\)</span>.</p></li>
</ol>
<p>Virtually all concrete examples of hypothesis test use notation similar to 1.</p>
</div>
<div id="exm-normtest" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.2 (One-Sided Z-Test)</strong></span> Suppose <span class="math inline">\(\mathcal P\)</span> is the collection of normal distributions with known variance <span class="math inline">\(\sigma^2\)</span>. This model is parameterized by mean <span class="math inline">\(\mu\)</span>. We want to test the following hypothesis: <span class="math display">\[\begin{align*}
H_0:&amp;\mu \le \mu_0\\
H_1:&amp;\mu &gt; \mu_0
\end{align*}\]</span> In this case, the null hypothesis is often abbreviated as <span class="math inline">\(H_0: \mu = \mu_0\)</span>. Our hypothesis has partitions our parameter space <span class="math inline">\(\Theta = \mathbb R\)</span> into <span class="math inline">\(\Theta_0 = (-\infty,\mu_0]\)</span> and <span class="math inline">\(\Theta_1 = (\mu_0,\infty)\)</span>. Define a statistic <span class="math display">\[T(\mathbf{X}) = \frac{\bar X - \mu_0}{\sigma/\sqrt n} = \frac{\frac{1}{n}\sum_{i=1}^nX_i - \mu_0}{\sigma/\sqrt n},\]</span> and a critical region <span class="math inline">\(C = [1.645,\infty)\)</span>. Our decision rule <span class="math inline">\(\delta\)</span> takes the form <span class="math display">\[\delta(\mathbf{X}) = \begin{cases} (-\infty,\mu_0] &amp; T(\mathbf{X}) &lt; 1.645 \\ (\mu_0,\infty) &amp; T(\mathbf{X}) \ge 1.645 \end{cases},\]</span> which is written succinctly as <span class="math inline">\(\delta(\mathbf{X}) = I[T(\mathbf{X}) \ge 1.645 ]\)</span> if we take <span class="math inline">\(\mathcal A = \{0,1\}\)</span></p>
</div>
<p>The binary nature of hypothesis testing makes defining a loss function quite simple. Our decision is either correct or incorrect. We can take the loss function to be 0 if we are correct, and 1 if we are incorrect. <span class="math display">\[l(P_\theta, \delta(\mathbf{X}))=\begin{cases}1 &amp; \delta(\mathbf{X}) = \mathcal P_0 \text{ and }P_\boldsymbol{\theta}\in\mathcal P_0 \\
0 &amp; \delta(\mathbf{X}) = \mathcal P_1 \text{ and }P_\boldsymbol{\theta}\in\mathcal P_0\\
1 &amp; \delta(\mathbf{X}) = \mathcal P_1 \text{ and }P_\boldsymbol{\theta}\in\mathcal P_1\\
0 &amp; \delta(\mathbf{X}) = \mathcal P_0 \text{ and }P_\boldsymbol{\theta}\in\mathcal P_1\end{cases}\]</span> The associated risk function becomes <span class="math display">\[\begin{align*}
R(P_\boldsymbol{\theta}, \delta(\mathbf{X})) &amp; = \text{E}\left[l(P_\theta, \delta(\mathbf{X}))\right] = l(P_\theta, \mathcal P_0)\cdot \Pr(\delta(\mathbf{X}) = \mathcal P_0) +l(P_\theta, \mathcal P_1)\cdot \Pr(\delta(\mathbf{X}) = \mathcal P_1).
\end{align*}\]</span> We can simplify <span class="math inline">\(R(P_\boldsymbol{\theta}, \delta(\mathbf{X}))\)</span> if we condition one either <span class="math inline">\(P_\theta \in \mathcal P_0\)</span>, or <span class="math inline">\(P_\theta \in \mathcal P_1\)</span>.</p>
<p><span class="math display">\[\begin{align*}
R(P_\boldsymbol{\theta}, \delta(\mathbf{X}) \mid P_\boldsymbol{\theta}\in\mathcal P_0)&amp; =  \underbrace{l(P_\theta, \mathcal P_0)}_0\cdot \Pr(\delta(\mathbf{X}) = \mathcal P_0 \mid P_\boldsymbol{\theta}\in\mathcal P_0) +\underbrace{l(P_\theta, \mathcal P_1)}_1\cdot \Pr(\delta(\mathbf{X}) = \mathcal P_1 \mid P_\boldsymbol{\theta}\in\mathcal P_0) =\Pr(\delta(\mathbf{X}) = \mathcal P_1 \mid P_\boldsymbol{\theta}\in\mathcal P_0)\\
R(P_\boldsymbol{\theta}, \delta(\mathbf{X}) \mid P_\boldsymbol{\theta}\in\mathcal P_1)&amp; =  \underbrace{l(P_\theta, \mathcal P_0)}_1\cdot \Pr(\delta(\mathbf{X}) = \mathcal P_0 \mid P_\boldsymbol{\theta}\in\mathcal P_1) +\underbrace{l(P_\theta, \mathcal P_1)}_0\cdot \Pr(\delta(\mathbf{X}) = \mathcal P_1 \mid P_\boldsymbol{\theta}\in\mathcal P_1) =\Pr(\delta(\mathbf{X}) = \mathcal P_0 \mid P_\boldsymbol{\theta}\in\mathcal P_1)
\end{align*}\]</span></p>
<p>In both cases, the risk function is the probability of making an erroneous decision. These two types of errors are likely familiar.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.2</strong></span> Suppose we have a null hypothesis <span class="math inline">\(H_0:P_\boldsymbol{\theta}\in\mathcal P_0\)</span>. If <span class="math inline">\(P_\boldsymbol{\theta}\in \mathcal P_0\)</span>, but <span class="math inline">\(\delta(\mathbf{X}) = \mathcal P_1\)</span> (the null hypothesis is true but we reject it), then we have committed a <span style="color:red"><strong><em>type I error</em></strong></span>. On the other hand, if <span class="math inline">\(P_\boldsymbol{\theta}\in \mathcal P_1\)</span>, but <span class="math inline">\(\delta(\mathbf{X}) = \mathcal P_0\)</span> (the null hypothesis is false but we fail to reject it), then we have committed a <span style="color:red"><strong><em>type II error</em></strong></span>.</p>
</div>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(H_0\)</span> True</th>
<th><span class="math inline">\(H_0\)</span> False</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Reject <span class="math inline">\(H_0\)</span></td>
<td>type I error</td>
<td>correct decision</td>
</tr>
<tr class="even">
<td>Fail to Reject <span class="math inline">\(H_0\)</span></td>
<td>correct decision</td>
<td>type II error</td>
</tr>
</tbody>
</table>
<p>Considering we have two types of errors, which is more important? How do we construct optimal test? <span class="citation" data-cites="neyman1933">Neyman and Pearson (<a href="#ref-neyman1933" role="doc-biblioref">1933</a>)</span> provide a solution to these problems.</p>
</section>
<section id="size-and-power" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="size-and-power"><span class="header-section-number">3.2</span> Size and Power</h2>
<p>In order to assess tests, we will need to define probabilities related to type I and type II error.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.3</strong></span> The <span style="color:red"><strong><em>level</em></strong></span> <span class="math inline">\(\alpha \in [0,1]\)</span> is a specified number such that <span class="math inline">\(\Pr(\text{type I error})&gt;\alpha\)</span> is unacceptable. In other words, <span class="math display">\[\Pr(\delta(\mathbf{X}) = \mathcal P_1 \mid P_\boldsymbol{\theta}\in P_0) = \Pr(T(\mathbf{X})\in C \mid P_\boldsymbol{\theta}\in P_0) \le \alpha \ \ \forall P_\boldsymbol{\theta}\in \mathcal P_0.\]</span></p>
</div>
<p>Note that <span class="math inline">\(\alpha\)</span> must hold for all <span class="math inline">\(P_\boldsymbol{\theta}\in \mathcal P_0\)</span>. A test may have a level of 0.01 for one <span class="math inline">\(P_{\boldsymbol{\theta}} \in \mathcal P_0\)</span>, but could have a level of 0.10 for <span class="math inline">\(P_{\boldsymbol{\theta}'} \in \mathcal P_0\)</span>. How then do we assess the “aggregate” level of a test across all <span class="math inline">\(\mathcal P_0\)</span>? We will do so by considering the worst case scenario, and associating a test with the largest level <span class="math inline">\(\alpha\)</span> possible, where the maximum is taken over all <span class="math inline">\(P_\boldsymbol{\theta}\in \mathcal P_0\)</span>. This will be known as the size of the test.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.4</strong></span> The <span style="color:red"><strong><em>size of a test</em></strong></span> defined with a statistic <span class="math inline">\(T(\mathbf{X})\)</span> and critical value <span class="math inline">\(c\)</span> is <span class="math display">\[\alpha(\delta) = \sup_{P_\boldsymbol{\theta}\in \mathcal P_0} \Pr(T(\mathbf{X})\in C \mid P_\boldsymbol{\theta}\in \mathcal P_0).\]</span></p>
</div>
<p>The size is nothing more than the maximum probability of committing a type I error permitted by a test <span class="math inline">\(\delta\)</span>. If we want to avoid type I errors, we want <span class="math inline">\(\alpha\)</span> to be very small. We also need to consider type II errors. Note that the probability of a type II error is</p>
<p><span class="math display">\[\Pr(\text{type II error}) = \Pr(T(\mathbf{X})\in C \mid P_\boldsymbol{\theta}\in\mathcal P_0) = 1 - \Pr(T(\mathbf{X})\in C \mid P_\boldsymbol{\theta}\in\mathcal P_1).\]</span> A small chance of committing a type II error is the same as the probability of our test correctly identifying <span class="math inline">\(P_\boldsymbol{\theta}\in \mathcal P_1\)</span> being high. This ability is the power of our test.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.5</strong></span> The <span style="color:red"><strong><em>power of a test</em></strong></span> defined with a statistic <span class="math inline">\(T(\mathbf{X})\)</span> and critical region <span class="math inline">\(C\)</span> is <span class="math display">\[\beta(\delta, P_\theta) = \Pr(T(\mathbf{X}) \in C \mid P_\boldsymbol{\theta}).\]</span></p>
</div>
<p>The power function is simply the probability of rejecting the null hypothesis for any <span class="math inline">\(P_\boldsymbol{\theta}\in \mathcal P\)</span>. It can be thought of as a test power detect that <span class="math inline">\(H_1\)</span> is true (<span class="math inline">\(H_0\)</span> is false). Note that <span class="math inline">\(\beta(\delta, P_\theta)\)</span> is redundant on the subset <span class="math inline">\(\mathcal P_0 \subset \mathcal P\)</span>. For any <span class="math inline">\(P_\theta\in \mathcal P_0\)</span>, <span class="math display">\[ \beta(\delta, P_\theta\mid P_\theta\in \mathcal P_0) = \Pr(T(\mathbf{X}) \in C \mid   P_\boldsymbol{\theta}\in \mathcal P_0) \le \sup_{P_\boldsymbol{\theta}\in P_0} \Pr(T(\mathbf{X})\in C \mid P_\boldsymbol{\theta}\in\mathcal P_0) = \alpha(\delta).\]</span> By construction <span class="math inline">\(\beta(\delta, P_\theta) \le \alpha(\delta)\)</span> on <span class="math inline">\(\mathcal P_0\)</span>, the power on <span class="math inline">\(\mathcal P_0\)</span> doesn’t provide any new information. On the other hand it gives us another way of writing the size of a test: <span class="math display">\[ \alpha(\delta) = \sup_{P_\theta \in\mathcal P_0} \beta(P_\boldsymbol{\theta}, \delta).\]</span>We’re interested in the power of our test when <span class="math inline">\(\mathcal P\in P_1\)</span>, which corresponds to the probability of correctly detecting <span class="math inline">\(\mathcal P\in P_1\)</span>.<br>
<span class="math display">\[\beta(\delta, P_\theta\mid P_\theta\in \mathcal P_1) = \Pr(T(\mathbf{X}) \in C \mid   P_\boldsymbol{\theta}\in \mathcal P_1) = 1 - \Pr(\text{type II error})\]</span> For this reason, you will very often see <span class="math inline">\(\beta\)</span> only defined on <span class="math inline">\(\mathcal P_1\)</span>.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.3 (Z-Test)</strong></span> Reconsider <a href="#exm-normtest" class="quarto-xref">Example&nbsp;<span class="quarto-unresolved-ref">exm-normtest</span></a>. We have <span class="math display">\[\begin{align*}
H_0:&amp;\mu \le \mu_0\\
H_1:&amp;\mu &gt; \mu_0\\
T(\mathbf{X}) &amp;= \frac{\bar X - \mu_0}{\sigma/\sqrt n }\\
\delta(\mathbf{X}) &amp;= \begin{cases} (-\infty,\mu_0] &amp; T(\mathbf{X}) &lt; 1.645 \\ (\mu_0,\infty) &amp; T(\mathbf{X}) \ge 1.645 \end{cases}
\end{align*}\]</span></p>
<p>Note that an equivalent test for our null hypothesis is <span class="math display">\[\delta(\mathbf{X}) = \begin{cases} (-\infty,\mu_0] &amp; \bar X &lt; \mu_0 +1.645\left(\frac{\sigma}{\sqrt n}\right) \\ (\mu_0,\infty) &amp; \bar X  \ge \mu_0 +1.645\left(\frac{\sigma}{\sqrt n}\right) \end{cases}\]</span> We can calculate the size of our test using the fact that <span class="math inline">\(T(\mathbf{X}) \sim N(0,1)\)</span>. Any such <span class="math inline">\(\mu\)</span> can be written as <span class="math inline">\(\mu_0 + t(\sigma/\sqrt n)\)</span> for <span class="math inline">\(t \le 0\)</span>. The level of a test for some <span class="math inline">\(\mu \in (-\infty,\mu_0]\)</span> is <span class="math display">\[\begin{align*}
\Pr(\bar X \ge \mu_0 +1.645(\sigma/\sqrt n)) &amp;= \Pr(\bar X \ge [\mu - t(\sigma/\sqrt n)] +1.645(\sigma/\sqrt n)) &amp; (\mu_0 =\mu - t(\sigma/\sqrt n))\\
&amp;= \Pr(\bar X \ge \mu+ (1.645-t)(\sigma/\sqrt n))\\
&amp; = \Pr \left(\frac{\bar X - \mu}{(\sigma/\sqrt n)} \ge 1.645 - t\right)\\
&amp; = \Phi(-1.645 + t)
\end{align*}\]</span> Before we take the supremum over all such probabilities, note that <span class="math inline">\(\mu \le \mu_0\)</span> is equivalent to <span class="math inline">\(t\le 0\)</span> where <span class="math inline">\(\mu = \mu_0 + t(\sigma/\sqrt n)\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Therefore the size of our test is <span class="math display">\[\begin{align*}
\alpha &amp;= \sup_{\mu \le \mu_0} \Pr(T(\mathbf{X})\in C \mid \mu &lt; \mu_0)\\
&amp; = \sup_{t \le 0} \Phi(-1.645 + t)
\end{align*}\]</span></p>
<p>Plotting this probability makes it clear that <span class="math inline">\(\alpha(\delta) \approx 0.05\)</span>, and the supremum is achieved when <span class="math inline">\(\mu = \mu_0\)</span> (<span class="math inline">\(t=0\)</span>).</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">t =</span> <span class="sc">-</span><span class="dv">300</span><span class="sc">:</span><span class="dv">0</span><span class="sc">/</span><span class="dv">100</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">+</span> t)) <span class="sc">%&gt;%</span> </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t,y)) <span class="sc">+</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"t =  (μ - μ0)/(σ√n)"</span>, <span class="at">y =</span> <span class="st">"Pr(Reject H0 | H0 True)"</span>) <span class="sc">+</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.05</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot31" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot31-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot31-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot31-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.1: The size of the test is given by the red dashed line corresponding to the supremum of the probability of rejecting a true null hypothesis.”
</figcaption>
</figure>
</div>
</div>
</div>
<p>Now we can consider the power <span class="math inline">\(\beta(\mu)\)</span>. We’ve in fact already done nearly all the calculations required for this. Consider <span class="math inline">\(\mu = \mu_0 + t(\sigma/\sqrt n)\)</span> for <span class="math inline">\(t\in \mathbb{R}\)</span>. If <span class="math inline">\(t \le 0\)</span>, then <span class="math inline">\(\mu \le \mu_0\)</span>, and the null hypothesis is true. If <span class="math inline">\(t &gt; 0\)</span>, then <span class="math inline">\(\mu &gt;\mu_0\)</span> and the null hypothesis is false. The power <span class="math inline">\(\beta(\mu)\)</span> is <span class="math inline">\(\Phi(-1.645 + t)\)</span>, but on the domain <span class="math inline">\(t\in \mathbb{R}\)</span>.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">t =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">4</span>, <span class="at">length =</span> <span class="dv">1000</span>), </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">group =</span> <span class="st">"Power Curve"</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">+</span> t)) <span class="sc">%&gt;%</span> </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(<span class="fu">data.frame</span>(<span class="at">t =</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">0</span>), <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">group =</span> <span class="st">"H0 True, μ &lt; μ0"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(<span class="fu">data.frame</span>(<span class="at">t =</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">4</span>), <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">group =</span> <span class="st">"H1 True, μ &gt; μ0"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t,y, <span class="at">color =</span> group)) <span class="sc">+</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="st">"t =  (μ - μ0)/(σ√n)"</span>, <span class="at">y =</span> <span class="st">"Pr(Reject H0)"</span> , <span class="at">color=</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"green"</span>, <span class="st">"black"</span>)) <span class="sc">+</span> </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-power" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-power-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.2: Power curve of test.
</figcaption>
</figure>
</div>
</div>
</div>
<p>To make this more concrete, we can perform a Monte Carlo simulation for fixed values of <span class="math inline">\(\mu_0\)</span>, <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma^2\)</span>, and <span class="math inline">\(n\)</span>. For all simulations, let’s fix <span class="math inline">\(\mu_0 = 2\)</span>, <span class="math inline">\(n = 100\)</span> and <span class="math inline">\(\sigma^2 =1\)</span>. First, assume <span class="math inline">\(\mu = \mu_0 = 2\)</span>, and record <span class="math inline">\(\delta(\mathbf{X})\)</span> for 100,000 simulations. In this case we should expect to make the correct decision (fail to reject the null hypothesis) about 95% of the time, as the size of our test is <span class="math inline">\(\alpha = 0.05\)</span> which corresponds to the maximum level which occurs at <span class="math inline">\(\mu = \mu_0\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># draw on realization of a test stat and report decision</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>draw_test <span class="ot">&lt;-</span> <span class="cf">function</span>(delta, test_stat, critical_region, mu_0, sigma, n, dist, dist_params, s){</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">delta</span>(test_stat, critical_region, X, mu_0, sigma) <span class="sc">%&gt;%</span> </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">iter =</span> s)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># draw N realizations of a test stat</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>draw_N_tests <span class="ot">&lt;-</span> <span class="cf">function</span>(N, delta, test_stat, critical_region, mu_0, sigma, n, dist, dist_params){</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map_df</span>(\(s) <span class="fu">draw_test</span>(delta, test_stat, critical_region, mu_0, sigma, n, dist, dist_params, s))</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># define test stat for this particular example</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>test_stat <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu_0, sigma){</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> (<span class="fu">mean</span>(X)<span class="sc">-</span>mu_0)<span class="sc">/</span>(sigma<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Define decision function, supply critical region as a list of bounds, ex: list(c(-Inf, -3), c(0, 1), c(3, Inf))</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>delta <span class="ot">&lt;-</span> <span class="cf">function</span>(test_stat, critical_region, X, mu_0, sigma){</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>  stat <span class="ot">&lt;-</span> <span class="fu">test_stat</span>(X, mu_0, sigma)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># determine if the test stat falls within any of the interval comprising the critical region</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>  decision <span class="ot">&lt;-</span> critical_region <span class="sc">%&gt;%</span> </span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map_lgl</span>(\(bounds) <span class="fu">between</span>(stat, bounds[<span class="dv">1</span>], bounds[<span class="dv">2</span>])) <span class="sc">%&gt;%</span> </span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.logical</span>()</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">stat =</span> stat,</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> decision,</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">H_0 =</span> mu_0</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">draw_N_tests</span>(</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e5</span>,</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> delta, </span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_stat =</span> test_stat, </span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>  <span class="at">critical_region =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="fl">1.645</span>, <span class="cn">Inf</span>)), </span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_0 =</span> <span class="dv">2</span>, </span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="dv">1</span>, </span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span>, </span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist =</span> rnorm, </span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist_params =</span> <span class="fu">list</span>(</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>    <span class="at">mean =</span> <span class="dv">2</span>, </span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd=</span> <span class="dv">1</span></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(decision) <span class="sc">%&gt;%</span> </span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 2
# Groups:   decision [2]
  decision     n
  &lt;lgl&gt;    &lt;int&gt;
1 FALSE    94986
2 TRUE      5014</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(results<span class="sc">$</span>decision)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.05014</code></pre>
</div>
</div>
<p>This simulation calculated the power of our test given <span class="math inline">\(\mu\)</span>. Let’s define the power function using this simulation, and calculate the power for <span class="math inline">\(\mu\in[1.8,2.4]\)</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Approximate the power of a test for a given μ using N simulations, assume normal distribution</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>power <span class="ot">&lt;-</span> <span class="cf">function</span>(mu, N, delta, test_stat, critical_region, mu_0, sigma, n){</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">draw_N_tests</span>(N, delta, test_stat, critical_region, mu_0, sigma, n, rnorm, <span class="fu">list</span>(mu, sigma)) <span class="sc">%&gt;%</span> </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">simulated_power =</span> <span class="fu">mean</span>(decision),</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">t =</span> mu</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>power_curve <span class="ot">&lt;-</span> <span class="cf">function</span>(domain, N, delta, test_stat, critical_region, mu_0, sigma, n){</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> domain <span class="sc">%&gt;%</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">map_df</span>(\(mu) <span class="fu">power</span>(mu, N, delta, test_stat, critical_region, mu_0, sigma, n))</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">power_curve</span>(</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">domain =</span> <span class="fu">seq</span>(<span class="fl">1.8</span>, <span class="fl">2.4</span>, <span class="at">length =</span> <span class="dv">25</span>), </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e4</span>,</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> delta, </span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_stat =</span> test_stat, </span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">critical_region =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="fl">1.645</span>, <span class="cn">Inf</span>)), </span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_0 =</span> <span class="dv">2</span>, </span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="dv">1</span>, </span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can plot this simulated power curve over the theoretical curve we calculated for a general <span class="math inline">\(\mu_0\)</span> (see <a href="#fig-power" class="quarto-xref">Figure&nbsp;<span class="quarto-unresolved-ref">fig-power</span></a>).<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> results <span class="sc">%&gt;%</span> </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> simulated_power,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">group =</span> <span class="st">"Simulated Power"</span>,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">t =</span> <span class="fu">seq</span>(<span class="fl">1.8</span>, <span class="fl">2.4</span>, <span class="at">length =</span> <span class="dv">1000</span>),</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">group =</span> <span class="st">"Power Curve"</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">+</span> (t<span class="dv">-2</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">10</span>) )) <span class="sc">%&gt;%</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(<span class="fu">data.frame</span>(<span class="at">t =</span><span class="fu">c</span>(<span class="fl">1.8</span>,<span class="dv">2</span>), <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">group =</span> <span class="st">"H0 True, μ &lt; μ0"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(<span class="fu">data.frame</span>(<span class="at">t =</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="fl">2.4</span>), <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">group =</span> <span class="st">"H1 True, μ &gt; μ0"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t, y, <span class="at">color =</span> group)) <span class="sc">+</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> df, <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="st">"True μ"</span>, <span class="st">"Pr(Reject H0)"</span>, <span class="at">color =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"green"</span>, <span class="st">"black"</span>, <span class="st">"blue"</span>)) <span class="sc">+</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot33" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot33-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot33-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot33-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.3: Simulated power function on the interval [1.8, 2.4] using 10,000 simulations for each point.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Our simulated probabilities are virtually identical to the theoretical probabilities calculated!</p>
</div>
<p>This example is special for a few reason. Note that we have: <span class="math display">\[\begin{align*}
\alpha &amp; = \sup_{\mu \le \mu_0}\beta(\mu) = \beta(\mu_0).
\end{align*}\]</span> This equality holds because <span class="math inline">\(\beta\)</span> is monotonically increasing: <span class="math display">\[\begin{align*}
\frac{\partial}{\partial \mu} \beta(\mu) &amp;= \frac{\partial }{\partial \mu}\Phi(-1.645 + t)  \\
&amp; = \frac{\partial t}{\partial \mu}\varphi(-1.645 - t) &amp; (\varphi \text{ standard normal pdf})\\
&amp; = \frac{\partial}{\partial \mu}\left(\frac{\mu - \mu_0}{\sigma/\sqrt n}\right)\varphi\left(-1.645 + \frac{\mu - \mu_0}{\sigma/\sqrt n}\right) &amp;(t = (\mu - \mu_0)/(\sigma/\sqrt n))\\ &amp; =
\frac{1}{\sigma/\sqrt n}\varphi\left(-1.645 + \frac{\mu - \mu_0}{\sigma/\sqrt n}\right) \\
&amp; &gt; 0 &amp;(\varphi(\cdot) &gt;0 , n &gt;0, \sigma &gt; 0).
\end{align*}\]</span></p>
<p>If the probability we reject the null hypothesis grows with <span class="math inline">\(\mu\in(-\infty,\mu_0]\)</span>, then of course the supremum of these probabilities is the probability at the boundary <span class="math inline">\(\mu_0\)</span>. Equivalently, <span class="math display">\[ \alpha = \inf_{\mu_0 &lt; \mu}\beta(\mu) = \inf_\mu \beta(\mu \mid \mu_0 &lt; \mu) = \inf_\mu \beta(\mu \mid H_0 \text{ false}).\]</span> Many people would define power <span class="math inline">\(\beta(\mu)\)</span> only on <span class="math inline">\((\mu_0,\infty)\)</span> (when <span class="math inline">\(H_0\)</span> is false), so in this case the size is in the infimum of the power. Finally because <span class="math display">\[\beta(\mu) = \Phi(-1.645 + t) = \Phi\left(-1.645 + \frac{\mu - \mu_0}{\sigma/\sqrt n}\right),\]</span> we have <span class="math inline">\(\alpha = \beta(\mu_0) = \Phi(-1.645)\)</span>. This means if we desire a size of <span class="math inline">\(\alpha\)</span>, we can use the standard quantile function to calculate the critical value required – <span class="math inline">\(c = -\Phi^{-1}(\alpha)\)</span>. Just to reiterate, these nice properties hold because <span class="math inline">\(\beta\)</span> is monotonic!</p>
<div class="hypothesis" name="p-Values">
<p>Our decision function <span class="math inline">\(\delta(\mathbf{X})\)</span> only tells us whether we reject the null hypothesis or not. It doesn’t directly give us any information on how confident we should be in our decision, or by what degree we reject the null hypothesis. We can capture this by looking at the distribution of the test statistics <span class="math inline">\(T(\mathbf{X})\)</span> in relation to the critical region <span class="math inline">\(C(\alpha)\)</span> for size <span class="math inline">\(\alpha\)</span>. We can define the <span style="color:red"><strong><em><span class="math inline">\(p\)</span>-value</em></strong></span>, denoted <span class="math inline">\(p\)</span>, as <span class="math display">\[p = \inf\{\alpha \mid T(\mathbf{X})\in C(\alpha)\}.\]</span> The <span class="math inline">\(p-\)</span>value is the minimum level of the test such that we still reject the null hypothesis (because <span class="math inline">\(T(\mathbf{X})\)</span> is in the critical region). Suppose in the case of the one sided <span class="math inline">\(Z-\)</span>test we had <span class="math inline">\(T(\mathbf{X}) = 2\)</span>. We reject the null hypothesis because <span class="math inline">\(T(\mathbf{X}) \ge  2\)</span>. We would also reject the null hypothesis for any size <span class="math inline">\(\alpha\)</span> such that <span class="math inline">\(2 \ge -\Phi^{-1}(\alpha)\)</span>. Because <span class="math inline">\(-\Phi^{-1}\)</span> is monotonic, <span class="math display">\[p = \inf\{\alpha\mid 2 \ge -\Phi^{-1}(\alpha)\} = \{\alpha\mid 2= -\Phi^{-1}(\alpha)\} = \Phi(-2) \approx 0.02275.\]</span> One important result which follows immediately from the definition of of <span class="math inline">\(p\)</span>: <span class="math display">\[T(\mathbf{X}) \in C\iff \alpha(\delta) &lt; p.\]</span> We reject <span class="math inline">\(H_0\)</span> <em>if and only if</em> the <span class="math inline">\(p-\)</span>value associated with <span class="math inline">\(T(\mathbf{X})\)</span> is less than the size of the test. One interpretation related to this is that the <span class="math inline">\(p-\)</span>value tells you the degree to which you reject the null hypothesis. If <span class="math inline">\(p\approx0.02275\)</span>, not only do we reject the null hypothesis for <span class="math inline">\(\alpha(\delta) = 0.05\)</span>, but we also reject it for more stringent tests with smaller sizes.</p>
</div>
<p>So if we can pick <span class="math inline">\(\alpha\)</span> by virtue of the critical value <span class="math inline">\(c\)</span>, then why don’t we simply pick <span class="math inline">\(\alpha\approx 0\)</span>. This would mean that we almost always fail to reject the null hypothesis, and in doing so we’re bound to fail to reject the null hypothesis even when it is false, increasing the probability of a type II error</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.4 (Power vs.&nbsp;Size)</strong></span> Again consider <span class="math display">\[\begin{align*}
H_0:&amp;\mu \le \mu_0\\
H_1:&amp;\mu &gt; \mu_0
\end{align*}\]</span> where <span class="math inline">\(X_i\overset{iid}{\sim}N(\mu,\sigma^2)\)</span> for a known <span class="math inline">\(\sigma^2\)</span>, and <span class="math inline">\(\delta(\mathbf{X}) = 1[T(\mathbf{X}) \ge c]\)</span> for some critical value <span class="math inline">\(c\)</span>. If we desire a test of size <span class="math inline">\(\alpha\)</span> we set our critical value as <span class="math inline">\(c = -\Phi^{-1}(\alpha)\)</span>.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">1000</span><span class="sc">/</span><span class="dv">1000</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="sc">-</span><span class="fu">qnorm</span>(x)) <span class="sc">%&gt;%</span> </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x,y)) <span class="sc">+</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Desired Size, α"</span>, <span class="at">y =</span> <span class="st">"Required Critical Value, c"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot34" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot34-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot34-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot34-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.4: The relationship between critical value and size.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Define <span class="math inline">\(t = (\mu - \mu_0)/(\sigma/\sqrt n)\)</span> to be the standardized distance between <span class="math inline">\(\mu_0\)</span> and the true <span class="math inline">\(\mu\)</span>. The power of the test is <span class="math display">\[\beta(\mu)= \Phi(- c + t) = \Phi(\Phi^{-1}(\alpha) + t),\]</span> which is increasing in <span class="math inline">\(\alpha\)</span>: <span class="math display">\[\begin{align*}
\frac{\partial \beta}{\partial \alpha} &amp; = \frac{\partial \Phi^{-1}(\alpha)}{\partial \alpha} \varphi(\Phi^{-1}(\alpha) + t) \\
&amp; = \frac{\varphi(\Phi^{-1}(\alpha) + t)}{\varphi(\Phi^{-1}(\alpha))} &amp; (\text{inverse function theorem}) \\
&amp; &gt; 0 &amp; (\varphi(\cdot) &gt; 0).
\end{align*}\]</span></p>
<p>As we let <span class="math inline">\(\alpha \to 0\)</span>, we have <span class="math inline">\(\beta \to 0\)</span>.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">a =</span> <span class="fu">c</span>(<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.10</span>, <span class="fl">0.25</span>), </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">t =</span> <span class="sc">-</span><span class="dv">2000</span><span class="sc">:</span><span class="dv">4000</span><span class="sc">/</span><span class="dv">1000</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">power =</span> <span class="fu">pnorm</span>(<span class="sc">-</span>(<span class="sc">-</span><span class="fu">qnorm</span>(a)) <span class="sc">+</span> t)) <span class="sc">%&gt;%</span> </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t, power, <span class="at">color =</span> <span class="fu">as.factor</span>(a))) <span class="sc">+</span> </span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"t =  (μ - μ0)/(σ√n)"</span>, <span class="at">y =</span> <span class="st">"Power"</span>, <span class="at">color =</span> <span class="st">"size"</span>) <span class="sc">+</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot35" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot35-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot35-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot35-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.5: There is an inherent tradeoff between the power and size of a test, as small values of α result in less power.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>So how do we select <span class="math inline">\(\alpha\)</span>? Do we care more about type I error or type II error? Furthermore, how do we even construct test statistics? We can begin to answer this question with the guidance of <span class="citation" data-cites="neyman1933">Neyman and Pearson (<a href="#ref-neyman1933" role="doc-biblioref">1933</a>)</span>.</p>
</section>
<section id="neyman-pearson-lemma-and-ump-tests" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="neyman-pearson-lemma-and-ump-tests"><span class="header-section-number">3.3</span> Neyman-Pearson Lemma and UMP Tests</h2>
<p>One of the key ideas presented proposed by <span class="citation" data-cites="neyman1933">Neyman and Pearson (<a href="#ref-neyman1933" role="doc-biblioref">1933</a>)</span> is that type II errors are more erroneous than their type I counterparts, so we should minimize the probability of committing a type II error subject to a predetermined test size <span class="math inline">\(\alpha\)</span>. If someone if getting tested for a disease, a false positive (type I) is much better than a false negative (type II). On the other hand, many would argue it is worse to sentence an innocent person to jail (type I error) than let a guilty person go free, so whether this assumption holds depends on the context of our test.</p>
<p>The Neyman-Pearson lemma solves this problem by maximizing the power of a test subject to a specified <span class="math inline">\(\alpha\)</span>: <span class="math display">\[ \max_{\delta\in \mathcal D}\{\beta(\delta, P_\boldsymbol{\theta}) \mid \alpha(\delta) &lt; \alpha\},\]</span> <em>fixing</em> <span class="math inline">\(P_\boldsymbol{\theta}\)</span>. The test which solves this maximization problem may vary across <span class="math inline">\(P_\boldsymbol{\theta}\)</span>. As such, the Neyman-Pearson lemma solves our problem in the context of simplified hypotheses.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.6</strong></span> A null hypothesis <span class="math inline">\(H_0\)</span> is <span style="color:red"><strong><em>simple</em></strong></span> if <span class="math inline">\(\mathcal P_0\)</span> is a singleton, <span class="math inline">\(\mathcal P_0 = \{P_{\boldsymbol{\theta}_0}\}\)</span>. Similarly, an alternative hypothesis <span class="math inline">\(H_1\)</span> is simple if <span class="math inline">\(\mathcal P_1 = \{P_{\boldsymbol{\theta}_1}\}\)</span>.</p>
</div>
<p>The Neyman-Pearson Lemma will only apply directly to hypotheses of the form: <span class="math display">\[\begin{align*}
H_0:P_\boldsymbol{\theta}&amp;= P_{\boldsymbol{\theta}_0}\\
H_1:P_\boldsymbol{\theta}&amp;=P_{\boldsymbol{\theta}_1}
\end{align*}\]</span> Note that for simple hypotheses <span class="math display">\[ \alpha(\delta) = \sup_{P_\boldsymbol{\theta}\in \mathcal P_0} \Pr(T(\mathbf{X})\in C \mid P_\boldsymbol{\theta}\in \mathcal P_0) = \Pr(T(\mathbf{X})\in C \mid P_\boldsymbol{\theta}=P_{\boldsymbol{\theta}_0}) \]</span></p>
<div id="NPlemma" name="Neyman-Pearson Lemma">
<p>Consider a test with simple hypotheses <span class="math inline">\(H_0:P_\boldsymbol{\theta}= P_{\boldsymbol{\theta}_0}\)</span> and <span class="math inline">\(H_1:P_\boldsymbol{\theta}=P_{\boldsymbol{\theta}_1}\)</span>. If <span class="math inline">\(\delta(\mathbf{X})\)</span> is test with size <span class="math inline">\(\alpha\)</span> and defined as <span class="math display">\[\delta(\mathbf{X})=\begin{cases} P_{\boldsymbol{\theta}_0} &amp; \frac{f_{\mathbf{X}}(\mathbf{x}\mid \boldsymbol{\theta}_1)}{f_{\mathbf{X}}(\mathbf{x}\mid \boldsymbol{\theta}_0)} &gt; \eta\\  P_{\boldsymbol{\theta}_1} &amp; \frac{f_{\mathbf{X}}(\mathbf{x}\mid \boldsymbol{\theta}_1)}{f_{\mathbf{X}}(\mathbf{x}\mid \boldsymbol{\theta}_0)} &lt; \eta\end{cases}\]</span> for <span class="math inline">\(\eta &gt; 0\)</span>, then <span class="math inline">\(\beta(\delta, \theta_1) \ge \beta(\delta', \theta_1)\)</span> for all <span class="math inline">\(\delta' \in \mathcal D\)</span> with a size less than or equal to <span class="math inline">\(\alpha\)</span>. In this case we refer to <span class="math inline">\(\delta(\mathbf{X})\)</span> as the <span style="color:red"><strong><em>most powerful (MP) test</em></strong></span> for our hypotheses.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\(\delta(\mathbf{X})\)</span> be some arbitrary decision rule in <span class="math inline">\(\mathcal D\)</span> with size <span class="math inline">\(\alpha\)</span>, and let <span class="math inline">\(\delta'\in\mathcal D\)</span> be some other decision rule with size less than or equal to <span class="math inline">\(\alpha\)</span>. <span class="math display">\[\begin{align*}
\delta(\mathbf{X}) &amp;= \begin{cases}P_{\boldsymbol{\theta}_1} &amp; \mathbf{X}\in C \\ P_{\boldsymbol{\theta}_0} &amp; \mathbf{X}\notin C\end{cases}\\
\delta'(\mathbf{X})&amp; = \begin{cases}P_{\boldsymbol{\theta}_1} &amp; \mathbf{X}\in C' \\ P_{\boldsymbol{\theta}_0} &amp; \mathbf{X}\notin C'\end{cases}\\
\Pr(\delta'(\mathbf{X}) = P_{\boldsymbol{\theta}_1} \mid P_{\boldsymbol{\theta}} = P_{\boldsymbol{\theta}_0} ) &amp;\le \alpha = \Pr(\delta(\mathbf{X}) = P_{\boldsymbol{\theta}_1} \mid P_{\boldsymbol{\theta}} = P_{\boldsymbol{\theta}_0} )
\end{align*}\]</span> Without loss of generality, we’ve taken <span class="math inline">\(T(\mathbf{X}) = \mathbf{X}\)</span>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> The only assumption we have made about our decision rules is, <span class="math display">\[\begin{align}
&amp; \Pr(\delta'(\mathbf{X}) = P_{\boldsymbol{\theta}_1} \mid P_{\boldsymbol{\theta}} = P_{\boldsymbol{\theta}_0} ) \le \alpha = \Pr(\delta(\mathbf{X}) = P_{\boldsymbol{\theta}_1} \mid P_{\boldsymbol{\theta}} = P_{\boldsymbol{\theta}_0} )\\
\implies &amp; \Pr(\mathbf{X}\in C' \mid \boldsymbol{\theta}_0 ) \le \Pr(\mathbf{X}\in C \mid \boldsymbol{\theta}_0 ) (\#eq:npa).
\end{align}\]</span></p>
<p>In order to compare <span class="math inline">\(\delta\)</span> and <span class="math inline">\(\delta'\)</span>, we’ll want to write their powers in term of the critical regions of both tests. We can write <span class="math inline">\(C\)</span> in terms of the disjoint union of its intersection with the disjoint sets <span class="math inline">\(C'\)</span> and <span class="math inline">\((C')^c\)</span>, as <span class="math inline">\(C'\)</span> and <span class="math inline">\((C')^c\)</span> partition the sample space <span class="math inline">\(\mathcal X\)</span>. We can also do the same with <span class="math inline">\(C'\)</span> and the disjoint sets <span class="math inline">\(C\)</span> and <span class="math inline">\(C^c\)</span>. <span class="math display">\[\begin{align*}
C &amp; = (C\cap C') \cup (C\cap (C')^c)\\
C' &amp; = (C'\cap C) \cup (C'\cap C^c)
\end{align*}\]</span> Accounting for these being disjoint unions, we have the following conditional probabilities: <span class="math display">\[\begin{align}
\Pr(\mathbf{X}\in C\mid \boldsymbol{\theta}) &amp; = \Pr(\mathbf{X}\in C\cap C' \mid \boldsymbol{\theta}) + \Pr(\mathbf{X}\in C\cap (C')^c \mid \boldsymbol{\theta})&amp; \text{for }\boldsymbol{\theta}\in\{\boldsymbol{\theta}_0, \boldsymbol{\theta}_1\} (\#eq:npa2)\\
\Pr(\mathbf{X}\in C'\mid\boldsymbol{\theta}) &amp; = \Pr(\mathbf{X}\in C'\cap C \mid \boldsymbol{\theta}) + \Pr(\mathbf{X}\in C'\cap C^c \mid \boldsymbol{\theta}) &amp; \text{for }\boldsymbol{\theta}\in\{\boldsymbol{\theta}_0, \boldsymbol{\theta}_1\} (\#eq:npa3)
\end{align}\]</span> We can use these two equations to rewrite Equation @ref(eq:npa). <span class="math display">\[\begin{align}
&amp;  \Pr(\mathbf{X}\in C' \mid \boldsymbol{\theta}_0 ) \le \Pr(\mathbf{X}\in C \mid \boldsymbol{\theta}_0 )\\
\implies &amp; \Pr(\mathbf{X}\in C'\cap C \mid \boldsymbol{\theta}_0) + \Pr(\mathbf{X}\in C'\cap C^c \mid \boldsymbol{\theta}_0) \le \Pr(\mathbf{X}\in C\cap C' \mid \boldsymbol{\theta}_0) + \Pr(\mathbf{X}\in C\cap (C')^c \mid \boldsymbol{\theta}_0)\\
\implies &amp; \Pr(\mathbf{X}\in C'\cap C^c \mid \boldsymbol{\theta}_0) \le\Pr(\mathbf{X}\in C\cap (C')^c \mid \boldsymbol{\theta}_0) (\#eq:npa4)
\end{align}\]</span> Similarly, <span class="math display">\[\begin{align}
\beta(\delta,\boldsymbol{\theta}_1) &amp; = \Pr(\mathbf{X}\in C \mid \theta_1) &amp;(\text{definition of }\beta)  (\#eq:npa5)\\
&amp; = \Pr(\mathbf{X}\in C\cap C' \mid \boldsymbol{\theta}_1) + \Pr(\mathbf{X}\in C\cap (C')^c \mid \boldsymbol{\theta}_1) &amp; (\text{Equation }(4.2))\\
\beta(\delta',\boldsymbol{\theta}_1) &amp; =\Pr(\mathbf{X}\in C'\cap C \mid \boldsymbol{\theta}_1) + \Pr(\mathbf{X}\in C'\cap C^c \mid \boldsymbol{\theta}_1) &amp; (\text{Equation }(4.3))  (\#eq:npa6)
\end{align}\]</span></p>
<p>We want to construct <span class="math inline">\(\delta(\mathbf{X})\)</span> such that <span class="math display">\[\begin{align*}
&amp;\beta(\delta,\boldsymbol{\theta}_1)  \ge\beta(\delta',\boldsymbol{\theta}_1),\\
\implies&amp;\Pr(\mathbf{X}\in C\cap C' \mid \boldsymbol{\theta}_1) + \Pr(\mathbf{X}\in C\cap (C')^c \mid \boldsymbol{\theta}_1) \le  \Pr(\mathbf{X}\in C'\cap C \mid \boldsymbol{\theta}_1) + \Pr(\mathbf{X}\in C'\cap C^c \mid \boldsymbol{\theta}_1) &amp;(\text{Equation }(4.5)\text{ and }(4.6)),\\
\implies &amp;\Pr(\mathbf{X}\in C\cap (C')^c \mid \boldsymbol{\theta}_1)  \ge \Pr(\mathbf{X}\in C'\cap C^c \mid \boldsymbol{\theta}_1),\\
\implies &amp; \int 1[\mathbf{X}\in C\cap (C')^c]\ dF_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1) \ge \int 1[\mathbf{X}\in C'\cap C^c]\ dF_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1),\\
\implies &amp; \int_{C\cap (C')^c} f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1) \ d\mathbf{x}\ge \int_{C'\cap C^c} f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1) \ d\mathbf{x}
\end{align*}\]</span> In other words, we need to define <span class="math inline">\(C\)</span> such that <span class="math display">\[ \int_{C\cap (C')^c} f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1)\stackrel{?}{\ge}\int_{C'\cap C^c} f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1) \ d\mathbf{x}\]</span> using the fact that <span class="math display">\[\begin{align*}
\int_{C'\cap C^c }f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)\ d\mathbf{x}&amp; \le \int_{C\cap (C')^c }f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)\ d\mathbf{x}&amp; (\text{Equation (4.4)}).
\end{align*}\]</span> We can write the left hand side of this known inequality as <span class="math display">\[\begin{align*}
\int_{C'\cap C^c }f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)\ d\mathbf{x}= \int_{C'\cap C^c}f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1) \cdot \frac{f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)}{f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1)}\ d\mathbf{x}.
\end{align*}\]</span> We want to somehow relate this to the integral of <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1)\)</span>, but in general cannot “remove” <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)/f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1)\)</span> from the integrand without an assumption about <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)/f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1)\)</span>. Namely, if we assume <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)/f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1) &gt;\eta^{-1}\)</span> on <span class="math inline">\(C'\cap C^c\)</span> for some constant <span class="math inline">\(\eta\)</span>,<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> we have <span class="math display">\[\begin{align*}
\int_{C'\cap C^c }f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)\ d\mathbf{x}= \int_{C'\cap C^c }f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1) \cdot \frac{f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)}{f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1)}\ d\mathbf{x}
\ge \eta^{-1}\int_{C'\cap C^c}f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0) \ d\mathbf{x}.
\end{align*}\]</span> Similarly, the right hand side of Equation 4.4 in integral form can be written as <span class="math display">\[\int_{C\cap (C')^c }f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)\ d\mathbf{x}= \int_{C\cap (C')^c }f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1) \cdot \frac{f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)}{f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1)}\ d\mathbf{x}\le \eta^{-1}\int_{C\cap (C')^c }f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0) \ d\mathbf{x},\]</span> assuming <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)/f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1) &lt; \eta^{-1}\)</span> on <span class="math inline">\(C\cap (C')^c\)</span>. Therefore, <span class="math display">\[\begin{align*}
\int_{C\cap (C')^c} f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1)\ d\mathbf{x}&amp; = \int_{C\cap (C')^c}f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1)  \cdot \frac{f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)}{f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1)}\ d\mathbf{x}\\
&amp; \ge \eta^{-1}\int_{C\cap (C')^c}f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)\ d\mathbf{x}&amp; (f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)/f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1) &lt; \eta^{-1} \text{ on } C\cap (C')^c)\\
&amp; =\eta^{-1}\Pr(\mathbf{X}\in C\cap (C')^c \mid \boldsymbol{\theta}_0)\\
&amp; \ge  \eta^{-1}\Pr(\mathbf{X}\in C'\cap C^c \mid \boldsymbol{\theta}_0) &amp; (\text{Equation }(4.4))\\
&amp; =\eta^{-1}\int_{ C'\cap C^c}f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)\ d\mathbf{x}\\
&amp; \ge \int_{C'\cap C^c }f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1) \cdot \frac{f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_0)}{f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1)}\ d\mathbf{x}&amp; (f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)/f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1) &gt; \eta^{-1} \text{ on } C'\cap C^c)\\
&amp; = \int_{C'\cap C^c} f_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta}_1)\ d\mathbf{x},
\end{align*}\]</span> which is the desired result for a fixed <span class="math inline">\(\delta'\)</span>. If we extend <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)/f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1) &gt; \eta^{-1}\)</span> to all of <span class="math inline">\(C^c\)</span> and <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)/f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1) &lt; \eta^{-1}\)</span> to all of <span class="math inline">\(C\)</span>, then this will hold <em>for all</em> <span class="math inline">\(\delta'\in \mathcal D\)</span> (with a size of at least <span class="math inline">\(\alpha\)</span>, otherwise Equation @ref(eq:npa4) needn’t hold). What then is the explicit form of <span class="math inline">\(\delta(\mathbf{X})\)</span>? It is defined using the bounds which allowed us to establish the desired inequality using properties of integrals. The critical region is, <span class="math display">\[\begin{align*}
C &amp;= \left\{\mathbf{x}\ \bigg|\ \frac{f_{\mathbf{X}}(\mathbf{x}\mid \boldsymbol{\theta}_1)}{f_{\mathbf{X}}(\mathbf{x}\mid \boldsymbol{\theta}_0)} &gt; \eta \right\}
\end{align*}\]</span> and <span class="math inline">\(\delta(\mathbf{X}) = 1[\mathbf{x}\in C]\)</span>.</p>
</div>
<p>Before discussing the intuition behind Theorem @ref(thm:NPlemma), here are some technical points:</p>
<ol type="1">
<li>In the event <span class="math inline">\(f_{\mathbf{X}}(\mathbf{x}\mid \boldsymbol{\theta}_1)/f_{\mathbf{X}}(\mathbf{x}\mid \boldsymbol{\theta}_0) = \eta\)</span>, then it doesn’t matter if <span class="math inline">\(\delta(\mathbf{X})\)</span> rejects the null hypothesis or not.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></li>
<li>A more general version of the result can be found in <span class="citation" data-cites="bickel2015mathematical">Bickel and Doksum (<a href="#ref-bickel2015mathematical" role="doc-biblioref">2015</a>)</span> or <span class="citation" data-cites="lehmann2005testing">Romano and Lehmann (<a href="#ref-lehmann2005testing" role="doc-biblioref">2005</a>)</span>, and concerns non-deterministic decision rules which the reject the null hypothesis with some probability when <span class="math inline">\(T(\mathbf{X}) \in C\)</span> (instead of with probability one)</li>
<li>The result says nothing about the uniqueness of the MP test.</li>
</ol>
<p>Theorem @ref(thm:NPlemma) tells us that for simple hypotheses, our test statistic should be <span class="math inline">\(T(\mathbf{X}) = \frac{f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1)}{f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)}\)</span>, which makes a fair bit of sense. If we observe <span class="math inline">\(\mathbf{x}\)</span>, then <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1)\)</span> and <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)\)</span> are the probabilities we observe <span class="math inline">\(\mathbf{x}\)</span> given <span class="math inline">\(\boldsymbol{\theta}_1\)</span> and <span class="math inline">\(\boldsymbol{\theta}_0\)</span>, respectively. In the event that <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1) \gg f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)\)</span>, it’s so likely that <span class="math inline">\(\boldsymbol{\theta}= \boldsymbol{\theta}_1\)</span>, that we should reject the null hypothesis. In other words, we reject the null hypothesis is the ratio of these probabilities is high enough. This ratio actually pops up elsewhere in statistics and has its own name.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.7</strong></span> The <span style="color:red"><strong><em>likelihood ratio</em></strong></span> associated with densities <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1)\)</span> and <span class="math inline">\(f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)\)</span> is defined as <span class="math display">\[ L(\boldsymbol{\theta}_1, \boldsymbol{\theta}_0 \mid \mathbf{x}) = \frac{f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_1)}{f_\mathbf{X}(\mathbf{x}\mid\boldsymbol{\theta}_0)}.\]</span></p>
</div>
<p>So how large does this ratio need to be such that we reject the null hypothesis? The Neyman-Pearson Lemma seems a bit vague here, as it only says that it needs to exceed <em>some</em> <span class="math inline">\(\eta\)</span>. The proof gives us some mathematical context on <span class="math inline">\(\eta\)</span>, but also fails to explicitly define it, so can we really pick <em>any</em> constant? Of course not, because we assume that <span class="math inline">\(\delta(\mathbf{X})\)</span> has size <span class="math inline">\(\alpha\)</span>. The actual value <span class="math inline">\(\eta\)</span> is implicitly given when we assume the size of <span class="math inline">\(\delta(\mathbf{X})\)</span>, but we can define is explicitly. <span class="math display">\[\begin{align*}
&amp; \alpha = \Pr(T(\mathbf{X}) &gt; \eta \mid P_\boldsymbol{\theta}= P_{\boldsymbol{\theta}_0})\\
\implies &amp; \alpha = 1 - \Pr(T(\mathbf{X}) \le \eta \mid P_\boldsymbol{\theta}= P_{\boldsymbol{\theta}_0})\\
\implies &amp; \alpha = 1 - F_{T(\mathbf{X})}(\eta \mid P_{\boldsymbol{\theta}_0})\\
\implies &amp; \eta = F_{T(\mathbf{X})}^{-1}(1-\alpha \mid P_{\boldsymbol{\theta}_0})
\end{align*}\]</span></p>
<p>Let’s see the Neyman-Pearson Lemma in action.</p>
<div id="exm-npnorm" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.5</strong></span> Suppose <span class="math inline">\(X_i \overset{iid}{\sim}N(\mu,\sigma^2)\)</span> for a known <span class="math inline">\(\sigma^2\)</span>, and <span class="math display">\[\begin{align*}
H_0:\mu=\mu_0,\\
H_1:\mu=\mu_1,
\end{align*}\]</span> where <span class="math inline">\(\mu_1 &gt; \mu_0\)</span>. Our likelihood ratio is <span class="math display">\[\begin{align*}
\frac{f_\mathbf{X}(\mathbf{x}\mid\mu_1)}{f_\mathbf{X}(\mathbf{x}\mid\mu_0)} &amp; = \frac{\prod_{i=1}^nf_{X_i}(x\mid\mu_1)}{\prod_{i=1}^nf_{X_i}(x\mid\mu_0)} \\
&amp; = \frac{\prod_{i=1}^n\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left[-\frac{(x-\mu_1)^2}{2\sigma^2}\right]}{\prod_{i=1}^n\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left[-\frac{(x-\mu_0)^2}{2\sigma^2}\right]}\\
&amp; = \frac{\prod_{i=1}^n\exp\left[-\frac{(x-\mu_1)^2}{2\sigma^2}\right]}{\prod_{i=1}^n\exp\left[-\frac{(x-\mu_0)^2}{2\sigma^2}\right]}\\
&amp; = \frac{\exp\left[-\sum_{i=1}^n\frac{(x-\mu_1)^2}{2\sigma^2}\right]}{\exp\left[-\sum_{i=1}^n\frac{(x-\mu_0)^2}{2\sigma^2}\right]}\\
&amp; = \exp\left[\frac{1}{2\sigma^2}\left(\sum_{i=1}^n(x_i - \mu_0)^2 - \sum_{i=1}^n(x_i - \mu_1)^2\right)\right]\\
&amp; = \exp\left[\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i^2 - x_i\mu_0 + \mu_0^2 - x_i^2  - x_i\mu_1 + \mu_1^2)\right]\\
&amp; = \exp\left[\frac{1}{2\sigma^2}[n(\mu_0^2 - \mu_1^2) - 2n\bar x(\mu_0 - \mu_1)]\right].
\end{align*}\]</span> The Neyman-Pearson lemma says the critical region of our test should take the form <span class="math display">\[\begin{align*}
C &amp; = \left\{\mathbf{x}\ \Big| \  \exp\left[\frac{1}{2\sigma^2}[n(\mu_0^2 - \mu_1^2) - 2n\bar x(\mu_0 - \mu_1)]\right] &gt; \eta\right\}\\
  &amp; = \left\{\mathbf{x}\ \Big| \ \bar x &gt; \frac{\mu_0+\mu_1}{2} - \frac{\sigma^2 \ln \eta}{n(\mu_0-\mu_1)}\right\}
\end{align*}\]</span> …okay so this looks like a monstrosity. Let’s define the constant <span class="math inline">\(\eta^*\)</span> to as <span class="math display">\[\eta^* = \frac{\mu_0+\mu_1}{2} - \frac{\sigma^2 \ln \eta}{n(\mu_0-\mu_1)},\]</span> as to give us <span class="math display">\[ C = \{\mathbf{x}\mid \bar x &gt; \eta^*\}.\]</span> If we want our test to have a size of <span class="math inline">\(\alpha\)</span>, we let <span class="math inline">\(\eta^* = \mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}\)</span>, which is the same one sided test we’ve been exploring in this section! Therefore the most powerful test for <span class="math inline">\(H_0 : \mu = \mu_1\)</span> versus <span class="math inline">\(H_1 : \mu = \mu_1\)</span> is:</p>
<p><span class="math display">\[\begin{align*}
\delta(\mathbf{X}) &amp; = \begin{cases}\mu_0 &amp; \bar X &lt; \mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n} \\ \mu_1 &amp; \bar X &gt; \mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}\end{cases} &amp; (T(\mathbf{X}) = \bar X)\\
&amp; = \begin{cases}\mu_0 &amp; \frac{\bar X - \mu_0}{\sigma/\sqrt n} &lt; \Phi^{-1}(1-\alpha) \\ \mu_1 &amp; \frac{\bar X - \mu_0}{\sigma/\sqrt n} &gt; \Phi^{-1}(1-\alpha) \end{cases}&amp; (T(\mathbf{X}) = (\bar X - \mu_0)/(\sigma/\sqrt n))
\end{align*}\]</span></p>
<p>These decision rules are equivalent to the likelihood ratio test given by the Neyman-Pearson lemma. If we want to keep with the spirit of the lemma and insist on using the test statistic <span class="math inline">\(T(\mathbf{X}) = \frac{f_\mathbf{X}(\mathbf{x}\mid\mu_1)}{f_\mathbf{X}(\mathbf{x}\mid\mu_0)}\)</span>, we need to solve for <span class="math inline">\(\eta\)</span>.</p>
<p><span class="math display">\[\begin{align*}
&amp;\eta^* = \mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}\\
\implies &amp; \frac{\mu_0+\mu_1}{2} - \frac{\sigma^2 \ln \eta}{n(\mu_0-\mu_1)} = \mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}\\
\implies &amp; \eta = \exp\left[-\left(\mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}\right)\left(\frac{n(\mu_0-\mu_1)}{\sigma^2}\right)\right]
\end{align*}\]</span></p>
<p>This gives the decision rule <span class="math display">\[\begin{align*}
\delta(\mathbf{X}) &amp;= \begin{cases}\mu_0 &amp; \frac{f_\mathbf{X}(\mathbf{x}\mid\mu_1)}{f_\mathbf{X}(\mathbf{x}\mid\mu_0)} &lt; \exp\left[-\left(\mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}\right)\left(\frac{n(\mu_0-\mu_1)}{\sigma^2}\right)\right] \\ \mu_1 &amp; \frac{f_\mathbf{X}(\mathbf{x}\mid\mu_1)}{f_\mathbf{X}(\mathbf{x}\mid\mu_0)} &gt;\exp\left[-\left(\mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}\right)\left(\frac{n(\mu_0-\mu_1)}{\sigma^2}\right)\right]\end{cases} &amp; (T(\mathbf{X}) = f_\mathbf{X}(\mathbf{x}\mid\mu_1)/f_\mathbf{X}(\mathbf{x}\mid\mu_0))
\end{align*}\]</span></p>
<p>To confirm these three test are equivalent, let’s simulate the decision rule for <span class="math inline">\(H_0:\mu = 0\)</span> versus <span class="math inline">\(H_1: \mu = 3\)</span>, where <span class="math inline">\(\sigma^2 = 1\)</span>, <span class="math inline">\(n = 100\)</span>, <span class="math inline">\(\alpha = 0.05\)</span>, and null hypothesis <span class="math inline">\(\mu = 0\)</span> is true. Not only should the tests agree for each simulation, but we should also see that we reject the null hypothesis (commit a type I error) with probability <span class="math inline">\(\alpha\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>sample_mean_test <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu0, alpha, sigma){</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  test_stat <span class="ot">&lt;-</span> <span class="cf">function</span>(X) {</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>(X)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">test_stat</span>(X) <span class="sc">&gt;</span> mu0 <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha)<span class="sc">*</span>(sigma<span class="sc">/</span><span class="fu">sqrt</span>(n))    </span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>z_score_test <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu0, alpha, sigma){</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  test_stat <span class="ot">&lt;-</span> <span class="cf">function</span>(X) {</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    (<span class="fu">mean</span>(X) <span class="sc">-</span> mu0)<span class="sc">/</span>(sigma<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">test_stat</span>(X) <span class="sc">&gt;</span> <span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha)   </span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>likelihood_ratio_test <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu0, mu1, alpha, sigma){</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>  test_stat <span class="ot">&lt;-</span> <span class="cf">function</span>(X) {</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prod</span>(<span class="fu">dnorm</span>(X, mu1, sigma)) <span class="sc">/</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(X, mu0, sigma))</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>  eta <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="sc">-</span>(mu0 <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha)<span class="sc">*</span>(sigma<span class="sc">/</span><span class="fu">sqrt</span>(n)) <span class="sc">-</span> (mu1<span class="sc">+</span>mu0)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>((n<span class="sc">*</span>(mu0<span class="sc">-</span>mu1)) <span class="sc">/</span>(sigma<span class="sc">^</span><span class="dv">2</span>)))</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">test_stat</span>(X) <span class="sc">&gt;</span> eta</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>iter <span class="ot">&lt;-</span> <span class="cf">function</span>(mu0, mu1, alpha, sigma, n, dist, dist_params, s){</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">smt =</span> <span class="fu">sample_mean_test</span>(X, mu0, alpha, sigma),</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">zst =</span> <span class="fu">z_score_test</span>(X, mu0, alpha, sigma),</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">lrt =</span> <span class="fu">likelihood_ratio_test</span>(X, mu0, mu1, alpha, sigma),</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">iter_num =</span> s</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>sim <span class="ot">&lt;-</span> <span class="cf">function</span>(N, mu0, mu1, alpha, sigma, n, dist, dist_params){</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>      iter, </span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu0 =</span> mu0, </span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu1 =</span> mu1, </span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>      <span class="at">alpha =</span> alpha, </span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>      <span class="at">sigma =</span> sigma, </span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n, </span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>      <span class="at">dist =</span> dist, </span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>      <span class="at">dist_params =</span> dist_params</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">sim</span>(<span class="fl">1e5</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="fl">0.05</span>, <span class="dv">1</span>, <span class="dv">100</span>, rnorm, <span class="fu">list</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a><span class="co">#If all decisions were the same, this should be 1</span></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob =</span> <span class="fu">mean</span>(smt <span class="sc">==</span> zst <span class="sc">&amp;</span> zst <span class="sc">==</span> lrt))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
   prob
  &lt;dbl&gt;
1     1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Check number of rejections of the true null hypothesis</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(results<span class="sc">$</span>smt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.05058</code></pre>
</div>
</div>
<p>This example is particularly special, because we were able to write the most powerful test in a form that did not depend on <span class="math inline">\(\mu_1\)</span>: <span class="math display">\[\delta(\mathbf{X}) =\begin{cases}\mu_0 &amp; \frac{\bar X - \mu_0}{\sigma/\sqrt n} &gt; \Phi^{-1}(1-\alpha) \\ \mu_1 &amp; \frac{\bar X - \mu_0}{\sigma/\sqrt n} &lt; \Phi^{-1}(1-\alpha) \end{cases}\]</span> The test statistic and critical region do not depend on <span class="math inline">\(\mu_1\)</span>, so this test is the most powerful test for any alternative <span class="math inline">\(\mu_1 &gt; \mu_0\)</span>. This means that this test is the most powerful test for any hypothesis of the form <span class="math inline">\(H_0:\mu = \mu_0\)</span> versus <span class="math inline">\(\mu \ge \mu_0\)</span>. In fact, we can even go one step further – this test is the most powerful test for any hypotheses of the form <span class="math inline">\(H_0:\mu\le \mu_0\)</span> versus <span class="math inline">\(H_1:\mu &gt; \mu_0\)</span>! Consider testing <span class="math inline">\(H_0:\mu = \mu_0\)</span> versus <span class="math inline">\(H_1:\mu \ge \mu_0\)</span>, and testing the modified hypothesis <span class="math inline">\(H_0':\mu = \mu_0'\)</span> versus <span class="math inline">\(H_1':\mu \ge \mu_0'\)</span>, where <span class="math inline">\(\mu_0'&lt;\mu_0\)</span>. All we’ve done is slightly tweaked <span class="math inline">\(H_0 : \mu \le \mu_0\)</span> by lowering the value of <span class="math inline">\(\mu_0'\)</span>. What happens if we attempt to test <span class="math inline">\(H_0'\)</span> versus <span class="math inline">\(H_1'\)</span> using the test statistic for <span class="math inline">\(\delta(\mathbf{X})\)</span> (as given above) instead of the test statistic of its modified counterpart <span class="math inline">\(\delta'(\mathbf{X})\)</span>? <span class="math display">\[\begin{align*}
T(\mathbf{X})&amp;=\frac{\bar X - \mu_0}{\sigma/\sqrt n}\\
T'(\mathbf{X})&amp;=\frac{\bar X - \mu_0'}{\sigma/\sqrt n}
\end{align*}\]</span> Under <span class="math inline">\(H_0'\)</span>: <span class="math display">\[\begin{align*}
T'(\mathbf{X}) &amp; \sim N(0,1)\\
T(\mathbf{X}) &amp; = \frac{\bar X - \mu_0'}{\sigma/\sqrt n} + \frac{\mu_0' - \mu_0}{\sigma/\sqrt n} = T'(\mathbf{X}) + \frac{\mu_0' - \mu_0}{\sigma/\sqrt n} \sim N\left(\frac{\mu_0' - \mu_0}{\sigma/\sqrt n}, 1\right)
\end{align*}\]</span></p>
<p>If we calculate the power of <span class="math inline">\(\delta'\)</span>, we find that <span class="math display">\[\begin{align*}
c' &amp; = -\Phi^{-1}(\alpha),\\
c &amp; = -\left[\Phi^{-1}\left(\alpha\right) - \frac{\mu_0' - \mu_0}{\sigma/\sqrt n}\right] = \frac{\mu_0' - \mu_0}{\sigma/\sqrt n}- \Phi^{-1}(\alpha).
\end{align*}\]</span> The power of the tests are <span class="math display">\[\begin{align*}
\beta(\delta, \mu) &amp; = \Pr\left(T(\mathbf{X}) &gt; \frac{\mu_0' - \mu_0}{\sigma/\sqrt n}- \Phi^{-1}(\alpha)\ \bigg| \ \mu\right)\\
&amp; = \Pr\left(T(\mathbf{X}) - \frac{\mu_0' - \mu_0}{\sigma/\sqrt n} &gt;  \Phi^{-1}(\alpha)\ \bigg| \ \mu\right)\\
&amp; = \Pr\left(T'(\mathbf{X}) &gt; - \Phi^{-1}(\alpha)  \mid \mu\right)\\
&amp; = \beta(\delta', \mu).
\end{align*}\]</span> Both tests have the same power, and same size, so <span class="math inline">\(\delta\)</span> is the most powerful test for any <span class="math inline">\(H_0':\mu \neq \mu_0'\)</span> versus <span class="math inline">\(H_1':\mu &gt; \mu_0'\)</span> where <span class="math inline">\(\mu_0'&lt;\mu_0\)</span>. We can confirm this with simulations:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>curve <span class="ot">&lt;-</span> <span class="fu">power_curve</span>(</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">domain =</span> <span class="fu">seq</span>(<span class="fl">2.6</span>, <span class="fl">3.3</span>, <span class="at">length =</span> <span class="dv">10</span>), <span class="do">## update to 40</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e3</span>, <span class="do">## update to 1e4</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> delta, </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_stat =</span> test_stat,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">critical_region =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="fu">qnorm</span>(<span class="fl">0.05</span>), <span class="cn">Inf</span>)),</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_0 =</span> <span class="fl">2.7</span>,</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="dv">1</span>, </span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">decision =</span> <span class="st">"δ"</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>curve_prime <span class="ot">&lt;-</span> <span class="fu">power_curve</span>(</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">domain =</span> <span class="fu">seq</span>(<span class="fl">2.6</span>, <span class="fl">3.3</span>, <span class="at">length =</span> <span class="dv">10</span>), <span class="do">## update to 40</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e3</span> , <span class="do">## update to 1e4</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> delta, </span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_stat =</span> test_stat,</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">critical_region =</span> <span class="fu">list</span>(<span class="fu">c</span>((<span class="fl">2.7</span> <span class="sc">-</span> <span class="dv">3</span>)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">100</span>)) <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="fl">0.05</span>), <span class="cn">Inf</span>)),</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_0 =</span> <span class="dv">3</span>,</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="dv">1</span>, </span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">decision =</span> <span class="st">"δ'"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>curve <span class="sc">%&gt;%</span> </span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(curve_prime) <span class="sc">%&gt;%</span> </span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t, simulated_power, <span class="at">color =</span> decision)) <span class="sc">+</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>)) <span class="sc">+</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"μ"</span>, <span class="at">y =</span> <span class="st">"Simulated Power"</span>, <span class="at">color =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot36" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot36-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot36-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot36-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.6: Simulated power curve for the two null hypotheses
</figcaption>
</figure>
</div>
</div>
</div>
<p>This will hold for all hypotheses <span class="math inline">\(H_1':\mu\le \mu_0'\)</span> where <span class="math inline">\(\mu_0'\)</span>, as <span class="math inline">\(\mu_0'\)</span> was arbitrary. This means that if we are testing <span class="math inline">\(H_0:\mu \le \mu_0\)</span> versus <span class="math inline">\(H_1:\mu&gt;\mu_0\)</span>, the most powerful test is the z-test, regardless of the specified <span class="math inline">\(\mu_0\)</span> or alternative <span class="math inline">\(\mu\)</span>. Because we pick the test that was derived using <span class="math inline">\(H_0:\mu = \mu_0\)</span>, we often write <span class="math display">\[\begin{align*}
H_0&amp;:\mu=\mu_0,\\
H_1&amp;:\mu&gt;\mu_0.
\end{align*}\]</span></p>
</div>
<p>While this example started as an application of the Neyman-Pearson lemma, it took several interesting turns. Firstly, while the Neyman-Pearson lemma gives the most powerful test in terms of the likelihood ratio, we were able to find several equivalent tests. Secondly, the most powerful test for the simple hypothesis <span class="math inline">\(H_0: \mu = \mu_0\)</span> versus <span class="math inline">\(H_1:\mu = \mu_1\)</span> (where <span class="math inline">\(\mu_1 &gt; \mu_0\)</span>), as given by the Neyman-Pearson lemma, did not depend on <span class="math inline">\(\mu_1\)</span>. This meant it was the most powerful test for <span class="math inline">\(H_0: \mu = \mu_0\)</span> versus <span class="math inline">\(H_1:\mu &gt; \mu_0\)</span>. It is uniform in its status as the most powerful test.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.8</strong></span> A decision rule <span class="math inline">\(\delta(\mathbf{X})\)</span>, with size <span class="math inline">\(\alpha\)</span>, is the <span style="color:red"><strong><em>uniformly most powerful (UMP)</em></strong></span> test for <span class="math inline">\(H_0: P_{\boldsymbol{\theta}}\in\mathcal P_0\)</span> versus <span class="math inline">\(H_1: P_{\boldsymbol{\theta}}\in\mathcal P_1\)</span> if <span class="math display">\[ \beta(\delta,P_\boldsymbol{\theta}) \ge \beta(\delta',P_\boldsymbol{\theta}) \ \ \ \text{for all }P_\boldsymbol{\theta}\in\mathcal P_1\]</span> for all other decision rules <span class="math inline">\(\delta'\)</span> with a size of at least <span class="math inline">\(\alpha\)</span>.</p>
</div>
<p>We also were able to establish that the UMP test for <span class="math inline">\(H_0: \mu = \mu_0\)</span> versus <span class="math inline">\(H_1:\mu &gt; \mu_0\)</span>, is the UMP for any test of the form <span class="math inline">\(H_0:\mu \le \mu_0\)</span> versus <span class="math inline">\(H_1:\mu &gt;\mu_0\)</span>. Despite the Neyman-Pearson lemma only holding for simple hypotheses, we were able to derive the optimal (in the sense of power) test for composite hypotheses in this case. Is this always the case, or was there something special at work? Let’s look at another example to get a better lay of the land.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.6</strong></span> Suppose we draw a single observation of <span class="math inline">\(X\)</span> where <span class="math inline">\(X\sim \text{Cauchy}(\theta,1)\)</span> and want to test <span class="math inline">\(H_0:\theta = 0\)</span> versus <span class="math inline">\(H_1:\theta = \theta_1\)</span>. In this case <span class="math display">\[f_X(x\mid\theta)= \frac{1}{\pi(1+(x-\theta)^2)},\]</span> so the Neyman-Pearson lemma tells us the most powerful test is <span class="math display">\[\delta(X) = \begin{cases}0 &amp; \frac{1+x^2}{1+(x-\theta_1)^2} &lt; \eta\\ \theta_1 &amp; \frac{1+x^2}{1+(x-\theta_1)^2} &gt; \eta\end{cases}.\]</span> To get a better sense of what the critical region for this test is, let’s plot the likelihood ratio.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">10</span>, <span class="at">length =</span> <span class="dv">3000</span>), </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">alt_par =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">1.2</span>, <span class="fl">1.4</span>,<span class="fl">1.6</span>,<span class="fl">1.8</span>,<span class="dv">2</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">dcauchy</span>(x, alt_par, <span class="dv">1</span>)<span class="sc">/</span><span class="fu">dcauchy</span>(x, <span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x,y, <span class="at">color =</span> <span class="fu">as.factor</span>(alt_par))) <span class="sc">+</span> </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Likelihood Ratio"</span>) <span class="sc">+</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Value of Single Observation"</span>) <span class="sc">+</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">2</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">color =</span> <span class="st">"Alternative θ"</span>) <span class="sc">+</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>) <span class="sc">+</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="sc">-</span><span class="dv">3</span>, <span class="at">y =</span> <span class="fl">2.3</span>, <span class="at">label =</span> <span class="st">"η"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot37" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot37-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot37-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot37-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.7: The liklihood ratio associated with the Cauchy distribution. The liklihood ratio test tells us to reject the null hypothesis whenever the ratio exceeds η
</figcaption>
</figure>
</div>
</div>
</div>
<p>Our rejection region will be a bounded interval. After some quick algebra, we find that the critical region is <span class="math display">\[C = \left\{x\ \Bigg| \ \frac{\eta\theta_1-\sqrt{\eta\theta_1^2+2\eta-\eta^2-1}}{\eta-1}&lt; x &lt;\frac{\eta\theta_1+\sqrt{\eta\theta_1^2+2\eta-\eta^2-1}}{\eta-1} \right\}.\]</span> Fixing <span class="math inline">\(\eta\)</span> to be some value, say <span class="math inline">\(\eta = 2\)</span>, we can plot these critical regions across values of <span class="math inline">\(\theta_1\)</span>.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>eta <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(<span class="at">par =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="fl">1.2</span>,<span class="fl">1.4</span>,<span class="fl">1.6</span>,<span class="fl">1.8</span>,<span class="dv">2</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> (eta<span class="sc">*</span>par <span class="sc">-</span> <span class="fu">sqrt</span>(eta<span class="sc">*</span>par<span class="sc">^</span><span class="dv">2</span><span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>eta<span class="sc">-</span>eta<span class="sc">^</span><span class="dv">2-1</span>)) <span class="sc">/</span> (eta <span class="sc">-</span> <span class="dv">1</span>),</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper =</span> (eta<span class="sc">*</span>par <span class="sc">+</span> <span class="fu">sqrt</span>(eta<span class="sc">*</span>par<span class="sc">^</span><span class="dv">2</span><span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>eta<span class="sc">-</span>eta<span class="sc">^</span><span class="dv">2-1</span>)) <span class="sc">/</span> (eta <span class="sc">-</span> <span class="dv">1</span>),</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">val =</span> (upper <span class="sc">+</span> lower)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(par, val)) <span class="sc">+</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper)) <span class="sc">+</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Alternative θ"</span>, <span class="at">y =</span> <span class="st">"Critical Region"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot38" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot38-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot38-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot38-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.8: The critical regions associated with the liklihood ratio test for varying alternatives. None of the critial regions are subsets of others.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The upper and lower bounds depend on the alternate <span class="math inline">\(\theta_1\)</span> so the most powerful test for one choice of <span class="math inline">\(\theta_1\)</span> fails to be the most powerful test for another <span class="math inline">\(\theta_1'\)</span>.</p>
</div>
<p>So what makes this different from the example with the normal distribution? Fixing <span class="math inline">\(H_0:\mu_0 = 0\)</span>, <span class="math inline">\(\sigma^2 = 1\)</span>, and <span class="math inline">\(n=1\)</span>, Let’s see if the likelihood ratio for normally distributed data has any clues.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="at">length =</span> <span class="dv">3000</span>), </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">alt_par =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">1.2</span>, <span class="fl">1.4</span>,<span class="fl">1.6</span>,<span class="fl">1.8</span>,<span class="dv">2</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">dnorm</span>(x, alt_par, <span class="dv">1</span>)<span class="sc">/</span><span class="fu">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x,y, <span class="at">color =</span> <span class="fu">as.factor</span>(alt_par))) <span class="sc">+</span> </span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Value of Single Observation"</span>, <span class="at">y =</span> <span class="st">"Likelihood Ratio"</span>, <span class="at">color =</span> <span class="st">"Alternative μ"</span>) <span class="sc">+</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot39" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot39-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot39-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot39-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.9: The liklihood ratio associated with the standard normal distribution
</figcaption>
</figure>
</div>
</div>
</div>
<p>Now let’s plot the critical region <span class="math display">\[ C = \left\{x \mid x &gt; \mu_1/2 + \ln \eta / \mu_1\right\}\]</span> for varying alternatives <span class="math inline">\(\mu_1\)</span>, fixing <span class="math inline">\(\eta = 2\)</span> (which is equivalent to fixing the size <span class="math inline">\(\alpha\)</span>).</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(<span class="at">par =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="fl">1.2</span>,<span class="fl">1.4</span>,<span class="fl">1.6</span>,<span class="fl">1.8</span>,<span class="dv">2</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> par<span class="sc">/</span><span class="dv">2</span> <span class="sc">-</span> (<span class="fu">log</span>(<span class="dv">2</span>))<span class="sc">/</span>(par),</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper =</span> <span class="cn">Inf</span>,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">val =</span> (upper <span class="sc">+</span> lower)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(par, val)) <span class="sc">+</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper)) <span class="sc">+</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Alternative μ"</span>, <span class="at">y =</span> <span class="st">"Critical Region"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot310" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot310-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot310-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot310-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.10: The critical regions associated with the liklihood ratio test for varying alternatives. As we increase the alternative μ, each critical region is a subset of the prior one.
</figcaption>
</figure>
</div>
</div>
</div>
<p>As <span class="math inline">\(\mu_1\)</span> increases, each critical region is a subset of the prior. In other words, for <span class="math inline">\(\mu_1' &gt; \mu_1\)</span>, <span class="math display">\[ x &gt; \frac{\mu_1'}{2} + \frac{\ln \eta}{\mu_1'} \implies x &gt; \frac{\mu_1}{2} + \frac{\ln \eta}{\mu_1}.\]</span> If we reject the null hypothesis for <span class="math inline">\(\mu_1'\)</span>, we will reject it for <span class="math inline">\(\mu_1\)</span>. If we want to pick the critical region that gives us the most power out of these options (subject to the fixed size <span class="math inline">\(\alpha\)</span>), we should pick the largest one, as it maximizes our chance of rejecting the null hypothesis, and is is a superset of the other choices of critical region. It is essential that the critical regions nest in one another like this as. Such sets are often called a monotonic sequence of sets, which is interesting, as the corresponding likelihood ratio is monotonically increasing for any <span class="math inline">\(\theta_1&gt;\theta_0\)</span>. This monotonicity turns out to be the key to extending the Neyman-Pearson lemma to composite hypotheses.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.9</strong></span> A density <span class="math inline">\(f_{\mathbf{X}}(\mathbf{x}\mid \theta)\)</span> has a <span style="color:red"><strong><em>monotone likelihood ratio (MLR) with respect to a statistic <span class="math inline">\(T\)</span></em></strong></span> if <span class="math inline">\(f(\mathbf{x}\mid \theta_1)/f(\mathbf{x}\mid \theta_0)\)</span> can be written as <span class="math inline">\(f_{\mathbf{X}}(T(\mathbf{x}) \mid \theta_1)/f_{\mathbf{X}}(T(\mathbf{x}) \mid \theta_0)\)</span>, and <span class="math inline">\(f_{\mathbf{X}}(T(\mathbf{x}) \mid \theta_1)/f_{\mathbf{X}}(T(\mathbf{x}) \mid \theta_0)\)</span> is a monotonically increasing function in <span class="math inline">\(T(\mathbf{x})\)</span> for <span class="math inline">\(\theta_1 &gt; \theta_0\)</span>.</p>
</div>
<p>In Example @ref(exm:npnorm), the normal distribution has an increasing MLR in the statistic <span class="math inline">\(T(\mathbf{X}) = \bar X\)</span>.</p>
<div id="thm-KR" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.1 (Karlin-Rubin Theorem)</strong></span> Suppose <span class="math inline">\(f_{\mathbf{X}}(\mathbf{x}\mid \theta)\)</span> has an increasing MLR in the statistic <span class="math inline">\(T\)</span>. The decision rule <span class="math inline">\(\delta(\mathbf{X})\)</span> defined as <span class="math display">\[ \delta(\mathbf{X}) = \begin{cases} \mathcal P_1 &amp; T(\mathbf{X}) &gt; \eta \\
\mathcal P_0  &amp; T(\mathbf{X}) &lt; \eta
\end{cases}\]</span> is the UMP test for <span class="math inline">\(H_0: \theta \le \theta_0\)</span> versus <span class="math inline">\(H_1:\theta &gt; \theta_0\)</span>. Additionally, the power function <span class="math inline">\(\beta(\delta, \theta)\)</span> is monotonically increasing. Analogously, <span class="math display">\[ \delta(\mathbf{X}) = \begin{cases} \mathcal P_1 &amp; T(\mathbf{X}) &lt; \eta \\
\mathcal P_0  &amp; T(\mathbf{X}) &gt; \eta
\end{cases}\]</span> is the UMP test for <span class="math inline">\(H_0: \theta \ge \theta_0\)</span> versus <span class="math inline">\(H_1:\theta &lt; \theta_0\)</span>, and the power function is monotonically decreasing.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>See <span class="citation" data-cites="degroot2012probability">DeGroot and Schervish (<a href="#ref-degroot2012probability" role="doc-biblioref">2012</a>)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.7 (Testing Variance)</strong></span> Suppose we want to test <span class="math inline">\(H_0:\sigma^2 \ge \sigma_0^2\)</span> versus <span class="math inline">\(H_1:\sigma^2 &lt; \sigma_0^2\)</span> where <span class="math inline">\(X_i \overset{iid}{\sim}N(\mu,\sigma^2)\)</span> for a known <span class="math inline">\(\mu\)</span>. For <span class="math inline">\(\sigma_1^2 &lt; \sigma_0^2\)</span>, the likelihood ratio of the joint distribution of our data is <span class="math display">\[\begin{align*}
\frac{f_\mathbf{X}(\mathbf{x}\mid\sigma_1^2)}{f_\mathbf{X}(\mathbf{x}\mid\sigma_0^2)} &amp; = \frac{\prod_{i=1}^nf_{X_i}(x\mid\sigma_1^2)}{\prod_{i=1}^nf_{X_i}(x\mid\sigma_0^2)} \\
&amp; = \frac{\left(\frac{1}{\sigma_1\sqrt{2\pi}}\right)^n}{\left(\frac{1}{\sigma_0\sqrt{2\pi}}\right)^n}\frac{\exp\left[-\sum_{i=1}^n\frac{(x_i-\mu)^2}{2\sigma_1^2}\right]}{\exp\left[-\sum_{i=1}^n\frac{(x_i-\mu)^2}{2\sigma_0^2}\right]}\\ &amp; = \left(\frac{\sigma_0}{\sigma_1}\right)^{n}
\exp \left[\sum_{i=1}^n\frac{(x_i-\mu)^2}{2\sigma_0^2}-\sum_{i=1}^n\frac{(x_i-\mu)^2}{2\sigma_1^2}  \right] \\
&amp; = \left(\frac{\sigma_1^2}{\sigma_0^2}\right)^{-n/2}
\exp \left[-\frac{1}{2(\sigma_1^2 - \sigma_0^2)}\sum_{i=1}^n(x_i-\mu)^2 \right]  \\
&amp; = \left(\frac{\sigma_1^2}{\sigma_0^2}\right)^{-n/2}
\exp \left[-\frac{T(\mathbf{x})}{2(\sigma_1^2 - \sigma_0^2)} \right]
\end{align*}\]</span> If we define <span class="math inline">\(T(\mathbf{X}) = \sum_{i=1}^n(X_i-\mu)^2\)</span>, then the likelihood ratio is monotonically decreasing for <span class="math inline">\(\sigma_1^2 &lt; \sigma_0^2\)</span> (meaning <span class="math inline">\(\sigma_1^2 - \sigma_0^2 &lt; 0\)</span>).<br>
<span class="math display">\[ \frac{\partial}{\partial T(\mathbf{x})}\left[\frac{f_\mathbf{X}(\mathbf{x}\mid\sigma_1^2)}{f_\mathbf{X}(\mathbf{x}\mid\sigma_0^2)}\right] = -\frac{1}{2(\sigma_1^2 - \sigma_0^2)}\cdot \left[\frac{f_\mathbf{X}(\mathbf{x}\mid\sigma_1^2)}{f_\mathbf{X}(\mathbf{x}\mid\sigma_0^2)}\right] &gt; 0.\]</span> This means the UMP test takes the form <span class="math display">\[\delta(\mathbf{X}) = \begin{cases} \sigma^2 &lt; \sigma_0^2 &amp; \sum_{i=1}^n(X_i-\mu)^2 &lt; \eta \\
\mathcal \sigma^2 \ge \sigma_0^2 &amp; \sum_{i=1}^n(X_i-\mu)^2 &gt; \eta
\end{cases}.\]</span> If we define <span class="math inline">\(\eta^* = 1/\sigma_0^2\)</span>, then <span class="math display">\[\delta(\mathbf{X}) = \begin{cases} \sigma^2 &lt; \sigma_0^2 &amp; \sum_{i=1}^n\left(\frac{X_i-\mu}{\sigma_0}\right)^2 &lt; \eta^* \\
\mathcal \sigma^2 \ge \sigma_0^2 &amp; \sum_{i=1}^n\left(\frac{X_i-\mu}{\sigma_0}\right)^2 &gt; \eta^*
\end{cases}.\]</span> Writing our test like this is far more useful, because <span class="math inline">\(T(\mathbf{X})\)</span> is now the sum of <span class="math inline">\(n\)</span> random variables which are distributed according to a standard normal distribution, i.e <span class="math inline">\(T(\mathbf{X}) \sim \chi^2_n\)</span>. This allows us to easily calculate <span class="math inline">\(\eta^*\)</span> given a desired size <span class="math inline">\(\alpha\)</span> using the quantile function for <span class="math inline">\(T(\mathbf{X}) \sim \chi^2_n\)</span>. <span class="math display">\[\delta(\mathbf{X}) = \begin{cases} \sigma^2 &lt; \sigma_0^2 &amp; \sum_{i=1}^n\left(\frac{X_i-\mu}{\sigma_0}\right)^2 &lt; (\chi^2_n)^{-1}(\alpha) \\
\mathcal \sigma^2 \ge \sigma_0^2 &amp; \sum_{i=1}^n\left(\frac{X_i-\mu}{\sigma_0}\right)^2 &gt; (\chi^2_n)^{-1}(\alpha)
\end{cases}\]</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>test_stat <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu, sigma_0){</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(((X <span class="sc">-</span> mu)<span class="sc">/</span>sigma_0)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>delta <span class="ot">&lt;-</span> <span class="cf">function</span>(test_stat, critical_region, X, mu, sigma_0){</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>  stat <span class="ot">&lt;-</span> <span class="fu">test_stat</span>(X, mu, sigma_0)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>  decision <span class="ot">&lt;-</span> critical_region <span class="sc">%&gt;%</span> </span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map_lgl</span>(\(bounds) <span class="fu">between</span>(stat, bounds[<span class="dv">1</span>], bounds[<span class="dv">2</span>])) <span class="sc">%&gt;%</span> </span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.logical</span>()</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">stat =</span> stat,</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> decision,</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">H_0 =</span> sigma_0</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>test_iter <span class="ot">&lt;-</span> <span class="cf">function</span>(delta, test_stat, critical_region, mu, sigma_0, n, dist, dist_params, s){</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">delta</span>(test_stat, critical_region, X, mu, sigma_0) <span class="sc">%&gt;%</span> </span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">iter =</span> s)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>test_sim <span class="ot">&lt;-</span> <span class="cf">function</span>(N, delta, test_stat, critical_region, mu, sigma_0, n, dist, dist_params){</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>      test_iter, </span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>      <span class="at">delta =</span> delta, </span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>      <span class="at">test_stat =</span> test_stat, </span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>      <span class="at">critical_region =</span> critical_region, </span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> mu, </span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>      <span class="at">sigma_0 =</span> sigma_0,</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n, </span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>      <span class="at">dist =</span> dist, </span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>      <span class="at">dist_params =</span> dist_params</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a><span class="co"># This function assumes dist = rnorm and dist_params = list(0, sigma)</span></span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a>power <span class="ot">&lt;-</span> <span class="cf">function</span>(sigma, N, delta, test_stat, critical_region, mu, sigma_0, n){</span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>  dist <span class="ot">&lt;-</span> rnorm</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>  dist_params <span class="ot">&lt;-</span> <span class="fu">list</span>(mu, sigma)</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">test_sim</span>(N, delta, test_stat, critical_region, mu, sigma_0, n, dist, dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>      <span class="at">simulated_power =</span> <span class="fu">mean</span>(decision),</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>      <span class="at">t =</span> sigma</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a>power_curve <span class="ot">&lt;-</span> <span class="cf">function</span>(domain, N, delta, test_stat, critical_region, mu, sigma_0, n){</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> domain <span class="sc">%&gt;%</span> </span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>      power,</span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>      <span class="at">N =</span> N,</span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a>      <span class="at">delta =</span> delta,</span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a>      <span class="at">test_stat =</span> test_stat,</span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>      <span class="at">critical_region =</span> critical_region,</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> mu,</span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a>      <span class="at">sigma_0 =</span> sigma_0,</span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">power_curve</span>(</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>  <span class="at">domain =</span> <span class="fu">seq</span>(<span class="fl">0.65</span>, <span class="fl">1.2</span>, <span class="at">length =</span> <span class="dv">10</span>), <span class="do">## change length to 40</span></span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e3</span>, <span class="do">## change to 1e4</span></span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> delta,</span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_stat =</span> test_stat,</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a>  <span class="at">critical_region =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">qchisq</span>(<span class="fl">0.05</span>, <span class="dv">100</span>))),</span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="dv">0</span>,</span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_0 =</span> <span class="dv">1</span>,</span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span></span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t, simulated_power)) <span class="sc">+</span> </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Alternate σ"</span>, <span class="at">y =</span> <span class="st">"Power"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot311" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot311-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot311-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot311-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.11: Power curve associated with the liklihood ratio for variance
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>The Karlin-Rubin Theorem is very powerful, but is limited. It only works for scalar parameters <span class="math inline">\(\theta_0\)</span>. The second we consider situations with a vector of parameters <span class="math inline">\(\boldsymbol{\theta}_0\)</span>, or a situation where are model is semiparametric or nonparametric, UMP tests usually do not exist. The theorem also does not directly apply to two-sided tests. There is some disagreement among sources about whether UMP tests even exist for two-sided tests (<span class="citation" data-cites="degroot2012probability">DeGroot and Schervish (<a href="#ref-degroot2012probability" role="doc-biblioref">2012</a>)</span> and <span class="citation" data-cites="casella2021statistical">Casella and Berger (<a href="#ref-casella2021statistical" role="doc-biblioref">2021</a>)</span> argue that they do not exist, while <span class="citation" data-cites="lehmann2005testing">Romano and Lehmann (<a href="#ref-lehmann2005testing" role="doc-biblioref">2005</a>)</span> say otherwise).</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.8 (Two-Sided Z Test)</strong></span> Suppose we want to test <span class="math inline">\(H_0:\mu = \mu_0\)</span> versus <span class="math inline">\(H_1:\mu\neq \mu_0\)</span> where <span class="math inline">\(X_i \overset{iid}{\sim}N(\mu,\sigma^2)\)</span> for a known <span class="math inline">\(\sigma^2\)</span>. To test this for some significance level <span class="math inline">\(\alpha\)</span>, we usually use a two-sided form of the <span class="math inline">\(z-\)</span>test: <span class="math display">\[\begin{align*}
\delta(\mathbf{X}) &amp; = \begin{cases}\mu = \mu_0 &amp; \Phi^{-1}(\alpha/2)&lt; \frac{\bar X-\mu_0}{\sigma/\sqrt{n}}&lt;\Phi^{-1}(1-\alpha/2)\\
\mu \neq \mu_0 &amp; \frac{\bar X-\mu_0}{\sigma/\sqrt{n}}\le \Phi^{-1}(1-\alpha/2) \text{ or }\frac{\bar X-\mu_0}{\sigma/\sqrt{n}}\ge\Phi^{-1}(1-\alpha/2)\end{cases}  
= \begin{cases}\mu = \mu_0 &amp; \left\lvert\frac{\bar X-\mu_0}{\sigma/\sqrt{n}}\right\rvert&lt;\Phi^{-1}(1-\alpha/2)\\
\mu \neq \mu_0 &amp; \left\lvert\frac{\bar X-\mu_0}{\sigma/\sqrt{n}}\right\rvert\ge \Phi^{-1}(1-\alpha/2)\end{cases}
\end{align*}\]</span> Consider the “right-handed” and “left-handed” alternatives <span class="math inline">\(\delta_R(\mathbf{X})\)</span> and <span class="math inline">\(\delta_L(\mathbf{X})\)</span>, respectively. Let’s graph the power functions of these three tests for <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> (<span class="sc">-</span><span class="dv">500</span><span class="sc">:</span><span class="dv">500</span>)<span class="sc">/</span><span class="dv">100</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Right Handed'</span> <span class="ot">=</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">+</span> x), </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Left Handed'</span> <span class="ot">=</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">-</span> x),</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Two Sided'</span> <span class="ot">=</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.956</span> <span class="sc">+</span> <span class="fu">abs</span>(x))</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> <span class="st">"test"</span>, <span class="at">value =</span> <span class="st">"power"</span>, <span class="sc">-</span>x) <span class="sc">%&gt;%</span> </span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x, power, <span class="at">color =</span> test)) <span class="sc">+</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"(μ - μ0)/(σ√n)"</span>, <span class="at">y =</span> <span class="st">"Power"</span>, <span class="at">color =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot312" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot312-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot312-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot312-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.12: Power for three versions of the Z-test
</figcaption>
</figure>
</div>
</div>
</div>
<p>We see that <span class="math inline">\(\beta(\delta_R) &gt; \beta(\delta)\)</span> when <span class="math inline">\(\mu &gt; \mu_0\)</span> and <span class="math inline">\(\beta(\delta_L) &gt; \beta(\delta)\)</span> when <span class="math inline">\(\mu &lt; \mu_0\)</span>, so clearly <span class="math inline">\(\delta\)</span> is not a UMP. Despite this <span class="citation" data-cites="lehmann2005testing">Romano and Lehmann (<a href="#ref-lehmann2005testing" role="doc-biblioref">2005</a>)</span> would argue this test is UMP, because it actually has significance level <span class="math inline">\(\alpha/2\)</span>. For two sided tests in this setting, <span class="citation" data-cites="lehmann2005testing">Romano and Lehmann (<a href="#ref-lehmann2005testing" role="doc-biblioref">2005</a>)</span> define a size <span class="math inline">\(\alpha\)</span> test to be one where <span class="math display">\[ \alpha(\delta \mid \mu &lt; \mu_0) =  \alpha(\delta \mid \mu &gt; \mu_0) = \alpha.\]</span></p>
</div>
<div class="proof remark">
<p><span class="proof-title"><em>Remark</em>. </span>The approach to testing proposed by <span class="citation" data-cites="neyman1933">Neyman and Pearson (<a href="#ref-neyman1933" role="doc-biblioref">1933</a>)</span> was/is not without controversy. Ronald Fisher, one of the central figures in the formalization of statistics, took issue with approach of Neyman and Pearson. A debate raged between the scientists as to the proper way of testing statistical hypotheses. The full details of this dispute is summarized by <span class="citation" data-cites="lehmann1993fisher">Lehmann (<a href="#ref-lehmann1993fisher" role="doc-biblioref">1993</a>)</span> and <span class="citation" data-cites="lehmann2011fisher">Lehmann (<a href="#ref-lehmann2011fisher" role="doc-biblioref">2011</a>)</span>.</p>
</div>
</section>
<section id="asymptotics" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="asymptotics"><span class="header-section-number">3.4</span> Asymptotics</h2>
<p>Until now, all of our examples have assumed <span class="math inline">\(X_i \overset{iid}{\sim}N(\mu,\sigma^2)\)</span>. In this case, we were able to find the exact distribution of test statistics used to test hypotheses about <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. This will usually not be possible, and we will need to use the tools developed in Section <a href="#sec-asy" class="quarto-xref"><span class="quarto-unresolved-ref">sec-asy</span></a> to determine the asymptotic distribution of test statistics. To highlight this, we will consider a situation where we can derive the distribution of a test statistic, but as <span class="math inline">\(n\to\infty\)</span>, it converges in distribution such that there is virtually no harm done from using the asymptotic distribution instead.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.9 (t-Test)</strong></span> For one final time, assume <span class="math inline">\(X_i \overset{iid}{\sim}N(\mu,\sigma^2)\)</span>, <em>but</em> drop the assumption that <span class="math inline">\(\sigma^2\)</span> is known. Assuming that we knew <span class="math inline">\(\sigma^2\)</span> made little to no sense. If we don’t know <span class="math inline">\(\mu\)</span>, then how would we possibly know <span class="math inline">\(\sigma^2\)</span> (which is calculated using <span class="math inline">\(\mu\)</span>)?! If we want to test <span class="math inline">\(H_0:\mu = \mu_0\)</span> versus <span class="math inline">\(H_1: \mu \neq \mu_0\)</span>, which decision rule do we pick? We can no longer calculate the statistic <span class="math inline">\(Z = \frac{\bar X - \mu_0}{\sigma/\sqrt n}\)</span>, as we do not know <span class="math inline">\(\sigma\)</span>. What if we simply replaced <span class="math inline">\(\sigma\)</span> with the (unbiased) sample standard deviation? <span class="math display">\[T(\mathbf{X}) = \frac{\bar X - \mu_0}{s/\sqrt n}\]</span> By replacing <span class="math inline">\(\sigma\)</span> with <span class="math inline">\(s\)</span>, we now have <span class="math inline">\(T(\mathbf{X})\not\sim N(0,1)\)</span>, so we can no longer define the critical region using <span class="math inline">\(\Phi^{-1}\)</span>. Instead we have <span class="math inline">\(T(\mathbf{X})\sim t_{n-1}\)</span>,<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> so we can still test <span class="math inline">\(H_0\)</span> versus <span class="math inline">\(H_1\)</span>. This new test is the classic <strong><em>(student’s) <span class="math inline">\(t-\)</span>test</em></strong>, and we usually write the test statistic as <span class="math inline">\(t = T(\mathbf{X})\)</span>. <span class="math display">\[\delta(\mathbf{X}) = \begin{cases} \mu \neq \mu_0&amp; \left\lvert\frac{\bar X - \mu_0}{s/\sqrt n}\right\rvert \ge t_{n-1}^{-1}(1-\alpha/2)\\ \mu = \mu_0 &amp; \left\lvert\frac{\bar X - \mu_0}{s/\sqrt n}\right\rvert &lt; t_{n-1}^{-1}(1-\alpha/2)\end{cases} \]</span></p>
<p>But does this difference in distribution really matter? In Section @ref(asymptotic-properties-of-estimators), one example highlighted that if <span class="math inline">\(Y \sim t_{n}\)</span>, then <span class="math inline">\(Y\overset{d}{\to}N(0,1)\)</span>. This means that <span class="math inline">\(t\overset{d}{\to}Z\)</span>, and the <span class="math inline">\(t-\)</span>test is asymptotically equivalent to the <span class="math inline">\(z-\)</span>test. To illustrate this, suppose <span class="math inline">\(X_i \overset{iid}{\sim}N(4,1)\)</span>, <span class="math inline">\(H_0:\mu = 2\)</span>, and <span class="math inline">\(H_1:\mu \neq 2\)</span>. For <span class="math inline">\(\alpha = 0.01\)</span>, we can compare the results of the two tests as <span class="math inline">\(n\)</span> increases.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Define t-test</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>t_test <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu_0, alpha){</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  T_stat <span class="ot">&lt;-</span> (<span class="fu">mean</span>(X) <span class="sc">-</span> mu_0)<span class="sc">/</span>(<span class="fu">sd</span>(X)<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abs</span>(T_stat) <span class="sc">&gt;</span> <span class="fu">qt</span>(<span class="dv">1</span> <span class="sc">-</span> alpha<span class="sc">/</span><span class="dv">2</span>, <span class="at">df =</span> n <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Define an "incorrect" z-test using the sample standard deviation</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>z_test <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu_0, alpha){</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>  Z <span class="ot">&lt;-</span> (<span class="fu">mean</span>(X) <span class="sc">-</span> mu_0)<span class="sc">/</span>(<span class="fu">sd</span>(X)<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abs</span>(Z) <span class="sc">&gt;</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>iter <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, mu_0, n, mu, sigma, t){</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, mu, sigma)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">iter_num =</span> t,</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">agree =</span> (<span class="fu">t_test</span>(X, mu_0, alpha) <span class="sc">==</span> <span class="fu">z_test</span>(X, mu_0, alpha))</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>sim <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha, mu_0, n, mu, sigma){</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(iter, <span class="at">alpha =</span> alpha, <span class="at">mu_0 =</span> mu_0, <span class="at">n =</span> n, <span class="at">mu =</span> mu, <span class="at">sigma =</span> sigma) <span class="sc">%&gt;%</span> </span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">sample_size =</span> n)</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>outer_sim <span class="ot">&lt;-</span> <span class="cf">function</span>(n_vals, N, alpha, mu_0, mu, sigma){</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> n_vals <span class="sc">%&gt;%</span> </span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(sim, <span class="at">N =</span> N, <span class="at">alpha =</span> alpha, <span class="at">mu_0 =</span> mu_0, <span class="at">mu =</span> mu, <span class="at">sigma =</span> sigma) <span class="sc">%&gt;%</span> </span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">outer_sim</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">15</span>, <span class="fl">1e4</span>, <span class="fl">0.01</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(sample_size) <span class="sc">%&gt;%</span> </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop =</span> <span class="fu">sum</span>(agree)<span class="sc">/</span><span class="fu">n</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(sample_size, prop)) <span class="sc">+</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Sample Size, n"</span>, <span class="at">y =</span> <span class="st">"Frequency of Tests Agreeing over 10000 Simulations"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot313" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot313-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot313-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot313-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.13: As the sample size increases, the frequency at which the Z-test and t-test agree increase
</figcaption>
</figure>
</div>
</div>
</div>
<p>Even for modest values of <span class="math inline">\(n\)</span>, the tests return the same results for 10,000 simulations.</p>
</div>
<p>While this example illustrates how we can leverage asymptotics when testing hypotheses, we weren’t “required” by any means to take advantage of the fact that <span class="math inline">\(t\overset{d}{\to}N(0,1)\)</span>, because we knew that <span class="math inline">\(t\sim t_{n-1}\)</span>. Unfortunately, <span class="math inline">\(t\sim t_{n-1}\)</span> will only hold if <span class="math inline">\(X_i\overset{iid}{\sim}N(\mu,\sigma^2)\)</span>. Once we drop this assumption we must rely on the fact that <span class="math inline">\(t \overset{d}{\to}N(0,1)\)</span></p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.10 (Non-normal Data)</strong></span> Suppose <span class="math inline">\(X_i\overset{iid}{\sim}F_X\)</span>, and we want to test <span class="math inline">\(H_0:\mu = \mu_0\)</span> versus <span class="math inline">\(H_1: \mu \neq \mu_0\)</span>. The (irregular) model <span class="math inline">\(\mathcal P\)</span> is a collection of sets, each comprised of all the distributions with a common expected value <span class="math inline">\(\mu\)</span>. <span class="math display">\[P_\mu = \left\{f_\mathbf{X}(\mathbf{x})\ \Bigg|\ f_\mathbf{X}(\mathbf{x}) = \prod_{i=1}^n f_{X_i}(x) \text{ and } f_{X_i} = f_{X_j}\ \forall i,j \text{ and }\text{E}\left[X_i\right]=\mu\ \forall i\right\}\]</span>In this case, the CLT tells us that <span class="math inline">\(\sqrt{n}(\bar X - \mu_0) \overset{d}{\to}N(0,1)\)</span>, so <span class="math display">\[ t = \frac{(\bar X - \mu_0)}{S/\sqrt{n}} = \frac{\sqrt{n}(\bar X - \mu_0)}{S}  \overset{d}{\to}\frac{N(0,\sigma^2)}{S} = t_{n-1}.\]</span> Even though we do not know the actual distribution of <span class="math inline">\(T\)</span>, we know the asymptotic distribution, and can calculate critical regions when <span class="math inline">\(n\)</span> is sufficiently large. To demonstrate this, let’s simulate <span class="math inline">\(\Pr(T\in C\mid \mu=\mu_0)\)</span> for <span class="math display">\[\delta(\mathbf{X}) = \begin{cases} \mu \neq \mu_0&amp; \left\lvert\frac{\bar X - \mu_0}{s/\sqrt n}\right\rvert \ge t_{n-1}^{-1}(1-\alpha/2)\\ \mu = \mu_0 &amp; \left\lvert\frac{\bar X - \mu_0}{s/\sqrt n}\right\rvert &lt; t_{n-1}^{-1}(1-\alpha/2)\end{cases}\]</span> when <span class="math inline">\(X_i \overset{iid}{\sim}\text{Exp}(1/\mu)\)</span> (such that <span class="math inline">\(\text{E}\left[X_i\right]=\mu\)</span>). As <span class="math inline">\(n\to\infty\)</span>, we should see <span class="math inline">\(\Pr(T\in C\mid \mu=\mu_0)\to \alpha\)</span>, indicating that <span class="math inline">\(t_{n-1}\)</span> does indeed provide a sufficient approximation to calculate critical values. We will test <span class="math inline">\(H_0:\mu=2\)</span> versus <span class="math inline">\(H_0:\mu=8\)</span> where <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>simulate_test <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, mu_0, n, dist, dist_params, t){</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> <span class="fu">t_test</span>(X, mu_0, alpha),</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">iter_num =</span> t</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>simulate_alpha_at_n <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha, mu_0, n, dist, dist_params){</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(simulate_test, <span class="at">alpha =</span> alpha, <span class="at">mu_0 =</span> mu_0, <span class="at">n =</span> n, <span class="at">dist =</span> dist, <span class="at">dist_params =</span> dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">alpha =</span> <span class="fu">mean</span>(decision),</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">sample_size =</span> n</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>simulate_alpha_over_n <span class="ot">&lt;-</span> <span class="cf">function</span>(n_vals, N, alpha, mu_0, dist, dist_params){</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> n_vals <span class="sc">%&gt;%</span> </span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(simulate_alpha_at_n, <span class="at">N =</span> N, <span class="at">alpha =</span> alpha, <span class="at">mu_0 =</span> mu_0, <span class="at">dist =</span> dist, dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">simulate_alpha_over_n</span>(</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_vals =</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>)<span class="sc">*</span><span class="dv">10</span>, </span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e2</span>,  <span class="co"># increase to 1e5</span></span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fl">0.05</span>, </span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_0 =</span> <span class="dv">2</span>, </span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist =</span> rexp, </span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist_params =</span> <span class="fu">list</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(sample_size, alpha)) <span class="sc">+</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Sample Size, n"</span>, <span class="at">y =</span> <span class="st">"Simulated α"</span>) <span class="sc">+</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.05</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot314" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot314-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot314-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot314-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.14: Despite our data being drawn from an exponential distribution, the test statistic is asympotically distributed according to the t-distribution, so the simulated size approaches the theoretical size of 0.05
</figcaption>
</figure>
</div>
</div>
</div>
<p>We also have that <span class="math inline">\(t\overset{d}{\to}N(0,1)\)</span> when <span class="math inline">\(X_i\overset{iid}{\sim}F_X\)</span>. We have <span class="math inline">\(S\to\sigma\)</span>, so by Slutsky’s theorem <span class="math display">\[ t = \underbrace{\sqrt{n}(\bar X - \mu_0)}_{\overset{d}{\to}N(0,\sigma^2)} / \underbrace{S}_{\overset{p}{\to}\sigma} \overset{d}{\to}N(0,1).\]</span> If we wanted to, we could still calculate critical values using the standard normal distribution, even with non-normal data, but those calculated with <span class="math inline">\(t_{n-1}\)</span> would be more slightly more accurate (with this advantage quickly diminishing as <span class="math inline">\(n\to\infty\)</span>).</p>
</div>
<p>In practice, the overwhelming majority of our tests will rely on asymptotic distributions of test statistics. What does this mean when considering the power of a test? The Neyman-Pearson lemma and Karlin-Rubin theorem assumed a fixed sample size. In this sense, we were consider finite sample properties of tests, just like how we considered finite sample properties of estimators in @ref(finite-sample-properties-of-estimators). This was a bit shortsighted considering the effect sample size has on power.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.11 (Power and Sample Size)</strong></span> Consider testing <span class="math inline">\(H_0:\mu \le \mu_0\)</span> versus <span class="math inline">\(H_1:\mu &gt; \mu_0\)</span> using the <span class="math inline">\(z-\)</span>test. where <span class="math inline">\(X_i\overset{iid}{\sim}N(\mu,\sigma^2)\)</span>. The power of this test is <span class="math display">\[\beta(\mu) = \Phi\left(-1.645 + \frac{\mu-\mu_0}{\sigma / \sqrt{n}} \right).\]</span> Power is increasing in <span class="math inline">\(n\)</span> as <span class="math display">\[ \frac{\partial \beta}{\partial n} = \frac{\mu-\mu_0}{2\sigma\sqrt n}\varphi\left(-1.645 + \frac{\mu-\mu_0}{\sigma / \sqrt{n}} \right) &gt; 0.\]</span></p>
<p>If we plot <span class="math inline">\(\beta(\mu)\)</span> for various sample sizes, it appears that that <span class="math inline">\(\beta(\mu \mid \mu &gt; \mu_0) \to 1\)</span>, and <span class="math inline">\(\beta(\mu \mid \mu \le \mu_0) \to 0\)</span>. For example if <span class="math inline">\(\mu_0 = 2\)</span> and <span class="math inline">\(\sigma = 1\)</span>, we have:</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>mu_0 <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">seq</span>(<span class="fl">1.8</span>, <span class="fl">2.2</span>, <span class="at">length =</span> <span class="dv">1000</span>), </span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="fu">c</span>((<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>)<span class="sc">*</span><span class="dv">10</span>, (<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>)<span class="sc">*</span><span class="dv">100</span>, (<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>)<span class="sc">*</span><span class="dv">1000</span>, (<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>)<span class="sc">*</span><span class="dv">10000</span>)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">power =</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">+</span> (mu <span class="sc">-</span> mu_0)<span class="sc">/</span>(sigma<span class="sc">/</span><span class="fu">sqrt</span>(n)))) <span class="sc">%&gt;%</span> </span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(mu, power)) <span class="sc">+</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fl">1.8</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">xend =</span> <span class="dv">2</span>, <span class="at">yend =</span> <span class="dv">0</span>), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">2</span>, <span class="at">y =</span> <span class="dv">1</span>, <span class="at">xend =</span> <span class="fl">2.2</span>, <span class="at">yend =</span> <span class="dv">1</span>), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">2</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">xend =</span> <span class="dv">2</span>, <span class="at">yend =</span> <span class="dv">1</span>), <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>) <span class="sc">+</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Alternate μ"</span>, <span class="at">y =</span> <span class="st">"Power"</span>, <span class="at">color =</span> <span class="st">"Sample Size"</span>) <span class="sc">+</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">colour =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transition_states</span>(n) <span class="sc">+</span> </span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">'n = {closest_state}'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_segment(aes(x = 1.8, y = 0, xend = 2, yend = 0), color = "red"): All aesthetics have length 1, but the data has 36000 rows.
ℹ Did you mean to use `annotate()`?</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_segment(aes(x = 2, y = 1, xend = 2.2, yend = 1), color = "red"): All aesthetics have length 1, but the data has 36000 rows.
ℹ Did you mean to use `annotate()`?</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_segment(aes(x = 2, y = 0, xend = 2, yend = 1), color = "red", : All aesthetics have length 1, but the data has 36000 rows.
ℹ Did you mean to use `annotate()`?</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Cannot get dimensions of plot table. Plot region might not be fixed
Caused by error in `setup_params()`:
! `direction` must be a string or character vector.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Failed to plot frame
Caused by error in `setup_params()`:
! `direction` must be a string or character vector.</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-plot315" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot315-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot315-1.gif" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot315-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.15: As the sample size increases, the power curve approaches a step function that is 0 where the null hypothesis is true, and 1 where is is false
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>This example highlights that as <span class="math inline">\(n\to\infty\)</span>, tests become optimal in the sense that the probability of committing any error (whether it be type I or type II) approaches zero.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.10</strong></span> Suppose <span class="math inline">\(\delta(\mathbf{X})\)</span> is a decision rule for the hypotheses <span class="math inline">\(H_0:P_{\boldsymbol{\theta}}\in\mathcal P_0\)</span> versus <span class="math inline">\(H_1:P_{\boldsymbol{\theta}}\in\mathcal P_0\)</span>. The decision rule has <span style="color:red"><strong><em>asymptotic size <span class="math inline">\(\alpha\)</span></em></strong></span> if <span class="math display">\[ \lim_{n\to\infty} \beta(\delta, P_{\boldsymbol{\theta}} \mid P_{\boldsymbol{\theta}}\in\mathcal P_0) = \alpha.\]</span> The decision rule has <span style="color:red"><strong><em>consistent</em></strong></span> if <span class="math display">\[ \lim_{n\to\infty} \beta(\delta, P_{\boldsymbol{\theta}} \mid P_{\boldsymbol{\theta}}\in\mathcal P_1) = 1.\]</span></p>
</div>
<p>These two definitions are somewhat informal, and barely scratch the surface of asymptotic properties of hypothesis testing. For a detailed treatment, see <span class="citation" data-cites="lehmann2005testing">Romano and Lehmann (<a href="#ref-lehmann2005testing" role="doc-biblioref">2005</a>)</span>.</p>
</section>
<section id="confidence-intervals" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="confidence-intervals"><span class="header-section-number">3.5</span> Confidence Intervals</h2>
<p>An alternate way to think about hypothesis testing is in terms of confidence intervals. An inherent flaw in point estimation is that is necessarily provides a single estimate. We may want to provide a set of plausible estimates in an effort to address the inherent uncertainty that arises from point estimation.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.11</strong></span> A statistic <span class="math inline">\(\underline\theta(\mathbf{X})\)</span> is a <span style="color:red"><strong><em>level <span class="math inline">\((1-\alpha)\)</span> lower confidence bound for <span class="math inline">\(\theta\)</span></em></strong></span> if <span class="math inline">\(\Pr[\underline\theta(\mathbf{X}) \le \theta] \ge 1 - \alpha\)</span> for all <span class="math inline">\(\theta \in \Theta\)</span>. A statistic <span class="math inline">\(\bar\theta(\mathbf{X})\)</span> is a <span style="color:red"><strong><em>level <span class="math inline">\((1-\alpha)\)</span> upper confidence bound for <span class="math inline">\(\theta\)</span></em></strong></span> if <span class="math inline">\(\Pr[\bar\theta(\mathbf{X}) \ge \theta] \ge 1 - \alpha\)</span> for all <span class="math inline">\(\theta \in \Theta\)</span>. Together these statistics form an interval <span class="math inline">\([\underline\theta(\mathbf{X}),\bar\theta(\mathbf{X})]\)</span> known as a level <span style="color:red"><strong><em>level <span class="math inline">\((1-\alpha)\)</span> confidence interval for <span class="math inline">\(\theta\)</span></em></strong></span> when <span class="math display">\[ \Pr[\underline\theta(\mathbf{X}) \le \theta \le \bar\theta(\mathbf{X})] \ge 1-\alpha\]</span> The <span style="color:red"><strong><em>confidence coefficient</em></strong></span> for a confidence interval is the largest possible confidence level given as <span class="math display">\[ \inf_{\theta \in \Theta}\{\Pr[\underline\theta(\mathbf{X}) \le \theta \le \bar\theta(\mathbf{X})]\}.\]</span> A confidence interval with confidence coefficient <span class="math inline">\(1-\alpha\)</span> is called a <span style="color:red"><strong><em><span class="math inline">\(100(1-\alpha)\)</span>% confidence interval</em></strong></span>.</p>
</div>
<p>The level of a confidence interval is not unique. If <span class="math inline">\(\Pr[\underline\theta(\mathbf{X}) \le \theta \le \bar\theta(\mathbf{X})] \ge 1-\alpha\)</span>, then <span class="math inline">\(\Pr[\underline\theta(\mathbf{X}) \le \theta \le \bar\theta(\mathbf{X})] \ge 1-\alpha'\)</span> for all <span class="math inline">\(\alpha'&gt;\alpha\)</span>, so a confidence interval of level <span class="math inline">\((1-\alpha)\)</span> will be a confidence interval of level <span class="math inline">\((1-\alpha')\)</span> for all <span class="math inline">\(\alpha'&gt;\alpha\)</span>. The confidence coefficient eliminates this ambiguity by taking the maximum level of confidence <span class="math inline">\((1-\alpha)\)</span>.</p>
<p>It’s important to emphasize that the probability <span class="math inline">\(\Pr[\underline\theta(\mathbf{X}) \le \theta \le \bar\theta(\mathbf{X})]\)</span> does <em>not</em> correspond to the probability that <span class="math inline">\(\theta\)</span> is contained in <span class="math inline">\([\underline\theta,\bar\theta]\)</span>. The parameter <span class="math inline">\(\theta\)</span> is a constant, and not a random variable. It is either in the interval or not. Instead <span class="math inline">\(\Pr[\underline\theta(\mathbf{X}) \le \theta \le \bar\theta(\mathbf{X})]\)</span> is related to the calculation of the statistics <span class="math inline">\(\underline\theta\)</span> and <span class="math inline">\(\bar\theta\)</span>, both of which are random variables. If we construct a 95% confidence interval for <span class="math inline">\(\theta\)</span>, then there is a 95% chance that the interval <span class="math inline">\([\underline\theta,\bar\theta]\)</span> contains <span class="math inline">\(\theta\)</span>, where probability is taken over all possible samples <span class="math inline">\(\mathbf{X}\)</span>.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.12</strong></span> Suppose we want to construct a confidence interval for <span class="math inline">\(\mu\)</span>, where <span class="math inline">\(X_i\overset{iid}{\sim}N(\mu,\sigma^2)\)</span> for an unknown <span class="math inline">\(\sigma\)</span>. In order to construct some confidence interval <span class="math inline">\([\underline\mu(\mathbf{X}),\bar \mu(\mathbf{X})]\)</span>, we need to define <span class="math inline">\(\underline\mu\)</span> and <span class="math inline">\(\bar \mu\)</span> such that we know their respective probability distributions, thereby allowing us to calculate <span class="math inline">\(\Pr[\underline\mu(\mathbf{X}) \le \mu \le \bar\mu(\mathbf{X})]\)</span>. One statistic for which we know the distribution is <span class="math inline">\(t = \frac{\bar X - \mu}{s/\sqrt n}\)</span>, as <span class="math inline">\(t \sim t_{n-1}\)</span>. The distribution <span class="math inline">\(t_{n-1}\)</span> is symmetric, so we can use the quantile function <span class="math inline">\(t_{n-1}^{-1}\)</span> to determine a confidence interval for <span class="math inline">\(t\)</span>. <span class="math display">\[\Pr[-t_{n-1}^{-1}(1-\alpha/2)\le t\le t_{n-1}^{-1}(1-\alpha/2)] = 1-\alpha \]</span> This is a key step in the direction of finding a confidence interval for <span class="math inline">\(\mu\)</span>, as <span class="math inline">\(t\)</span> is a function of <span class="math inline">\(\mu\)</span>. <span class="math display">\[\begin{align*}
&amp;\Pr[-t_{n-1}^{-1}(1-\alpha/2)\le t\le t_{n-1}^{-1}(1-\alpha/2)] = 1-\alpha \\
\implies &amp;\Pr\left[-t_{n-1}^{-1}(1-\alpha/2)\le \frac{\bar X - \mu}{s/\sqrt n}\le t_{n-1}^{-1}(1-\alpha/2)\right] = 1-\alpha \\
\implies &amp;\Pr\left[ \bar X - (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}} \le \mu \le \bar X + (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}}\right] = 1-\alpha
\end{align*}\]</span> Therefore we have a <span class="math inline">\((1-\alpha)\)</span> level confidence interval for <span class="math inline">\(\mu\)</span> in the form of <span class="math display">\[ \left[ \bar X - (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}} , \bar X + (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}}\right].\]</span> If we let <span class="math inline">\(\alpha = 0.05\)</span>, <span class="math inline">\(\mu = 0\)</span>, <span class="math inline">\(\sigma = 1\)</span>, and <span class="math inline">\(n = 10\)</span>, we can generate confidence intervals for a large number of simulated samples. About 95% of the constructed intervals will contain the true mean <span class="math inline">\(\mu = 0\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>confidence_interval <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, n, dist, dist_params, t){</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> <span class="fu">mean</span>(X) <span class="sc">-</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, n<span class="dv">-1</span>)<span class="sc">*</span>(<span class="fu">sd</span>(X)<span class="sc">/</span><span class="fu">sqrt</span>(n)),</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper =</span> <span class="fu">mean</span>(X) <span class="sc">+</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, n<span class="dv">-1</span>)<span class="sc">*</span>(<span class="fu">sd</span>(X)<span class="sc">/</span><span class="fu">sqrt</span>(n)),</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> alpha,</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">iter_num =</span> t</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>draw_confidence_intervals <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha, n, dist, dist_params){</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(confidence_interval, <span class="at">alpha =</span> alpha, <span class="at">n =</span> n, <span class="at">dist =</span> dist, <span class="at">dist_params =</span> dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">draw_confidence_intervals</span>(<span class="fl">1e5</span>, <span class="fl">0.05</span>, <span class="dv">10</span>, rnorm, <span class="fu">list</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob_contains =</span> <span class="fu">mean</span>((lower <span class="sc">&lt;=</span> <span class="dv">0</span>)<span class="sc">*</span>(<span class="dv">0</span> <span class="sc">&lt;=</span> upper)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
  prob_contains
          &lt;dbl&gt;
1         0.951</code></pre>
</div>
</div>
<p>Let’s plot 100 of our constructed 95% confidence intervals (drawn at random).</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">contains =</span> (lower <span class="sc">&lt;=</span> <span class="dv">0</span>)<span class="sc">*</span>(<span class="dv">0</span> <span class="sc">&lt;=</span> upper)) <span class="sc">%&gt;%</span> </span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(iter_num, <span class="at">color =</span> <span class="fu">as.factor</span>(contains))) <span class="sc">+</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper)) <span class="sc">+</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">color =</span> <span class="st">"Interval Contains   μ = 0:"</span>, <span class="at">x =</span> <span class="st">"Sample"</span>, <span class="at">y =</span> <span class="st">"Parameter Space"</span>) <span class="sc">+</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"green"</span>)) <span class="sc">+</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot316" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot316-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot316-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot316-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.16: 100 of the 10,000 simulated confidence intervals drawn at random. Approximately 5% of the 100 do not contain the true parameter value
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>We can also construct approximate confidence intervals using asymptotic theory. If we modified the previous example such that <span class="math inline">\(X_i\)</span> had some arbitrary distribution <span class="math inline">\(F_X\)</span> with mean <span class="math inline">\(\mu\)</span>, then <span class="math inline">\(t\overset{a}{\sim}t_{n-1}\)</span>, so <span class="math display">\[ \lim_{n\to\infty}\Pr\left[ \bar X - (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}} \le \mu \le \bar X + (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}}\right] = 1- \alpha. \]</span> In other words, for a sufficiently large <span class="math inline">\(n\)</span>, we will have <span class="math display">\[ \Pr\left[ \bar X - (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}} \le \mu \le \bar X + (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}}\right] \approx 1- \alpha.\]</span></p>
<p>The previous example also suggests that we may be able to use confidence intervals to test hypotheses. We derived an interval <span class="math inline">\([\underline\mu(\mathbf{X}),\bar \mu(\mathbf{X})]\)</span> such that <span class="math inline">\(\Pr(0 \notin [\underline\mu(\mathbf{X}),\bar \mu(\mathbf{X})]) = \alpha\)</span>. If we wanted to test <span class="math inline">\(H_0:\mu=0\)</span> versus <span class="math inline">\(H_1:\mu\neq0\)</span> with a significance level of <span class="math inline">\(\alpha\)</span>, then perhaps we define a decision rule <span class="math inline">\(\delta\)</span> such that we fail to reject <span class="math inline">\(H_0\)</span> if and only if <span class="math inline">\(\bar X\in[\underline\mu(\mathbf{X}),\bar \mu(\mathbf{X})]\)</span>. Not only does this work, but it highlights how confidence intervals and hypothesis tests are two sides of the same coin.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.2</strong></span> Suppose <span class="math inline">\(\delta(\mathbf{X})\)</span> is a decision rule with level <span class="math inline">\(\alpha\)</span> for the hypothesis <span class="math inline">\(H_0:\boldsymbol{\theta}= \boldsymbol{\theta}_0\)</span>. If <span class="math inline">\(A(\boldsymbol{\theta}_0)=\{\mathbf{x}\mid \delta(\mathbf{x}) = 0\}\)</span> is the set of observations for which we fail to reject <span class="math inline">\(H_0\)</span>, then the set <span class="math display">\[S(\mathbf{x}) = \{\boldsymbol{\theta}\mid \mathbf{x}\in A(\boldsymbol{\theta})\} \]</span> is a family of confidence intervals for <span class="math inline">\(\boldsymbol{\theta}\)</span> with level <span class="math inline">\(1-\alpha\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We’ve defined <span class="math inline">\(S(\mathbf{x})\)</span> such that <span class="math inline">\(\boldsymbol{\theta}\in S(\mathbf{x})\)</span> holds if and only if <span class="math inline">\(\mathbf{x}\in A(\boldsymbol{\theta})\)</span>, so <span class="math display">\[ \Pr[\boldsymbol{\theta}\in S(\mathbf{X})] = \Pr[\mathbf{X}\in A(\boldsymbol{\theta})] .\]</span> Since <span class="math inline">\(\delta\)</span> is a level <span class="math inline">\(\alpha\)</span> test, <span class="math inline">\(\Pr[\mathbf{X}\in A(\boldsymbol{\theta})] \ge 1-\alpha\)</span>, so <span class="math display">\[\Pr[\boldsymbol{\theta}\in S(\mathbf{X})] \ge 1-\alpha.\]</span></p>
</div>
</section>
<section id="wald-test-and-t-test" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="wald-test-and-t-test"><span class="header-section-number">3.6</span> Wald Test and t-Test</h2>
<p>While we’ve talked a fair amount about the properties tests can have, and considered very specific examples of tests, we have only defined one test in general – the likelihood ratio test given by Theorem @ref(thm:NPlemma). This test has appealing properties in finite samples, especially if @ref(thm:KR) holds. Unfortunately, the distribution of the test statistic in finite samples depends on the model which generates the data, so the likelihood ratio is not very robust. Instead, we will consider a large-sample alternative.</p>
<p>Suppose we are testing <span class="math inline">\(H_0: P_{\boldsymbol{\theta}} \in \mathcal P_0\)</span> versus <span class="math inline">\(H_1: P_{\boldsymbol{\theta}} \in \mathcal P_1\)</span> where <span class="math display">\[\begin{align*}
\mathcal P_0 = \{P_{\boldsymbol{\theta}}\in\mathcal P \mid \mathbf h(\boldsymbol{\theta}) = \mathbf 0\},\\
\mathcal P_1 = \{P_{\boldsymbol{\theta}}\in\mathcal P \mid \mathbf h(\boldsymbol{\theta}) \neq \mathbf 0\},
\end{align*}\]</span> for some function <span class="math inline">\(\mathbf h:\boldsymbol\Theta \to \mathbb R^q\)</span>. In other words, we are testing <span class="math inline">\(H_0:\mathbf h(\boldsymbol{\theta}) = \mathbf 0\)</span> versus <span class="math inline">\(H_1: \mathbf h(\boldsymbol{\theta}) \neq \mathbf 0\)</span>. See <span class="citation" data-cites="wolak1989local">Wolak (<a href="#ref-wolak1989local" role="doc-biblioref">1989</a>)</span> for the case where <span class="math inline">\(\mathbf h(\boldsymbol{\theta}) \ge \mathbf{0}\)</span> or <span class="math inline">\(\mathbf h(\boldsymbol{\theta}) \le \mathbf{0}\)</span>. The function <span class="math inline">\(\mathbf h:\boldsymbol\Theta \to \mathbb R^q\)</span> describes the <span class="math inline">\(q\)</span> relationships we are testing between the <span class="math inline">\(k=\dim(\boldsymbol\Theta)\)</span> components of <span class="math inline">\(\boldsymbol{\theta}= (\theta_1,\ldots,\theta_k)\)</span>. For example, if <span class="math inline">\(\boldsymbol\Theta = \mathbb R^4\)</span> and our null hypothesis was comprised of the following equations: <span class="math display">\[\begin{align*}
\theta_1 &amp;= 2\theta_3\\
\theta_2 &amp;= \theta_1\ln \theta_4\\
\theta_3 &amp;= 3
\end{align*}\]</span> then <span class="math inline">\(\mathbf h: \mathbb R^4 \to \mathbb R^3\)</span> is <span class="math display">\[ \mathbf h(\boldsymbol{\theta}) = \begin{bmatrix} \theta_1 - 2\theta_3\\ \theta_2 -\theta_1\ln \theta_4\\\theta_3-3\end{bmatrix}.\]</span> There are two special cases of hypotheses we should consider.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.13 (Linear Hypotheses)</strong></span> In the event our null hypothesis postulates that the components of <span class="math inline">\(\boldsymbol{\theta}\)</span> are linear combinations of each other, we can write <span class="math inline">\(\mathbf h(\boldsymbol{\theta}) = \mathbf H\boldsymbol{\theta}\)</span> for some <span class="math inline">\(q\times k\)</span> matrix of constants. <span class="math display">\[\begin{cases}\sum_{i=1}^k c_{1i}\theta_i = 0\\\ \ \ \ \ \ \ \ \ \vdots\\ \sum_{i=1}^k c_{qi}\theta_i = 0\end{cases} \implies \mathbf H = \begin{bmatrix} c_{11} &amp; \cdots &amp;c_{1k} \\ \vdots &amp; \ddots &amp; \vdots \\ c_{q1} &amp; \cdots &amp;c_{qk} \end{bmatrix}\]</span> Our null hypothesis is <span class="math inline">\(\mathbf H\boldsymbol{\theta}= \mathbf 0\)</span>.</p>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.14</strong></span> In many settings, the default null hypothesis considered is <span class="math inline">\(H_0:\boldsymbol{\theta}= \mathbf 0\)</span>. In this case, <span class="math inline">\(\mathbf h(\boldsymbol{\theta}) = \boldsymbol{\theta}\)</span>. If we are only interested in one parameter <span class="math inline">\(\theta_j\)</span>, then <span class="math inline">\(\mathbf h(\boldsymbol{\theta}) = \theta_j\)</span>.</p>
</div>
<p>In order to determine the asymptotic distribution of the test statistics prescribed by each test, we need to adopt a distributional assumption about our estimator.</p>
<div id="assone" class="exercise">
<p>We have an estimator <span class="math inline">\(\hat {\boldsymbol{\theta}}\)</span> satisfying <span class="math inline">\(\sqrt{n}(\hat{\boldsymbol{\theta}} - \boldsymbol{\theta}) \overset{d}{\to}N(\mathbf{0}, \mathbf V)\)</span> for a PSD matrix <span class="math inline">\(\mathbf V\)</span>. That is, <span class="math inline">\(\hat {\boldsymbol{\theta}}\)</span> is root-<span class="math inline">\(n\)</span> CAN and <span class="math inline">\(\hat  {\boldsymbol{\theta}}\overset{a}{\sim}N(\boldsymbol{\theta}, \mathbf V/n)\)</span> where <span class="math inline">\(\text{Avar}\left(\hat{\boldsymbol{\theta}}\right)= \mathbf V/n\)</span></p>
</div>
<p>We are making no assumptions about the distribution of <span class="math inline">\(\mathbf{X}\)</span>, the asymptotic distribution of <span class="math inline">\(\mathbf{X}\)</span>, or the distribution of <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>. We are only making an assumption about the asymptotic distribution of some <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>. Because of the LLN and CLT, this assumption turns out to be fairly weak, as nearly all common estimators are root-<span class="math inline">\(n\)</span> CAN.</p>
<p>The first test we consider will be the most familiar, and will not involve the likelihood function in our general setting. Suppose <span class="math inline">\(\theta\)</span> and <span class="math inline">\(h(\theta)=\theta_0\)</span> are scalars. If we want to test $h()=0 $, we may want to decide whether or not to reject the null hypothesis based on the discrepancy between <span class="math inline">\(h(\theta)\)</span> and <span class="math inline">\(h(\hat\theta)\)</span>. If the true parameter value is <span class="math inline">\(\theta_0\)</span>, then we would reject the null hypothesis if <span class="math inline">\(\hat\theta- \theta_0 \gg 0\)</span> or <span class="math inline">\(\hat\theta- \theta_0 \ll 0\)</span>. We can consider these cases simultaneously by rejecting the null hypothesis if <span class="math inline">\((\hat\theta-\theta_0)^2 \gg 0\)</span>. This is a bit ambiguous though, because it isn’t clear what distance <span class="math inline">\(\hat\theta- \theta_0\)</span> is surprising enough to merit rejecting the null hypothesis. Fortunately, we’ve assumed that <span class="math inline">\(\text{Avar}\left(\hat{\theta}\right)=  V/n\)</span> so we can standardize the distance using the standard deviation of <span class="math inline">\(\hat\theta\)</span>. This standard deviation has a special name.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.12</strong></span> The <span style="color:red"><strong><em>standard error</em></strong></span> of an estimator <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> is its standard deviation. <span class="math display">\[\text{se}\left(\hat{\boldsymbol{\theta}}\right)=\text{diag}\left[\text{Var}\left(\hat{\boldsymbol{\theta}}\right)\right]^{1/2} \]</span></p>
</div>
<p>Using the standard error we can measure the non-negative distance as <span class="math display">\[ \left(\frac{\hat\theta-\theta_0}{\text{se}\left(\hat{\theta}\right)}\right)^2 = \frac{(\hat\theta-\theta_0)^2}{\text{Var}\left(\hat\theta\right)}.\]</span> This still doesn’t do though, because we do not know <span class="math inline">\(\text{Var}\left(\hat\theta\right)\)</span>. Perhaps instead we can use <span class="math inline">\(\text{Avar}\left(\hat\theta\right)\)</span>, giving <span class="math display">\[ \frac{(\hat\theta-\theta_0)^2}{\text{Avar}\left(\hat\theta\right)} = \frac{(\hat\theta-\theta_0)^2}{V/n} .\]</span> Unfortunately, if <span class="math inline">\(\text{Avar}\left(\hat\theta\right)\)</span> is a function of <span class="math inline">\(\theta\)</span> (which is more often than not the case), then we must estimate <span class="math inline">\(\text{Avar}\left(\hat\theta\right)\)</span>, giving the statistic <span class="math display">\[ \frac{(\hat\theta-\theta_0)^2}{\widehat{\text{Avar}}(\hat\theta)} = \frac{(\hat\theta-\theta_0)^2}{\hat V/n}.\]</span> This should look <em>very familiar</em>. For example, if we have <span class="math inline">\(X_i\overset{iid}{\sim}N(\mu,\sigma^2)\)</span> and want to test <span class="math inline">\(H_0:\mu\neq \mu_0\)</span>, a situation where <span class="math inline">\(\sqrt n(\bar X-\mu_0) \overset{d}{\to}N(0,\sigma^2)\)</span> and <span class="math inline">\(\text{Avar}\left((\right)\bar X) = \sigma^2/n\)</span>, we have <span class="math display">\[ \frac{(\hat\theta-\theta_0)^2}{\widehat{\text{Avar}}(\hat\theta)} = \frac{(\bar X-\mu_0)^2}{\widehat{(\sigma^2/n)}} = \frac{(\bar X-\mu_0)^2}{S^2/n}.\]</span> This is just the squared test statistic for the <span class="math inline">\(t-\)</span>test! <span class="math display">\[ \left[\frac{(\bar X-\mu_0)^2}{S^2/n}\right]^{1/2} = \frac{\bar X -\mu_0}{S/\sqrt n}.\]</span> In the event we know <span class="math inline">\(\sigma^2\)</span>, we don’t even need to estimate <span class="math inline">\(\text{Avar}\left(\bar X\right)\)</span>, and this statistic becomes the squared version of test statistic from the <span class="math inline">\(z-\)</span>test. In general this test statistic simply reports how many estimated standard deviations <span class="math inline">\(\theta\)</span> is from <span class="math inline">\(\theta_0\)</span>, squared. This statistic is due to <span class="citation" data-cites="wald1943tests">Wald (<a href="#ref-wald1943tests" role="doc-biblioref">1943</a>)</span>, and we will now define it in higher dimensions for possibly nonlinear hypotheses.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.13</strong></span> Given the hypotheses <span class="math inline">\(H_0:\mathbf h(\boldsymbol{\theta}) = \mathbf 0\)</span> versus <span class="math inline">\(H_1: \mathbf h(\boldsymbol{\theta}) \neq \mathbf 0\)</span>, the <span style="color:red"><strong><em>Wald statistic</em></strong></span> is defined as <span class="math display">\[ W(\mathbf{X}) = \mathbf h(\hat{\boldsymbol{\theta}})'\left[\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})\widehat{\text{Avar}}(\hat{\boldsymbol{\theta}})\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})'\right]^{-1}\mathbf h(\hat{\boldsymbol{\theta}}).\]</span></p>
</div>
<p>While this looks fairly complex, the following example shows that it does indeed simplify to statistic we used to build intuition.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.15</strong></span> Suppose <span class="math inline">\(\dim(\boldsymbol\Theta)=1\)</span>, and <span class="math inline">\(h(\theta) = \theta - \theta_0\)</span>. The null hypothesis is <span class="math inline">\(H_0: \theta - \theta_0 = 0\)</span>, which is <span class="math inline">\(H_0: \theta  = \theta_0\)</span>. We have <span class="math display">\[\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}}) = \frac{\partial }{\partial \theta}[\theta - \theta_0]_{\theta=\hat\theta} = 1.\]</span> Because we have a single parameter, transposes are trivial: <span class="math display">\[\begin{align*}
\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})' &amp; = [1]' = 1 = \frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}}).\\
\mathbf h(\hat{\boldsymbol{\theta}})' &amp;= [\hat\theta - \theta_0]'=\hat\theta - \theta_0 = \mathbf h(\hat{\boldsymbol{\theta}}).
\end{align*}\]</span> Our statistic is <span class="math display">\[\begin{align*}
W &amp;= \mathbf h(\hat{\boldsymbol{\theta}})'\left[\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})\widehat{\text{Avar}}(\hat{\boldsymbol{\theta}})\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})'\right]^{-1}\mathbf h(\hat{\boldsymbol{\theta}})\\
&amp; = (\hat\theta - \theta_0)[1\cdot\widehat{\text{Avar}}(\hat{\theta})\cdot 1 ]^{-1}(\hat\theta - \theta_0)\\
&amp; = \frac{(\hat\theta - \theta_0)^2}{\widehat{\text{Avar}}(\hat{\theta})}
\end{align*}\]</span></p>
</div>
<p>To use the Wald statistic in a test, we need to be able to construct critical regions given a choice of size <span class="math inline">\(\alpha\)</span>. When <span class="math inline">\(n\)</span> is sufficiently large, this requires knowing the asymptotic distribution of <span class="math inline">\(W\)</span>. It’s possible to make an informed guess about this distribution if we think about the Wald statistic as a squared <span class="math inline">\(t-\)</span>statistic. We established that <span class="math display">\[ t = \frac{(\bar X-\mu_0)^2}{S^2/n} \overset{d}{\to}N(0,1).\]</span> If we apply the continuous mapping theorem to <span class="math inline">\(t^2 = W\)</span>, we have <span class="math display">\[ W = t^2 \overset{d}{\to}[N(0,1)]^2 = \chi^2_1.\]</span> Not only is <span class="math inline">\(W\)</span> asymptotically distributed according to a chi-square distribution in this simple setting, but it is in the general setting. The only thing we need to account for when showing this in higher dimensions is that we are testing <span class="math inline">\(q\)</span> one dimensional hypotheses simultaneously when <span class="math inline">\(\mathbf h:\boldsymbol \Theta \to \mathbb R^q\)</span>.</p>
<div id="quadchi" class="lemma">
<p>If <span class="math inline">\(\mathbf{x}\sim N(\mathbf{0},\mathbf I)\)</span> where <span class="math inline">\(\mathbf{x}= (x_1,\ldots,x_n)\)</span>, then <span class="math inline">\(\mathbf{x}'\mathbf{x}\sim \chi_n^2\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We have <span class="math inline">\(\mathbf{x}'\mathbf{x}= \sum_{i=1}^n x_i^2\)</span> where <span class="math inline">\(x_i\sim N(0,1)\)</span>, so <span class="math inline">\(\mathbf{x}'\mathbf{x}\)</span> is the sum of <span class="math inline">\(n\)</span> random variables with a standard normal distribution. This means <span class="math inline">\(\mathbf{x}'\mathbf{x}\sim \chi_n^2\)</span>.</p>
</div>
<div id="thm-wald" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.3</strong></span> Suppose:</p>
<ol type="1">
<li>Assumption @ref(exr:assone) holds;</li>
<li><span class="math inline">\(\mathbf h:\boldsymbol \Theta \to \mathbb R^q\)</span> is continuously differentiable on <span class="math inline">\(\boldsymbol\Theta\subset\mathbb R^k\)</span> and <span class="math inline">\(\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}\)</span> is invertible;</li>
<li><span class="math inline">\(\hat {\mathbf V}\)</span> is a consistent estimator for <span class="math inline">\(\mathbf V\)</span>;</li>
<li><span class="math inline">\(\boldsymbol{\theta}\)</span> is in the interior of <span class="math inline">\(\boldsymbol\Theta\)</span> .</li>
</ol>
<p>Then <span class="math inline">\(W \overset{d}{\to}\chi_q^2\)</span> under <span class="math inline">\(H_0\)</span>. As a result, the <span style="color:red"><strong><em>Wald test</em></strong></span> with size <span class="math inline">\(\alpha\)</span> takes the form <span class="math display">\[\delta(\mathbf{X}) = \begin{cases} \mathbf h(\boldsymbol{\theta}) = \mathbf{0}&amp; W &lt; (\chi_q^2)^{-1}(1-\alpha)\\
\mathbf h(\boldsymbol{\theta}) \neq \mathbf{0}&amp; W \ge (\chi_q^2)^{-1}(1-\alpha)\end{cases}.\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We are given that <span class="math inline">\(\sqrt{n}(\hat{\boldsymbol{\theta}} - \boldsymbol{\theta}) \overset{d}{\to}N(\mathbf{0}, \mathbf V)\)</span>. Under assumptions 2 and 4, we can apply the delta method as follows: <span class="math display">\[ \sqrt{n}(\mathbf h(\hat{\boldsymbol{\theta}}) - \mathbf h(\boldsymbol{\theta})) \overset{d}{\to}N\left(\mathbf{0}, \frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})\mathbf V\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})'\right).\]</span> We are assuming <span class="math inline">\(H_0\)</span> holds, so <span class="math inline">\(\mathbf h(\boldsymbol{\theta}) = \mathbf{0}\)</span>, giving <span class="math display">\[\begin{align*}
&amp;\sqrt{n}(\mathbf h(\hat{\boldsymbol{\theta}}) - \mathbf h(\boldsymbol{\theta})) \overset{d}{\to}N\left(\mathbf{0}, \frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})\mathbf V\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})'\right)\\
\implies &amp; \sqrt{n}\mathbf h(\hat{\boldsymbol{\theta}}) \overset{d}{\to}N\left(\mathbf{0}, \frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})\mathbf V\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})'\right)\\
\implies &amp; \left[\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})\mathbf V\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})'\right]^{-1/2}\sqrt{n}\mathbf h(\hat{\boldsymbol{\theta}}) \overset{d}{\to}N(\mathbf{0}, \mathbf I)
\end{align*}\]</span> Using the previous lemma we have <span class="math display">\[\begin{align*}
&amp;\sqrt{n}\mathbf h(\hat{\boldsymbol{\theta}})'\left[\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})\mathbf V\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})'\right]^{-1/2}\left[\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})\mathbf V\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})'\right]^{-1/2}\sqrt{n}\mathbf h(\hat{\boldsymbol{\theta}})\overset{d}{\to}\chi_q^2\\
\implies &amp;
n\mathbf h(\hat{\boldsymbol{\theta}})'\left[\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})\mathbf V\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})'\right]^{-1}\mathbf h(\hat{\boldsymbol{\theta}})\overset{d}{\to}\chi_q^2\\
\implies &amp; \mathbf h(\hat{\boldsymbol{\theta}})'\left[\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})(\mathbf V/n)\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})'\right]^{-1}\mathbf h(\hat{\boldsymbol{\theta}})\overset{d}{\to}\chi_q^2
\end{align*}\]</span> If we replace <span class="math inline">\(\mathbf V\)</span> with our estimator <span class="math inline">\(\hat {\mathbf V}\)</span> which satisfies <span class="math inline">\(\hat {\mathbf V}\overset{p}{\to}\mathbf V\)</span>, then we can apply Slutky’s theorem and conclude <span class="math display">\[\mathbf h(\hat{\boldsymbol{\theta}})'\left[\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})(\hat {\mathbf V}/n)\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})'\right]^{-1}\mathbf h(\hat{\boldsymbol{\theta}})\overset{d}{\to}\chi_q^2\]</span></p>
</div>
<p>The intuition behind the Wald test is identical to that of the <span class="math inline">\(z-\)</span>test, the <span class="math inline">\(t\)</span>-test, and many other familiar tests – we know the distribution of <span class="math inline">\(W(\mathbf{X})\)</span> under <span class="math inline">\(H_0\)</span>, so if we observe a value of <span class="math inline">\(W(\mathbf{x})\)</span> that is very unlikely then we should reject <span class="math inline">\(H_0\)</span>.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.16</strong></span> We can write a simple function which implements the Wald test.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>Wald_test <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, h, n, theta_hat, V_hat){</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#Calculate test stat</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  h_prime <span class="ot">&lt;-</span> <span class="fu">jacobian</span>(h, theta_hat)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  W <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">t</span>(<span class="fu">h</span>(theta_hat)) <span class="sc">%*%</span> <span class="fu">solve</span>(h_prime <span class="sc">%*%</span> (V_hat<span class="sc">/</span>n) <span class="sc">%*%</span> <span class="fu">t</span>(h_prime)) <span class="sc">%*%</span> <span class="fu">h</span>(theta_hat))</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#determine if we reject</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  dof <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">h</span>(theta_hat))</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  c <span class="ot">&lt;-</span> <span class="fu">qchisq</span>(<span class="dv">1</span> <span class="sc">-</span> alpha, dof)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>  reject <span class="ot">&lt;-</span> (W <span class="sc">&gt;=</span> c)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>  <span class="co">#Output information</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">statistic =</span> W,</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">critical_value =</span> c,</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> reject</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In order to calculate <span class="math inline">\(\frac{\partial \mathbf h}{\partial \boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})\)</span>, we made use of the <code>jacobian()</code> function from the <code>numDeriv</code> package instead of requiring an additional argument where we supply the calculated Jacobian. Let’s put our function to use. Suppose that <span class="math inline">\(\mathbf{X}\overset{iid}{\sim}N(\boldsymbol\mu, \boldsymbol\Sigma)\)</span> where <span class="math display">\[\begin{align*}
\boldsymbol\mu &amp;= \begin{bmatrix}2&amp;2&amp;2\end{bmatrix}',\\
\boldsymbol\Sigma&amp;= \begin{bmatrix}1&amp;0.4&amp;0.2\\0.4&amp; 2&amp; 0.1\\0.2&amp;0.1&amp;1 \end{bmatrix}.
\end{align*}\]</span> The sample mean satisfies <span class="math inline">\(\sqrt{n}(\bar {\mathbf{X}} - \boldsymbol\mu)\overset{d}{\to}N(\mathbf{0}, \mathbf V)\)</span> trivially, as <span class="math inline">\(\sqrt{n}(\bar {\mathbf{X}} - \boldsymbol\mu)\sim N(\mathbf{0}, \boldsymbol\Sigma)\)</span>. We can use the Wald test to test the hypothesis that <span class="math inline">\(\boldsymbol\mu = (2,2,2)\)</span> with <span class="math inline">\(\alpha = 0.05\)</span> and <span class="math inline">\(n = 100\)</span>. In this case we have <span class="math display">\[ \mathbf h(\boldsymbol\mu) = \begin{bmatrix} \mu_1 - 2\\ \mu_2 -2\\\mu_3-2\end{bmatrix}.\]</span> We do need a consistent estimate of <span class="math inline">\(\mathbf V = \boldsymbol \Sigma\)</span>, but the most intuitive candidate will do. The sample covariance, calculated using <code>cov()</code>, of our observed data is a consistent estimator of <span class="math inline">\(\boldsymbol \Sigma\)</span> just as the sample variance is a consistent estimator of the actual variance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>sim_wald <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, h, n, dist, dist_params, t){</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">Wald_test</span>(alpha, h, n, <span class="fu">colMeans</span>(X), <span class="fu">cov</span>(X)) <span class="sc">%&gt;%</span> </span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">iter_num =</span> t)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>draw_N_wald <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha, h, n, dist, dist_params){</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(sim_wald, <span class="at">alpha =</span> alpha, <span class="at">h =</span> h, <span class="at">n =</span> n, <span class="at">dist =</span> dist, <span class="at">dist_params =</span> dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="co">#Define hypothesis</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="cf">function</span>(t){</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(t[<span class="dv">1</span>], t[<span class="dv">2</span>], t[<span class="dv">3</span>]) <span class="sc">-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">draw_N_wald</span>(</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e5</span>,</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fl">0.05</span>, </span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">h =</span> h,</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="fl">1e3</span>, </span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist =</span> rmvnorm,</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist_params =</span> <span class="fu">list</span>(</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>      <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>), </span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>      <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,.<span class="dv">4</span>,.<span class="dv">2</span>,.<span class="dv">4</span>,<span class="dv">2</span>,.<span class="dv">1</span>,.<span class="dv">2</span>,.<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span> <span class="dv">3</span>)</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a><span class="co">#Should be ≈ 0.05</span></span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob_reject =</span> <span class="fu">mean</span>(decision))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
  prob_reject
        &lt;dbl&gt;
1      0.0517</code></pre>
</div>
</div>
<p>If we plot the test statistics from our 10,000 simulations, we can illustrate that <span class="math inline">\(W\overset{a}{\sim}\chi_3^2\)</span>.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(statistic)) <span class="sc">+</span> </span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">colour =</span> <span class="dv">1</span>, <span class="at">fill =</span> <span class="st">"white"</span>, <span class="at">bins =</span> <span class="dv">50</span>) <span class="sc">+</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlab</span>(<span class="st">"Simulated Wald Test Statistics"</span>) <span class="sc">+</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dchisq, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">df =</span> <span class="dv">3</span>), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>,<span class="dv">15</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot317" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot317-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot317-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot317-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.17: The hisotrgram of simulated wald test statistics (calculated using a sample size of 100) coincides with the asymptotic distribution given in Theorem 3.2
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>If we are only testing <span class="math inline">\(\theta_j = \theta_0\)</span> for one component of <span class="math inline">\(\boldsymbol{\theta}\)</span>, then we can use a general version of the <span class="math inline">\(t-\)</span>test, which is a modified Wald test.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.14</strong></span> Given the hypotheses <span class="math inline">\(H_0:\theta_j = \theta_{0}\)</span> versus <span class="math inline">\(H_1: \theta_j \neq \theta_{0}\)</span>, the <span style="color:red"><strong><em><span class="math inline">\(t-\)</span>statistic</em></strong></span> is defined as <span class="math display">\[ t = \frac{\hat\theta_j-\theta_0}{\widehat{\text{se}}(\hat\theta_j)} = [W(\mathbf{X})]^{1/2}.\]</span> Assuming @ref(exr:assone) holds, the <span style="color:red"><strong><em><span class="math inline">\(t-\)</span>test</em></strong></span> with size <span class="math inline">\(\alpha\)</span> takes the form <span class="math display">\[\delta(\mathbf{X}) = \begin{cases} \theta_j = \theta_0 &amp; \left\lvert t\right\rvert \ge t_{n-1}^{-1}(1-\alpha/2)\\
\theta_j \neq \theta_0 &amp; \left\lvert t\right\rvert &lt; t_{n-1}^{-1}(1-\alpha/2)\end{cases}.\]</span></p>
</div>
<p>Considering the <span class="math inline">\(t-\)</span>test in the broader context of the Wald test highlights an important distinction – there is a difference between the one hypothesis <span class="math inline">\(\boldsymbol{\theta}= \boldsymbol{\theta}_0\)</span>, and the separate hypotheses <span class="math inline">\(\theta_j = \theta_{0,j}\)</span> for <span class="math inline">\(j=1,\ldots,k\)</span>. The prior requires that <span class="math inline">\(\theta_j = \theta_{0,j}\)</span> for all <span class="math inline">\(j\)</span> <em>simultaneously</em>, while the latter hypotheses are completely independent. We can highlight this by comparing the <span class="math inline">\(t-\)</span>test and the Wald test.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.17 (t-test versus Wald test)</strong></span> We will start by writing a function which performs the <span class="math inline">\(t-\)</span>test just like we did with the Wald test.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>t_test <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, theta0, n, theta_hat, se_hat){</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#calculate test stat</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>  t <span class="ot">&lt;-</span> (theta_hat <span class="sc">-</span> theta0)<span class="sc">/</span>se_hat</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">#determine if we reject</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>  dof <span class="ot">&lt;-</span> n <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>  c <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="dv">1</span> <span class="sc">-</span> alpha<span class="sc">/</span><span class="dv">2</span>, dof)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>  reject <span class="ot">&lt;-</span> (<span class="fu">abs</span>(t) <span class="sc">&gt;=</span> c)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">#Output information</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">parameter =</span> <span class="fu">paste0</span>(<span class="st">"θ"</span>, <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(t)),</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">statistic =</span> t,</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">critical_value =</span> c,</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> reject</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As defined, the function is able to perform multiple <span class="math inline">\(t-\)</span>tests simultaneously. If we supply a matrix for <code>X</code> along with vectors for <code>theta0</code>, <code>theta_hat</code>, and <code>se_hat</code>, then<code>t</code> will be a vector and <code>decision</code> will record whether the components of <code>t</code> exceed the critical value.</p>
<p>To compare <code>t_test()</code> and <code>Wald_test()</code>, suppose <span class="math inline">\(\mathbf{X}\overset{iid}{\sim}N(\boldsymbol\mu, \boldsymbol\Sigma)\)</span> for <span class="math display">\[\begin{align*}
\boldsymbol\mu &amp;=/ \begin{bmatrix}0&amp;0.5\end{bmatrix}',\\
\boldsymbol\Sigma&amp;= \begin{bmatrix}1&amp;0\\0&amp;2 \end{bmatrix},
\end{align*}\]</span> and <span class="math inline">\(n=2\)</span>. We will test <span class="math inline">\(H_0:\boldsymbol\mu = \mathbf{0}\)</span> with <code>Wald_test()</code> and the separate hypotheses <span class="math inline">\(H_0:\mu_1 = 0\)</span> (which is true) and <span class="math inline">\(H_0:\mu_2 = 0\)</span>, all with <span class="math inline">\(\alpha = 0.05\)</span>. We should reject <span class="math inline">\(\mu_1 = 0\)</span> with an approximate probability <span class="math inline">\(\alpha\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>wald_vs_t <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, h, mu0, n, dist, dist_params, t){</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  t_test_results <span class="ot">&lt;-</span> <span class="fu">t_test</span>(alpha, mu0, n, <span class="fu">colMeans</span>(X), <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">var</span>(X)<span class="sc">/</span>n))) <span class="sc">%&gt;%</span> </span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">test =</span> <span class="st">"t-test"</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  wald_test_results <span class="ot">&lt;-</span> <span class="fu">Wald_test</span>(alpha, h, n, <span class="fu">colMeans</span>(X), <span class="fu">cov</span>(X)) <span class="sc">%&gt;%</span> </span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">parameter =</span> <span class="st">"θ"</span>,</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">test =</span> <span class="st">"Wald test"</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> t_test_results <span class="sc">%&gt;%</span> </span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>(wald_test_results) <span class="sc">%&gt;%</span> </span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">iter_num =</span> t)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>draw_N_wald_vs_t <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha, h, mu0, n, dist, dist_params){</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(wald_vs_t, <span class="at">alpha =</span> alpha, <span class="at">h =</span> h, <span class="at">mu0 =</span> mu0, <span class="at">n =</span> n, <span class="at">dist =</span> dist, <span class="at">dist_params =</span> dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>() </span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="cf">function</span>(t){</span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(t[<span class="dv">1</span>], t[<span class="dv">2</span>]) <span class="sc">-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">draw_N_wald_vs_t</span>(</span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e5</span>,</span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">h =</span> h,</span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu0 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span>,</span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist =</span> rmvnorm,</span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist_params =</span> <span class="fu">list</span>(</span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">mean =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>),</span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">sigma =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(test, parameter) <span class="sc">%&gt;%</span> </span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob_reject =</span> <span class="fu">mean</span>(decision)) <span class="sc">%&gt;%</span> </span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`summarise()` has grouped output by 'test'. You can override using the
`.groups` argument.</code></pre>
</div>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">test</th>
<th style="text-align: left;">parameter</th>
<th style="text-align: right;">prob_reject</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Wald test</td>
<td style="text-align: left;">θ</td>
<td style="text-align: right;">0.89695</td>
</tr>
<tr class="even">
<td style="text-align: left;">t-test</td>
<td style="text-align: left;">θ1</td>
<td style="text-align: right;">0.04834</td>
</tr>
<tr class="odd">
<td style="text-align: left;">t-test</td>
<td style="text-align: left;">θ2</td>
<td style="text-align: right;">0.93781</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We end up rejecting the null hypothesis <span class="math inline">\(H_0:\boldsymbol\mu = \mathbf{0}\)</span> less than the null hypothesis <span class="math inline">\(H_0:\mu_2 = 0\)</span>, as the Wald test also must incorporate evidence about <span class="math inline">\(\mu_1\)</span> in the form of <span class="math inline">\(\bar X_1\)</span>. A large value of <span class="math inline">\(\bar X_2\)</span> (which is sufficient to reject <span class="math inline">\(H_0:\mu_2 = 0\)</span> with the <span class="math inline">\(t-\)</span>test), is only one part of the story for the Wald test, as it also must consider <span class="math inline">\(\bar X_1\)</span>. That being said, <span class="math inline">\(\bar X_2\)</span> is usually <em>so large</em> that the Wald test will still reject <span class="math inline">\(H_0:\boldsymbol\mu = \mathbf{0}\)</span> even if <span class="math inline">\(\bar X_1\)</span> is not large enough for the <span class="math inline">\(t-\)</span>test to reject <span class="math inline">\(H_0:\mu_1= 0\)</span>. To see this, we can breakdown the simulated probabilities that we reject <span class="math inline">\(H_0:\mu_1= 0\)</span> and/or <span class="math inline">\(H_0:\mu_2 = 0\)</span>.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(test <span class="sc">==</span> <span class="st">"t-test"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    parameter,</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    decision,</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    iter_num</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(iter_num) <span class="sc">%&gt;%</span> </span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> parameter, <span class="at">values_from =</span> decision) <span class="sc">%&gt;%</span> </span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_count</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(θ1, θ2) <span class="sc">%&gt;%</span> </span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob =</span> <span class="fu">n</span>()<span class="sc">/</span><span class="fu">max</span>(n)) <span class="sc">%&gt;%</span> </span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(θ1) <span class="sc">%&gt;%</span> </span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> θ2, <span class="at">values_from =</span> prob) <span class="sc">%&gt;%</span> </span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at"> </span><span class="st">`</span> <span class="ot">=</span> <span class="dv">1</span>,</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">Fail to Reject θ2 = 0</span><span class="st">`</span> <span class="ot">=</span> <span class="dv">2</span>,</span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">Reject θ2 = 0</span><span class="st">`</span> <span class="ot">=</span> <span class="dv">3</span></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at"> </span><span class="st">`</span> <span class="ot">=</span> <span class="fu">ifelse</span>(<span class="st">`</span><span class="at"> </span><span class="st">`</span>, <span class="st">"Reject θ1 = 0"</span>, <span class="st">"Fail to Reject θ1 = 0"</span>)</span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>`summarise()` has grouped output by 'θ1'. You can override using the `.groups`
argument.</code></pre>
</div>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">Fail to Reject θ2 = 0</th>
<th style="text-align: right;">Reject θ2 = 0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Fail to Reject θ1 = 0</td>
<td style="text-align: right;">0.05919</td>
<td style="text-align: right;">0.89247</td>
</tr>
<tr class="even">
<td style="text-align: left;">Reject θ1 = 0</td>
<td style="text-align: right;">0.00300</td>
<td style="text-align: right;">0.04534</td>
</tr>
</tbody>
</table>
<p>The QQ-plot for the simulated distribution of the adjusted sample mean</p>
</div>
</div>
<p>We reject <span class="math inline">\(H_0:\mu_1= 0\)</span> and <span class="math inline">\(H_0:\mu_2 = 0\)</span> (simultaneously) with an approximate probability of <span class="math inline">\(0.047\)</span>, far less than that calculated using the Wald test. Why does this happen? For our example, we reject <span class="math inline">\(H_0:\boldsymbol\mu = \mathbf{0}\)</span> if <span class="math inline">\(W \ge (\chi_2^2)^{-1}(1-0.05) \approx 6\)</span>. We reject <span class="math inline">\(H_0:\mu_1 = 0\)</span> if <span class="math inline">\(|t_1| \ge  1.98\)</span> and <span class="math inline">\(H_0:\mu_2 = 0\)</span> if <span class="math inline">\(|t_2| \ge  1.98\)</span>. In terms of <span class="math inline">\(\bar X\)</span>, we reject <span class="math inline">\(H_0:\mu_1 = 0\)</span> if <span class="math display">\[\left\lvert\bar X_1\right\rvert \ge 0 + 1.98\cdot\widehat{\text{se}}(\bar X_1) \approx 1.98\cdot\text{se}(\bar X_1) = 1.98\cdot(1/\sqrt{ 100}) = 0.198,\]</span> and we reject <span class="math inline">\(H_0:\mu_2 = 0\)</span> if <span class="math display">\[\left\lvert\bar X_2\right\rvert \ge 0 + 1.98\cdot\widehat{\text{se}}(\bar X_2) \approx 1.98\cdot\text{se}(\bar X_1) = 1.98\cdot(2/\sqrt{ 100}) \approx 0.28.\]</span> Because the Wald statistic is a function of <span class="math inline">\(\bar X_1\)</span> and <span class="math inline">\(\bar X_2\)</span>, we can plot the values of <span class="math inline">\(W\)</span> over values of <span class="math inline">\(\{\bar X_1,\bar X_2\}\)</span> and compare this value to the rejection regions of the <span class="math inline">\(t-\)</span>tests.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span>.<span class="dv">40</span>, .<span class="dv">40</span>, <span class="at">length =</span> <span class="dv">500</span>),</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">seq</span>(<span class="sc">-</span>.<span class="dv">40</span>, .<span class="dv">40</span>, <span class="at">length =</span> <span class="dv">500</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map2_vec</span>(x, y, \(x, y) <span class="fu">Wald_test</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">h =</span> h, <span class="at">n =</span> <span class="dv">100</span>, <span class="at">theta_hat =</span> <span class="fu">c</span>(x, y), <span class="at">V_hat =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">2</span>)))</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>  )  <span class="sc">%&gt;%</span> </span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x, y, <span class="at">fill =</span> statistic)) <span class="sc">+</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>() <span class="sc">+</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_gradient2</span>(<span class="at">low =</span> <span class="st">"red"</span>, <span class="at">mid =</span> <span class="st">"white"</span>, <span class="at">high =</span> <span class="st">"green"</span>, <span class="at">midpoint =</span> <span class="fl">5.991465</span>) <span class="sc">+</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Estimate of μ1"</span>, <span class="at">y =</span> <span class="st">"Estimate of μ2"</span>, <span class="at">fill =</span> <span class="st">"Wald Statistic"</span>) <span class="sc">+</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">198</span>,.<span class="dv">198</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span>(<span class="fu">sqrt</span>(<span class="dv">2</span>)<span class="sc">/</span><span class="dv">10</span>)<span class="sc">*</span><span class="fl">1.98</span>,(<span class="fu">sqrt</span>(<span class="dv">2</span>)<span class="sc">/</span><span class="dv">10</span>)<span class="sc">*</span><span class="fl">1.98</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>) <span class="sc">+</span></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">label =</span> <span class="st">"Don't Reject μ1 = 0, Don't Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="sc">-</span>.<span class="dv">3</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Don't Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> .<span class="dv">3</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Don't Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> .<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Don't Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> <span class="sc">-</span>.<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Don't Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="sc">-</span>.<span class="dv">3</span>, <span class="at">y =</span> <span class="sc">-</span>.<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> .<span class="dv">3</span>, <span class="at">y =</span> .<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="sc">-</span>.<span class="dv">3</span>, <span class="at">y =</span> .<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> .<span class="dv">3</span>, <span class="at">y =</span> <span class="sc">-</span>.<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> (<span class="sc">-</span><span class="dv">4</span><span class="sc">:</span><span class="dv">4</span>)<span class="sc">/</span><span class="dv">10</span>, <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> (<span class="sc">-</span><span class="dv">4</span><span class="sc">:</span><span class="dv">4</span>)<span class="sc">/</span><span class="dv">10</span>, <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-plot318" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot318-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot318-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot318-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.18: The values of the Wald test statistic in relation to the decisions seperate t-tests make regarding the null hypotheses when considering each in one dimmension
</figcaption>
</figure>
</div>
</div>
</div>
<p>This illustrates that it’s possible to reject <span class="math inline">\(H_0:\boldsymbol\mu = \mathbf{0}\)</span> using the Wald test while not rejecting <span class="math inline">\(H_0:\mu_1 = 0\)</span> or not rejecting <span class="math inline">\(H_1:\mu_1 = 0\)</span>. On the other hand, if we reject <span class="math inline">\(H_0:\mu_1 = 0\)</span> and <span class="math inline">\(H_1:\mu_1 = 0\)</span> using separate <span class="math inline">\(t-\)</span>tests, we are guaranteed to reject <span class="math inline">\(H_0:\boldsymbol\mu = \mathbf{0}\)</span> using the Wald test. This plot omits an important consideration – the true distribution of <span class="math inline">\(\{\bar X_1,\bar X_2\}\)</span> which will determine how frequently our estimates fall in the various rejection regions.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Show code which generates figure</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span>.<span class="dv">35</span>, .<span class="dv">35</span>, <span class="at">length =</span> <span class="dv">500</span>),</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">seq</span>(<span class="sc">-</span>.<span class="dv">40</span>, <span class="dv">1</span>, <span class="at">length =</span> <span class="dv">500</span>)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map2_vec</span>(x, y, \(x, y) <span class="fu">Wald_test</span>(<span class="at">alpha =</span> <span class="fl">0.05</span>, <span class="at">h =</span> h, <span class="at">n =</span> <span class="dv">100</span>, <span class="at">theta_hat =</span> <span class="fu">c</span>(x, y), <span class="at">V_hat =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">2</span>))),</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">density =</span> <span class="fu">map2_dbl</span>(x, y, \(x, y) <span class="fu">dmvnorm</span>(<span class="fu">c</span>(x,y), <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), <span class="fu">sqrt</span>(<span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">2</span>))<span class="sc">/</span><span class="dv">10</span>)),</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> <span class="fu">ifelse</span>(decision, <span class="st">"Wald Test Rejects μ = 0"</span>, <span class="st">"Wald Test Fails to Reject μ = 0"</span>)</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x, y, <span class="at">fill =</span> density)) <span class="sc">+</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>() <span class="sc">+</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Estimate of μ1"</span>, <span class="at">y =</span> <span class="st">"Estimate of μ2"</span>, <span class="at">fill =</span> <span class="st">"Density"</span>) <span class="sc">+</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">198</span>,.<span class="dv">198</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span>(<span class="fu">sqrt</span>(<span class="dv">2</span>)<span class="sc">/</span><span class="dv">10</span>)<span class="sc">*</span><span class="fl">1.98</span>,(<span class="fu">sqrt</span>(<span class="dv">2</span>)<span class="sc">/</span><span class="dv">10</span>)<span class="sc">*</span><span class="fl">1.98</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>, <span class="at">panel.spacing.x =</span> <span class="fu">unit</span>(<span class="dv">2</span>, <span class="st">"lines"</span>)) <span class="sc">+</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_gradient</span>(<span class="at">low =</span> <span class="st">"white"</span>, <span class="at">high =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>decision) <span class="sc">+</span></span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> (<span class="sc">-</span><span class="dv">4</span><span class="sc">:</span><span class="dv">10</span>)<span class="sc">/</span><span class="dv">5</span>, <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> (<span class="sc">-</span><span class="dv">35</span><span class="sc">:</span><span class="dv">35</span>)<span class="sc">/</span><span class="dv">4</span>, <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-plot319" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot319-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="testing_files/figure-html/fig-plot319-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot319-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.19: The joint density of the sample means
</figcaption>
</figure>
</div>
</div>
</div>
<p>The majority of the density is concentrated in a region where the Wald test rejects <span class="math inline">\(H_0:\boldsymbol\mu = \mathbf{0}\)</span>, the <span class="math inline">\(t-\)</span>test does not reject <span class="math inline">\(H_0:\mu_1 = 0\)</span>, and the <span class="math inline">\(t-\)</span>test rejects <span class="math inline">\(H_0:\mu_2 = 0\)</span>. This is why our Wald test rejected <span class="math inline">\(H_0:\boldsymbol\mu = \mathbf{0}\)</span> so often, despite <span class="math inline">\(\mu_1 = 0\)</span> being true. Finally, note that we’ve assumed <span class="math inline">\(\text{Cov}\left(X_1,X_2\right) = 0\)</span>. In the event that <span class="math inline">\(\text{Cov}\left(X_1,X_2\right) \neq 0\)</span>, things become even more interesting, as the Wald test considers this covariance, whereas the <span class="math inline">\(t-\)</span>tests do not. If you play around with this example by changing <span class="math inline">\(\boldsymbol\Sigma =\text{Var}\left(\mathbf{X}\right)\)</span>, the elliptical rejection region of the Wald test will rotate/shrink/expand, thereby affecting how its results relate to those of the separate <span class="math inline">\(t-\)</span>tests.</p>
</div>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bickel2015mathematical" class="csl-entry" role="listitem">
Bickel, Peter J, and Kjell A Doksum. 2015. <em>Mathematical Statistics: Basic Ideas and Selected Topics, Volume i</em>. 2nd ed. CRC Press.
</div>
<div id="ref-casella2021statistical" class="csl-entry" role="listitem">
Casella, George, and Roger L Berger. 2021. <em>Statistical Inference</em>. Cengage Learning.
</div>
<div id="ref-degroot2012probability" class="csl-entry" role="listitem">
DeGroot, Morris H, and Mark J Schervish. 2012. <em>Probability and Statistics</em>. Pearson Education.
</div>
<div id="ref-lehmann1993fisher" class="csl-entry" role="listitem">
Lehmann. 1993. <span>“The Fisher, Neyman-Pearson Theories of Testing Hypotheses: One Theory or Two?”</span> <em>Journal of the American Statistical Association</em> 88 (424): 1242–49.
</div>
<div id="ref-lehmann2011fisher" class="csl-entry" role="listitem">
———. 2011. <em>Fisher, Neyman, and the Creation of Classical Statistics</em>. Springer Science &amp; Business Media.
</div>
<div id="ref-neyman1933" class="csl-entry" role="listitem">
Neyman, Jerzy, and Egon Sharpe Pearson. 1933. <span>“On the Problem of the Most Efficient Tests of Statistical Hypotheses.”</span> <em>Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character</em> 231 (694-706): 289–337.
</div>
<div id="ref-lehmann2005testing" class="csl-entry" role="listitem">
Romano, Joseph P, and EL Lehmann. 2005. <em>Testing Statistical Hypotheses</em>. Vol. 3. Springer.
</div>
<div id="ref-wald1943tests" class="csl-entry" role="listitem">
Wald, Abraham. 1943. <span>“Tests of Statistical Hypotheses Concerning Several Parameters When the Number of Observations Is Large.”</span> <em>Transactions of the American Mathematical Society</em> 54 (3): 426–82.
</div>
<div id="ref-wolak1989local" class="csl-entry" role="listitem">
Wolak, Frank A. 1989. <span>“Local and Global Testing of Linear and Nonlinear Inequality Constraints in Nonlinear Econometric Models.”</span> <em>Econometric Theory</em> 5 (1): 1–35.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>That is <span class="math inline">\(\mathcal P = \mathcal P_0 \cup \mathcal P_1\)</span> and <span class="math inline">\(\mathcal P_0 \cap \mathcal P_1 = \emptyset\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In order to keep this problem a bit more general and avoid defining an explicit <span class="math inline">\(\mu_0\)</span>, we express <span class="math inline">\(\mu\)</span> in terms of its standardized distance from <span class="math inline">\(\mu_0\)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>This requires us to reparameterize the domain of the theoretical curve in terms of <span class="math inline">\(\mu\)</span> instead of <span class="math inline">\(t\)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>How is this WLOG? If <span class="math inline">\(\delta(\mathbf{X}) = 1[T(\mathbf{X}) \in C]\)</span>, we can always write it as <span class="math inline">\(\delta(\mathbf{X}) = 1[\mathbf{X}\in T^{-1}(C)]\)</span> where <span class="math inline">\(T^{-1}\)</span> is the preimage of the test statistic. This is convenient for two reasons. Firstly we’re comparing arbitrary elements from an infinite set of decision rules <span class="math inline">\(\mathcal D\)</span>, so it’s much easier just to assume they both have the trivial test statistic <span class="math inline">\(T(\mathbf{X})=\mathbf{X}\)</span>, because in this case decision rules are determined only by critical regions. Comparing decision rules now amounts to comparing critical regions. Secondly, we’ll want to calculate the probability of errors, which requires us to know the distribution of <span class="math inline">\(T(\mathbf{X})\)</span>. If <span class="math inline">\(T(\mathbf{X}) = \mathbf{X}\)</span>, then we have <span class="math inline">\(T(\mathbf{X}) \sim F_\mathbf{X}(\mathbf{x}\mid \boldsymbol{\theta})\)</span> where <span class="math inline">\(\boldsymbol{\theta}\in \{\boldsymbol{\theta}_1, \boldsymbol{\theta}_2\}\)</span>. We know this distribution, so we can easily calculate the probability of errors. The proof is exactly the same without taking this step, but it looks a bit gnarlier with the additional notation.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Recall that $f(x)g(x)&nbsp;dx M f(x) $ if <span class="math inline">\(g(x)\le M\)</span> on the domain of integration.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>For the measure theory fans, this equality holds with measure zero, so we can just sweep it under the rug.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>This follows from the definition of the student’s <span class="math inline">\(t\)</span>-distribution.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./asymptotics.html" class="pagination-link" aria-label="Asymptotic Properties of Estimators">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Asymptotic Properties of Estimators</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./exp_fam.html" class="pagination-link" aria-label="Exponential Families">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Exponential Families</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb49" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>\DeclareMathOperator{\plim}{plim}</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>\DeclareMathOperator{\argmin}{argmin}</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>\DeclareMathOperator{\argmax}{argmax}</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>\newcommand{\var}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\text{Var}\left(#1\right)}</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>\newcommand{\avar}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\text{Avar}\left(#1\right)}</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>\newcommand{\E}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\text{E}\left<span class="co">[</span><span class="ot">#1\right</span><span class="co">]</span>}</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>\newcommand{\cov}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\text{Cov}\left(#1\right)}</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>\newcommand{\mse}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\text{MSE}\left(#1\right)}</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>\newcommand{\se}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\text{se}\left(#1\right)}</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>\newcommand{\limfunc}{lim} </span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>\newcommand{\X}{\mathbf{X}}</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>\newcommand{\Xm}{\mathbb{X}}</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>\newcommand{\EER}{\bar{\thet}_\text{EE}}</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>\newcommand{\NLS}{\hat{\bet}_\text{NLLS}}</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>\newcommand{\z}{\mathbf{z}}</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>\newcommand{\rr}{\mathbf{r}}</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>\newcommand{\C}{\mathbf{C}}</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>\newcommand{\Pe}{\mathbf{P}}</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>\newcommand{\y}{\mathbf{y}}</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>\newcommand{\Y}{\mathbf{Y}}</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>\newcommand{\uu}{\mathbf{u}}</span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a>\newcommand{\e}{\mathbf{e}}</span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>\newcommand{\D}{\mathbf{D}}</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>\newcommand{\x}{\mathbf{x}}</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a>\newcommand{\xm}{\mathbb{x}}</span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a>\newcommand{\Zm}{\mathbb{Z}}</span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a>\newcommand{\Wm}{\mathbb{W}}</span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>\newcommand{\Hm}{\mathbb{H}}</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>\newcommand{\W}{\mathbf{W}}</span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a>\newcommand{\Z}{\mathbf{Z}}</span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a>\newcommand{\Hess}{\mathbf{H}(\mathbf{\Z\mid\thet})}</span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a>\newcommand{\Score}{\mathbf{S}(\mathbf{\Z\mid\thet})}</span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a>\newcommand{\A}{\mathbf{A}}</span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a>\newcommand{\h}{\mathbf{h}}</span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a>\newcommand{\Q}{\mathbf{Q}}</span>
<span id="cb49-36"><a href="#cb49-36" aria-hidden="true" tabindex="-1"></a>\newcommand{\F}{\mathbf{F}}</span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a>\newcommand{\G}{\mathbf{G}}</span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a>\newcommand{\I}{\mathbf{I}}</span>
<span id="cb49-39"><a href="#cb49-39" aria-hidden="true" tabindex="-1"></a>\renewcommand{\D}{\mathbf{D}}</span>
<span id="cb49-40"><a href="#cb49-40" aria-hidden="true" tabindex="-1"></a>\renewcommand{\C}{\mathbf{C}}</span>
<span id="cb49-41"><a href="#cb49-41" aria-hidden="true" tabindex="-1"></a>\newcommand{\zer}{\mathbf{0}}</span>
<span id="cb49-42"><a href="#cb49-42" aria-hidden="true" tabindex="-1"></a>\newcommand{\OLS}{\hat{\boldsymbol\beta}_\text{OLS} }</span>
<span id="cb49-43"><a href="#cb49-43" aria-hidden="true" tabindex="-1"></a>\newcommand{\OLSOV}{\hat{\boldsymbol\beta}_\text{OLS,OV} }</span>
<span id="cb49-44"><a href="#cb49-44" aria-hidden="true" tabindex="-1"></a>\newcommand{\OLSME}{\hat{\boldsymbol\beta}_\text{OLS,ME} }</span>
<span id="cb49-45"><a href="#cb49-45" aria-hidden="true" tabindex="-1"></a>\newcommand{\EE}{\hat{\boldsymbol\theta}_\text{EX} }</span>
<span id="cb49-46"><a href="#cb49-46" aria-hidden="true" tabindex="-1"></a>\newcommand{\ME}{\hat{\boldsymbol\theta}_\text{M} }</span>
<span id="cb49-47"><a href="#cb49-47" aria-hidden="true" tabindex="-1"></a>\newcommand{\MDE}{\hat{\boldsymbol\theta}_\text{MDE} }</span>
<span id="cb49-48"><a href="#cb49-48" aria-hidden="true" tabindex="-1"></a>\newcommand{\IV}{\hat{\boldsymbol\beta}_\text{IV} }</span>
<span id="cb49-49"><a href="#cb49-49" aria-hidden="true" tabindex="-1"></a>\newcommand{\TSLS}{\hat{\boldsymbol\beta}_\text{2SLS} }</span>
<span id="cb49-50"><a href="#cb49-50" aria-hidden="true" tabindex="-1"></a>\newcommand{\thet}{\boldsymbol{\theta}}</span>
<span id="cb49-51"><a href="#cb49-51" aria-hidden="true" tabindex="-1"></a>\newcommand{\et}{\boldsymbol{\eta}}</span>
<span id="cb49-52"><a href="#cb49-52" aria-hidden="true" tabindex="-1"></a>\newcommand{\R}{\mathbb{R}}</span>
<span id="cb49-53"><a href="#cb49-53" aria-hidden="true" tabindex="-1"></a>\newcommand{\Sig}{\boldsymbol{\Sigma}}</span>
<span id="cb49-54"><a href="#cb49-54" aria-hidden="true" tabindex="-1"></a>\newcommand{\ep}{\boldsymbol{\varepsilon}}</span>
<span id="cb49-55"><a href="#cb49-55" aria-hidden="true" tabindex="-1"></a>\newcommand{\Omeg}{\boldsymbol{\Omega}}</span>
<span id="cb49-56"><a href="#cb49-56" aria-hidden="true" tabindex="-1"></a>\newcommand{\Thet}{\boldsymbol{\Theta}}</span>
<span id="cb49-57"><a href="#cb49-57" aria-hidden="true" tabindex="-1"></a>\newcommand{\bet}{\boldsymbol{\beta}}</span>
<span id="cb49-58"><a href="#cb49-58" aria-hidden="true" tabindex="-1"></a>\newcommand{\rk}{rank}</span>
<span id="cb49-59"><a href="#cb49-59" aria-hidden="true" tabindex="-1"></a>\newcommand{\tsum}{\sum}</span>
<span id="cb49-60"><a href="#cb49-60" aria-hidden="true" tabindex="-1"></a>\newcommand{\tr}{tr}</span>
<span id="cb49-61"><a href="#cb49-61" aria-hidden="true" tabindex="-1"></a>\newcommand{\norm}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\left\lVert#1\right\rVert}</span>
<span id="cb49-62"><a href="#cb49-62" aria-hidden="true" tabindex="-1"></a>\newcommand{\abs}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\left\lvert#1\right\rvert}</span>
<span id="cb49-63"><a href="#cb49-63" aria-hidden="true" tabindex="-1"></a>\newcommand{\ms}{\overset{ms}{\to}}</span>
<span id="cb49-64"><a href="#cb49-64" aria-hidden="true" tabindex="-1"></a>\newcommand{\pto}{\overset{p}{\to}}</span>
<span id="cb49-65"><a href="#cb49-65" aria-hidden="true" tabindex="-1"></a>\newcommand{\iid}{\overset{iid}{\sim}}</span>
<span id="cb49-66"><a href="#cb49-66" aria-hidden="true" tabindex="-1"></a>\newcommand{\dto}{\overset{d}{\to}}</span>
<span id="cb49-67"><a href="#cb49-67" aria-hidden="true" tabindex="-1"></a>\newcommand{\asim}{\overset{a}{\sim}}</span>
<span id="cb49-68"><a href="#cb49-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-69"><a href="#cb49-69" aria-hidden="true" tabindex="-1"></a><span class="fu"># Hypothesis Testing {#sec-testing}</span></span>
<span id="cb49-70"><a href="#cb49-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-73"><a href="#cb49-73" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-74"><a href="#cb49-74" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-75"><a href="#cb49-75" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb49-76"><a href="#cb49-76" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb49-77"><a href="#cb49-77" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mvtnorm)</span>
<span id="cb49-78"><a href="#cb49-78" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(numDeriv)</span>
<span id="cb49-79"><a href="#cb49-79" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gganimate)</span>
<span id="cb49-80"><a href="#cb49-80" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-81"><a href="#cb49-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-82"><a href="#cb49-82" aria-hidden="true" tabindex="-1"></a>Until now, we've focused on point estimation, but that's only half the picture when it comes to statistics. The other half is inference. How do we test hypotheses about the true $\thet_0$, and make inferences about the underling data generating process $P_{\thet_0}\in \mathcal P$? An exhaustive treatment of inference is due to @lehmann2005testing, while @bickel2015mathematical offer an equally technical, yet briefer, treatment. </span>
<span id="cb49-83"><a href="#cb49-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-84"><a href="#cb49-84" aria-hidden="true" tabindex="-1"></a><span class="fu">## Decision Theory</span></span>
<span id="cb49-85"><a href="#cb49-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-86"><a href="#cb49-86" aria-hidden="true" tabindex="-1"></a>In @sec-est we defined a (point) estimator as a function from a sample space $\mathcal X$ to the parameter space $\Theta$. For some specified model $\mathcal P$, we observe a realization of the random vector $\X\sim P_{\thet_0}$ for $P_{\thet_0}\in \mathcal P$, and then calculate an estimate $\hat{\thet}$. This process is a special case of a more general framework that unifies point estimation and hypothesis testing. </span>
<span id="cb49-87"><a href="#cb49-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-88"><a href="#cb49-88" aria-hidden="true" tabindex="-1"></a>Consider an **_action space_** $\mathcal A$. A **_decision process/rule_** $\delta:\mathcal X\to \mathcal A$ prescribes an action given an observation of a random vector $\X$ defined on $\mathcal X$. The set of all decision rules is $\mathcal D$. If the true data generating process is $P_\thet\in\mathcal P$, the cost of taking the action $a$ is given by the **_loss function_** $l(P_\thet, a)$ where $l:\mathcal P\times \mathcal A\to\mathbb R^+$. The loss associated with a decision rule is $l(P_\thet, \delta(\X))$. We cannot calculate this loss, as we do not know $P_\thet$. Instead we average the loss over $\Theta$ (which is the same as over all $P_\theta$ if $\mathcal P$ is identified), giving a **_risk function_** $R:\mathcal P\to \mathbb R^+$ defined as $\E{l(P_\thet, \delta(\X))}$. </span>
<span id="cb49-89"><a href="#cb49-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-90"><a href="#cb49-90" aria-hidden="true" tabindex="-1"></a>:::{#exm- name="Point Estimation"}</span>
<span id="cb49-91"><a href="#cb49-91" aria-hidden="true" tabindex="-1"></a>In the case of Section @sec-est, we took $\mathcal A = \Theta$. Our space of actions where simply parameter values. We also defined a quadratic loss function which resulted in the risk function taking the form of the MSE of an estimator.</span>
<span id="cb49-92"><a href="#cb49-92" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-93"><a href="#cb49-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-94"><a href="#cb49-94" aria-hidden="true" tabindex="-1"></a>We can also define hypothesis testing using decision theory. </span>
<span id="cb49-95"><a href="#cb49-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-96"><a href="#cb49-96" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-97"><a href="#cb49-97" aria-hidden="true" tabindex="-1"></a>Let $\mathcal X$ and $\mathcal P$ be the sample space and model, respectively, and partition $\mathcal P$ into $\mathcal P_0$ and $\mathcal P_1$.^<span class="co">[</span><span class="ot">That is $\mathcal P = \mathcal P_0 \cup \mathcal P_1$ and $\mathcal P_0 \cap \mathcal P_1 = \emptyset$.</span><span class="co">]</span> A &lt;span style="color:red"&gt;**_test function_**&lt;/span&gt; is a decision rule defined on $\mathcal A =\{\mathcal P_0,\mathcal P_1\}$ given as $$\delta(\X) = \begin{cases}\mathcal P_1 &amp; T(\X) \in C \\ \mathcal P_0 &amp; T(\X)\notin C\end{cases}$$ for some &lt;span style="color:red"&gt;**_critical region_**&lt;/span&gt; $C\subseteq \mathcal X$ and &lt;span style="color:red"&gt;**_test statistic_**&lt;/span&gt; $T:\mathcal X\to\mathcal X$.</span>
<span id="cb49-98"><a href="#cb49-98" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-99"><a href="#cb49-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-100"><a href="#cb49-100" aria-hidden="true" tabindex="-1"></a>Of the set of models $\mathcal P_0$ and $\mathcal P_1$, one is often easier to specify. For example, suppose $\X = (X_1,\ldots,X_n)$ captures the effectiveness of a drug on a series of patients $i=1,\ldots,n$, and $\X\sim P_\thet\in \mathcal P$. If we want to test whether this drug has an effect on patients' health, then we want to partition $\mathcal P$ into two groups: one group corresponding to the drug having no effect, and one where the drug has an effect. It's *much* easier to specify the models which correspond to no effect than the models that correspond to the drug having an effect, as there are nearly infinite possibilities when it comes to the type and degree of effectiveness. The easier of the two groups to specify is traditionally denoted $\mathcal P_0$, and is often associated with some well formed **_(null) hypothesis_**. This hypothesis is often written as $H_0:P_\theta\in \mathcal P_0$. Our decision $\delta(\X)$ prescribed whether we **_fail to reject/reject_** $H_0:P_\thet\in\mathcal P_0$. If we reject of the hypothesis $H_0:P_\thet \in\mathcal P_0$, we conclude that $P_\thet$ belongs to the **_class of alternative_** $H_1:P_\thet \in \mathcal P_1$. We often think of $H_0:P_\thet \in\mathcal P_0$ as a statement we assume to be true, with the burden of proof being on $H_1:P_\thet \in \mathcal P_1$.  </span>
<span id="cb49-101"><a href="#cb49-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-102"><a href="#cb49-102" aria-hidden="true" tabindex="-1"></a>::: {.hypothesis name="Different Conventions"}</span>
<span id="cb49-103"><a href="#cb49-103" aria-hidden="true" tabindex="-1"></a>There exist two other popular ways of writing the decision problem associated with testing a hypothesis:</span>
<span id="cb49-104"><a href="#cb49-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-105"><a href="#cb49-105" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Assuming $\mathcal P$ is identified and each $P_\thet$ is uniquely determined by a $\thet \in \Theta$, then we can partition $\Theta$ into $\Theta_1$ and $\Theta_0$, and define </span>
<span id="cb49-106"><a href="#cb49-106" aria-hidden="true" tabindex="-1"></a>$\delta(\X) = \begin{cases}\Theta_1 &amp; T(\X) \in C <span class="sc">\\</span> \Theta_0 &amp; T(\X)\notin C\end{cases},$  where $\mathcal A = <span class="sc">\{</span>\Theta_0, \Theta_1<span class="sc">\}</span>$ The hypothesis and class of alternatives are now written as $H_0: \thet \in\Theta_0$ and $H_1: \thet \in\Theta_1$, respectively.</span>
<span id="cb49-107"><a href="#cb49-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-108"><a href="#cb49-108" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>We could define $\mathcal A = <span class="sc">\{</span>0,1<span class="sc">\}</span>$, where $1$ corresponds to rejecting $H_0:P_\thet \in\mathcal P_0$ and $0$ failing to reject $H_0:P_\thet \in\mathcal P_0$.  </span>
<span id="cb49-109"><a href="#cb49-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-110"><a href="#cb49-110" aria-hidden="true" tabindex="-1"></a>Virtually all concrete examples of hypothesis test use notation similar to 1. </span>
<span id="cb49-111"><a href="#cb49-111" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-112"><a href="#cb49-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-113"><a href="#cb49-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-114"><a href="#cb49-114" aria-hidden="true" tabindex="-1"></a>:::{#exm-normtest}</span>
<span id="cb49-115"><a href="#cb49-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-116"><a href="#cb49-116" aria-hidden="true" tabindex="-1"></a><span class="fu">## One-Sided Z-Test</span></span>
<span id="cb49-117"><a href="#cb49-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-118"><a href="#cb49-118" aria-hidden="true" tabindex="-1"></a>Suppose $\mathcal P$ is the collection of normal distributions with known variance $\sigma^2$. This model is parameterized by mean $\mu$. We want to test the following hypothesis:</span>
<span id="cb49-119"><a href="#cb49-119" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-120"><a href="#cb49-120" aria-hidden="true" tabindex="-1"></a>H_0:&amp;\mu \le \mu_0<span class="sc">\\</span></span>
<span id="cb49-121"><a href="#cb49-121" aria-hidden="true" tabindex="-1"></a>H_1:&amp;\mu &gt; \mu_0</span>
<span id="cb49-122"><a href="#cb49-122" aria-hidden="true" tabindex="-1"></a>\end{align*} In this case, the null hypothesis is often abbreviated as $H_0: \mu = \mu_0$. Our hypothesis has partitions our parameter space $\Theta = \mathbb R$ into $\Theta_0 = (-\infty,\mu_0]$ and $\Theta_1 = (\mu_0,\infty)$. Define a statistic $$T(\X) = \frac{\bar X - \mu_0}{\sigma/\sqrt n} = \frac{\frac{1}{n}\sum_{i=1}^nX_i - \mu_0}{\sigma/\sqrt n},$$ and a critical region $C = [1.645,\infty)$. Our decision rule $\delta$ takes the form </span>
<span id="cb49-123"><a href="#cb49-123" aria-hidden="true" tabindex="-1"></a>$$\delta(\X) = \begin{cases} (-\infty,\mu_0] &amp; T(\X) &lt; 1.645 <span class="sc">\\</span> (\mu_0,\infty) &amp; T(\X) \ge 1.645 \end{cases},$$ which is  written succinctly as $\delta(\X) = I<span class="co">[</span><span class="ot">T(\X) \ge 1.645 </span><span class="co">]</span>$ if we take $\mathcal A = <span class="sc">\{</span>0,1<span class="sc">\}</span>$</span>
<span id="cb49-124"><a href="#cb49-124" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb49-125"><a href="#cb49-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-126"><a href="#cb49-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-127"><a href="#cb49-127" aria-hidden="true" tabindex="-1"></a>The binary nature of hypothesis testing makes defining a loss function quite simple. Our decision is either correct or incorrect. We can take the loss function to be 0 if we are correct, and 1 if we are incorrect.</span>
<span id="cb49-128"><a href="#cb49-128" aria-hidden="true" tabindex="-1"></a>$$l(P_\theta, \delta(\X))=\begin{cases}1 &amp; \delta(\X) = \mathcal P_0 \text{ and }P_\thet\in\mathcal P_0 <span class="sc">\\</span></span>
<span id="cb49-129"><a href="#cb49-129" aria-hidden="true" tabindex="-1"></a>0 &amp; \delta(\X) = \mathcal P_1 \text{ and }P_\thet\in\mathcal P_0<span class="sc">\\</span></span>
<span id="cb49-130"><a href="#cb49-130" aria-hidden="true" tabindex="-1"></a>1 &amp; \delta(\X) = \mathcal P_1 \text{ and }P_\thet\in\mathcal P_1<span class="sc">\\</span></span>
<span id="cb49-131"><a href="#cb49-131" aria-hidden="true" tabindex="-1"></a>0 &amp; \delta(\X) = \mathcal P_0 \text{ and }P_\thet\in\mathcal P_1\end{cases}$$</span>
<span id="cb49-132"><a href="#cb49-132" aria-hidden="true" tabindex="-1"></a>The associated risk function becomes </span>
<span id="cb49-133"><a href="#cb49-133" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-134"><a href="#cb49-134" aria-hidden="true" tabindex="-1"></a>R(P_\thet, \delta(\X)) &amp; = \E{l(P_\theta, \delta(\X))} = l(P_\theta, \mathcal P_0)\cdot \Pr(\delta(\X) = \mathcal P_0) +l(P_\theta, \mathcal P_1)\cdot \Pr(\delta(\X) = \mathcal P_1).</span>
<span id="cb49-135"><a href="#cb49-135" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-136"><a href="#cb49-136" aria-hidden="true" tabindex="-1"></a>We can simplify $R(P_\thet, \delta(\X))$ if we condition one either $P_\theta \in \mathcal P_0$, or $P_\theta \in \mathcal P_1$.</span>
<span id="cb49-137"><a href="#cb49-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-138"><a href="#cb49-138" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-139"><a href="#cb49-139" aria-hidden="true" tabindex="-1"></a>R(P_\thet, \delta(\X) \mid P_\thet\in\mathcal P_0)&amp; =  \underbrace{l(P_\theta, \mathcal P_0)}_0\cdot \Pr(\delta(\X) = \mathcal P_0 \mid P_\thet\in\mathcal P_0) +\underbrace{l(P_\theta, \mathcal P_1)}_1\cdot \Pr(\delta(\X) = \mathcal P_1 \mid P_\thet\in\mathcal P_0) =\Pr(\delta(\X) = \mathcal P_1 \mid P_\thet\in\mathcal P_0)<span class="sc">\\</span> </span>
<span id="cb49-140"><a href="#cb49-140" aria-hidden="true" tabindex="-1"></a>R(P_\thet, \delta(\X) \mid P_\thet\in\mathcal P_1)&amp; =  \underbrace{l(P_\theta, \mathcal P_0)}_1\cdot \Pr(\delta(\X) = \mathcal P_0 \mid P_\thet\in\mathcal P_1) +\underbrace{l(P_\theta, \mathcal P_1)}_0\cdot \Pr(\delta(\X) = \mathcal P_1 \mid P_\thet\in\mathcal P_1) =\Pr(\delta(\X) = \mathcal P_0 \mid P_\thet\in\mathcal P_1)</span>
<span id="cb49-141"><a href="#cb49-141" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-142"><a href="#cb49-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-143"><a href="#cb49-143" aria-hidden="true" tabindex="-1"></a>In both cases, the risk function is the probability of making an erroneous decision. These two types of errors are likely familiar.</span>
<span id="cb49-144"><a href="#cb49-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-145"><a href="#cb49-145" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-146"><a href="#cb49-146" aria-hidden="true" tabindex="-1"></a>Suppose we have a null hypothesis $H_0:P_\thet \in\mathcal P_0$. If $P_\thet \in \mathcal P_0$, but $\delta(\X) = \mathcal P_1$ (the null hypothesis is true but we reject it), then we have committed a &lt;span style="color:red"&gt;**_type I error_**&lt;/span&gt;. On the other hand, if $P_\thet \in \mathcal P_1$, but $\delta(\X) = \mathcal P_0$ (the null hypothesis is false but we fail to reject it), then we have committed a &lt;span style="color:red"&gt;**_type II error_**&lt;/span&gt;.</span>
<span id="cb49-147"><a href="#cb49-147" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-148"><a href="#cb49-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-149"><a href="#cb49-149" aria-hidden="true" tabindex="-1"></a>|                      | $H_0$ True       | $H_0$  False     |</span>
<span id="cb49-150"><a href="#cb49-150" aria-hidden="true" tabindex="-1"></a>|----------------------|------------------|------------------|</span>
<span id="cb49-151"><a href="#cb49-151" aria-hidden="true" tabindex="-1"></a>| Reject $H_0$         | type I error | correct decision    |</span>
<span id="cb49-152"><a href="#cb49-152" aria-hidden="true" tabindex="-1"></a>| Fail to Reject $H_0$ | correct decision     | type II error |</span>
<span id="cb49-153"><a href="#cb49-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-154"><a href="#cb49-154" aria-hidden="true" tabindex="-1"></a>Considering we have two types of errors, which is more important? How do we construct optimal test? @neyman1933 provide a solution to these problems.</span>
<span id="cb49-155"><a href="#cb49-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-156"><a href="#cb49-156" aria-hidden="true" tabindex="-1"></a><span class="fu">## Size and Power</span></span>
<span id="cb49-157"><a href="#cb49-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-158"><a href="#cb49-158" aria-hidden="true" tabindex="-1"></a>In order to assess tests, we will need to define probabilities related to type I and type II error.</span>
<span id="cb49-159"><a href="#cb49-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-160"><a href="#cb49-160" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-161"><a href="#cb49-161" aria-hidden="true" tabindex="-1"></a>The &lt;span style="color:red"&gt;**_level_**&lt;/span&gt; $\alpha \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ is a specified number such that $\Pr(\text{type I error})&gt;\alpha$ is unacceptable. In other words, $$\Pr(\delta(\X) = \mathcal P_1 \mid P_\thet\in P_0) = \Pr(T(\X)\in C \mid P_\thet\in P_0) \le \alpha \ \ \forall P_\thet\in \mathcal P_0.$$</span>
<span id="cb49-162"><a href="#cb49-162" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-163"><a href="#cb49-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-164"><a href="#cb49-164" aria-hidden="true" tabindex="-1"></a>Note that $\alpha$ must hold for all $P_\thet \in \mathcal P_0$. A test may have a level of 0.01 for one $P_{\thet} \in \mathcal P_0$, but could have a level of 0.10 for $P_{\thet'} \in \mathcal P_0$. How then do we assess the "aggregate" level of a test across all $\mathcal P_0$? We will do so by considering the worst case scenario, and associating a test with the largest level $\alpha$ possible, where the maximum is taken over all $P_\thet\in \mathcal P_0$. This will be known as the size of the test.</span>
<span id="cb49-165"><a href="#cb49-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-166"><a href="#cb49-166" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-167"><a href="#cb49-167" aria-hidden="true" tabindex="-1"></a>The &lt;span style="color:red"&gt;**_size of a test_**&lt;/span&gt; defined with a statistic $T(\X)$ and critical value $c$ is $$\alpha(\delta) = \sup_{P_\thet \in \mathcal P_0} \Pr(T(\X)\in C \mid P_\thet \in \mathcal P_0).$$</span>
<span id="cb49-168"><a href="#cb49-168" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-169"><a href="#cb49-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-170"><a href="#cb49-170" aria-hidden="true" tabindex="-1"></a>The size is nothing more than the maximum probability of committing a type I error permitted by a test $\delta$. If we want to avoid type I errors, we want $\alpha$ to be very small. We also need to consider type II errors. Note that the probability of a type II error is</span>
<span id="cb49-171"><a href="#cb49-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-172"><a href="#cb49-172" aria-hidden="true" tabindex="-1"></a>$$\Pr(\text{type II error}) = \Pr(T(\X)\in C \mid P_\thet \in\mathcal P_0) = 1 - \Pr(T(\X)\in C \mid P_\thet \in\mathcal P_1).$$</span>
<span id="cb49-173"><a href="#cb49-173" aria-hidden="true" tabindex="-1"></a>A small chance of committing a type II error is the same as the probability of our test correctly identifying $P_\thet\in \mathcal P_1$ being high. This ability is the power of our test.</span>
<span id="cb49-174"><a href="#cb49-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-175"><a href="#cb49-175" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-176"><a href="#cb49-176" aria-hidden="true" tabindex="-1"></a>The &lt;span style="color:red"&gt;**_power of a test_**&lt;/span&gt; defined with a statistic $T(\X)$ and critical region $C$ is $$\beta(\delta, P_\theta) = \Pr(T(\X) \in C \mid P_\thet).$$</span>
<span id="cb49-177"><a href="#cb49-177" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-178"><a href="#cb49-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-179"><a href="#cb49-179" aria-hidden="true" tabindex="-1"></a>The power function is simply the probability of rejecting the null hypothesis for any $P_\thet\in \mathcal P$. It can be thought of as a test power detect that $H_1$ is true ($H_0$ is false). Note that $\beta(\delta, P_\theta)$ is redundant on the subset $\mathcal P_0 \subset \mathcal P$. For any $P_\theta\in \mathcal P_0$,</span>
<span id="cb49-180"><a href="#cb49-180" aria-hidden="true" tabindex="-1"></a>$$ \beta(\delta, P_\theta\mid P_\theta\in \mathcal P_0) = \Pr(T(\X) \in C \mid   P_\thet\in \mathcal P_0) \le \sup_{P_\thet\in P_0} \Pr(T(\X)\in C \mid P_\thet\in\mathcal P_0) = \alpha(\delta).$$ By construction $\beta(\delta, P_\theta) \le \alpha(\delta)$ on $\mathcal P_0$, the power on $\mathcal P_0$ doesn't provide any new information. On the other hand it gives us another way of writing the size of a test:</span>
<span id="cb49-181"><a href="#cb49-181" aria-hidden="true" tabindex="-1"></a>$$ \alpha(\delta) = \sup_{P_\theta \in\mathcal P_0} \beta(P_\thet, \delta).$$We're interested in the power of our test when $\mathcal P\in P_1$, which corresponds to the probability of correctly detecting $\mathcal P\in P_1$.   </span>
<span id="cb49-182"><a href="#cb49-182" aria-hidden="true" tabindex="-1"></a>$$\beta(\delta, P_\theta\mid P_\theta\in \mathcal P_1) = \Pr(T(\X) \in C \mid   P_\thet\in \mathcal P_1) = 1 - \Pr(\text{type II error})$$ For this reason, you will very often see $\beta$ only defined on $\mathcal P_1$.</span>
<span id="cb49-183"><a href="#cb49-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-184"><a href="#cb49-184" aria-hidden="true" tabindex="-1"></a>:::{#exm-}</span>
<span id="cb49-185"><a href="#cb49-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-186"><a href="#cb49-186" aria-hidden="true" tabindex="-1"></a><span class="fu">## Z-Test</span></span>
<span id="cb49-187"><a href="#cb49-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-188"><a href="#cb49-188" aria-hidden="true" tabindex="-1"></a>Reconsider @exm-normtest. We have </span>
<span id="cb49-189"><a href="#cb49-189" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-190"><a href="#cb49-190" aria-hidden="true" tabindex="-1"></a>H_0:&amp;\mu \le \mu_0<span class="sc">\\</span></span>
<span id="cb49-191"><a href="#cb49-191" aria-hidden="true" tabindex="-1"></a>H_1:&amp;\mu &gt; \mu_0<span class="sc">\\</span></span>
<span id="cb49-192"><a href="#cb49-192" aria-hidden="true" tabindex="-1"></a>T(\X) &amp;= \frac{\bar X - \mu_0}{\sigma/\sqrt n }<span class="sc">\\</span></span>
<span id="cb49-193"><a href="#cb49-193" aria-hidden="true" tabindex="-1"></a>\delta(\X) &amp;= \begin{cases} (-\infty,\mu_0] &amp; T(\X) &lt; 1.645 <span class="sc">\\</span> (\mu_0,\infty) &amp; T(\X) \ge 1.645 \end{cases}</span>
<span id="cb49-194"><a href="#cb49-194" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-195"><a href="#cb49-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-196"><a href="#cb49-196" aria-hidden="true" tabindex="-1"></a>Note that an equivalent test for our null hypothesis is </span>
<span id="cb49-197"><a href="#cb49-197" aria-hidden="true" tabindex="-1"></a>$$\delta(\X) = \begin{cases} (-\infty,\mu_0] &amp; \bar X &lt; \mu_0 +1.645\left(\frac{\sigma}{\sqrt n}\right) <span class="sc">\\</span> (\mu_0,\infty) &amp; \bar X  \ge \mu_0 +1.645\left(\frac{\sigma}{\sqrt n}\right) \end{cases}$$</span>
<span id="cb49-198"><a href="#cb49-198" aria-hidden="true" tabindex="-1"></a>We can calculate the size of our test using the fact that $T(\X) \sim N(0,1)$. Any such $\mu$ can be written as $\mu_0 + t(\sigma/\sqrt n)$ for $t \le 0$. The level of a test for some $\mu \in (-\infty,\mu_0]$ is </span>
<span id="cb49-199"><a href="#cb49-199" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-200"><a href="#cb49-200" aria-hidden="true" tabindex="-1"></a>\Pr(\bar X \ge \mu_0 +1.645(\sigma/\sqrt n)) &amp;= \Pr(\bar X \ge <span class="co">[</span><span class="ot">\mu - t(\sigma/\sqrt n)</span><span class="co">]</span> +1.645(\sigma/\sqrt n)) &amp; (\mu_0 =\mu - t(\sigma/\sqrt n))<span class="sc">\\</span></span>
<span id="cb49-201"><a href="#cb49-201" aria-hidden="true" tabindex="-1"></a>&amp;= \Pr(\bar X \ge \mu+ (1.645-t)(\sigma/\sqrt n))<span class="sc">\\</span></span>
<span id="cb49-202"><a href="#cb49-202" aria-hidden="true" tabindex="-1"></a>&amp; = \Pr \left(\frac{\bar X - \mu}{(\sigma/\sqrt n)} \ge 1.645 - t\right)<span class="sc">\\</span></span>
<span id="cb49-203"><a href="#cb49-203" aria-hidden="true" tabindex="-1"></a>&amp; = \Phi(-1.645 + t) </span>
<span id="cb49-204"><a href="#cb49-204" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-205"><a href="#cb49-205" aria-hidden="true" tabindex="-1"></a>Before we take the supremum over all such probabilities, note that $\mu \le \mu_0$ is equivalent to $t\le 0$ where $\mu = \mu_0 + t(\sigma/\sqrt n)$.^<span class="co">[</span><span class="ot">In order to keep this problem a bit more general and avoid defining an explicit $\mu_0$, we express $\mu$ in terms of its standardized distance from $\mu_0$.</span><span class="co">]</span> Therefore the size of our test is </span>
<span id="cb49-206"><a href="#cb49-206" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-207"><a href="#cb49-207" aria-hidden="true" tabindex="-1"></a>\alpha &amp;= \sup_{\mu \le \mu_0} \Pr(T(\X)\in C \mid \mu &lt; \mu_0)<span class="sc">\\</span></span>
<span id="cb49-208"><a href="#cb49-208" aria-hidden="true" tabindex="-1"></a>&amp; = \sup_{t \le 0} \Phi(-1.645 + t)</span>
<span id="cb49-209"><a href="#cb49-209" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-210"><a href="#cb49-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-211"><a href="#cb49-211" aria-hidden="true" tabindex="-1"></a>Plotting this probability makes it clear that $\alpha(\delta) \approx 0.05$, and the supremum is achieved when $\mu = \mu_0$ ($t=0$).</span>
<span id="cb49-214"><a href="#cb49-214" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-215"><a href="#cb49-215" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-216"><a href="#cb49-216" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot31</span></span>
<span id="cb49-217"><a href="#cb49-217" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-218"><a href="#cb49-218" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-219"><a href="#cb49-219" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-220"><a href="#cb49-220" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: The size of the test is given by the red dashed line corresponding to the supremum of the probability of rejecting a true null hypothesis."</span></span>
<span id="cb49-221"><a href="#cb49-221" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-222"><a href="#cb49-222" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">t =</span> <span class="sc">-</span><span class="dv">300</span><span class="sc">:</span><span class="dv">0</span><span class="sc">/</span><span class="dv">100</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-223"><a href="#cb49-223" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">+</span> t)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-224"><a href="#cb49-224" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t,y)) <span class="sc">+</span></span>
<span id="cb49-225"><a href="#cb49-225" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb49-226"><a href="#cb49-226" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-227"><a href="#cb49-227" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"t =  (μ - μ0)/(σ√n)"</span>, <span class="at">y =</span> <span class="st">"Pr(Reject H0 | H0 True)"</span>) <span class="sc">+</span></span>
<span id="cb49-228"><a href="#cb49-228" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.05</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>)</span>
<span id="cb49-229"><a href="#cb49-229" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-230"><a href="#cb49-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-231"><a href="#cb49-231" aria-hidden="true" tabindex="-1"></a>Now we can consider the power $\beta(\mu)$. We've in fact already done nearly all the calculations required for this. Consider $\mu = \mu_0 + t(\sigma/\sqrt n)$ for $t\in \R$. If $t \le 0$, then $\mu \le \mu_0$, and the null hypothesis is true. If $t &gt; 0$, then $\mu &gt;\mu_0$ and the null hypothesis is false. The power $\beta(\mu)$ is $\Phi(-1.645 + t)$, but on the domain $t\in \R$.</span>
<span id="cb49-232"><a href="#cb49-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-235"><a href="#cb49-235" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-236"><a href="#cb49-236" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-237"><a href="#cb49-237" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-power</span></span>
<span id="cb49-238"><a href="#cb49-238" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-239"><a href="#cb49-239" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-240"><a href="#cb49-240" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-241"><a href="#cb49-241" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Power curve of test."</span></span>
<span id="cb49-242"><a href="#cb49-242" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-243"><a href="#cb49-243" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb49-244"><a href="#cb49-244" aria-hidden="true" tabindex="-1"></a>  <span class="at">t =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">4</span>, <span class="at">length =</span> <span class="dv">1000</span>), </span>
<span id="cb49-245"><a href="#cb49-245" aria-hidden="true" tabindex="-1"></a>  <span class="at">group =</span> <span class="st">"Power Curve"</span></span>
<span id="cb49-246"><a href="#cb49-246" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-247"><a href="#cb49-247" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">+</span> t)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-248"><a href="#cb49-248" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(<span class="fu">data.frame</span>(<span class="at">t =</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">0</span>), <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">group =</span> <span class="st">"H0 True, μ &lt; μ0"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb49-249"><a href="#cb49-249" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(<span class="fu">data.frame</span>(<span class="at">t =</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">4</span>), <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">group =</span> <span class="st">"H1 True, μ &gt; μ0"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb49-250"><a href="#cb49-250" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t,y, <span class="at">color =</span> group)) <span class="sc">+</span></span>
<span id="cb49-251"><a href="#cb49-251" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb49-252"><a href="#cb49-252" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-253"><a href="#cb49-253" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="st">"t =  (μ - μ0)/(σ√n)"</span>, <span class="at">y =</span> <span class="st">"Pr(Reject H0)"</span> , <span class="at">color=</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb49-254"><a href="#cb49-254" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"green"</span>, <span class="st">"black"</span>)) <span class="sc">+</span> </span>
<span id="cb49-255"><a href="#cb49-255" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb49-256"><a href="#cb49-256" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-257"><a href="#cb49-257" aria-hidden="true" tabindex="-1"></a>To make this more concrete, we can perform a Monte Carlo simulation for fixed values of $\mu_0$, $\mu$, $\sigma^2$, and $n$. For all simulations, let's fix $\mu_0 = 2$, $n = 100$ and $\sigma^2 =1$. First, assume $\mu = \mu_0 = 2$, and record $\delta(\X)$ for 100,000 simulations. In this case we should expect to make the correct decision (fail to reject the null hypothesis) about 95% of the time, as the size of our test is $\alpha = 0.05$ which corresponds to the maximum level which occurs at $\mu = \mu_0$. </span>
<span id="cb49-258"><a href="#cb49-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-261"><a href="#cb49-261" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-262"><a href="#cb49-262" aria-hidden="true" tabindex="-1"></a><span class="co"># draw on realization of a test stat and report decision</span></span>
<span id="cb49-263"><a href="#cb49-263" aria-hidden="true" tabindex="-1"></a>draw_test <span class="ot">&lt;-</span> <span class="cf">function</span>(delta, test_stat, critical_region, mu_0, sigma, n, dist, dist_params, s){</span>
<span id="cb49-264"><a href="#cb49-264" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb49-265"><a href="#cb49-265" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">delta</span>(test_stat, critical_region, X, mu_0, sigma) <span class="sc">%&gt;%</span> </span>
<span id="cb49-266"><a href="#cb49-266" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">iter =</span> s)</span>
<span id="cb49-267"><a href="#cb49-267" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-268"><a href="#cb49-268" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-269"><a href="#cb49-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-270"><a href="#cb49-270" aria-hidden="true" tabindex="-1"></a><span class="co"># draw N realizations of a test stat</span></span>
<span id="cb49-271"><a href="#cb49-271" aria-hidden="true" tabindex="-1"></a>draw_N_tests <span class="ot">&lt;-</span> <span class="cf">function</span>(N, delta, test_stat, critical_region, mu_0, sigma, n, dist, dist_params){</span>
<span id="cb49-272"><a href="#cb49-272" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb49-273"><a href="#cb49-273" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map_df</span>(\(s) <span class="fu">draw_test</span>(delta, test_stat, critical_region, mu_0, sigma, n, dist, dist_params, s))</span>
<span id="cb49-274"><a href="#cb49-274" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-275"><a href="#cb49-275" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-276"><a href="#cb49-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-277"><a href="#cb49-277" aria-hidden="true" tabindex="-1"></a><span class="co"># define test stat for this particular example</span></span>
<span id="cb49-278"><a href="#cb49-278" aria-hidden="true" tabindex="-1"></a>test_stat <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu_0, sigma){</span>
<span id="cb49-279"><a href="#cb49-279" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb49-280"><a href="#cb49-280" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> (<span class="fu">mean</span>(X)<span class="sc">-</span>mu_0)<span class="sc">/</span>(sigma<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb49-281"><a href="#cb49-281" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-282"><a href="#cb49-282" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-283"><a href="#cb49-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-284"><a href="#cb49-284" aria-hidden="true" tabindex="-1"></a><span class="co"># Define decision function, supply critical region as a list of bounds, ex: list(c(-Inf, -3), c(0, 1), c(3, Inf))</span></span>
<span id="cb49-285"><a href="#cb49-285" aria-hidden="true" tabindex="-1"></a>delta <span class="ot">&lt;-</span> <span class="cf">function</span>(test_stat, critical_region, X, mu_0, sigma){</span>
<span id="cb49-286"><a href="#cb49-286" aria-hidden="true" tabindex="-1"></a>  stat <span class="ot">&lt;-</span> <span class="fu">test_stat</span>(X, mu_0, sigma)</span>
<span id="cb49-287"><a href="#cb49-287" aria-hidden="true" tabindex="-1"></a>  <span class="co"># determine if the test stat falls within any of the interval comprising the critical region</span></span>
<span id="cb49-288"><a href="#cb49-288" aria-hidden="true" tabindex="-1"></a>  decision <span class="ot">&lt;-</span> critical_region <span class="sc">%&gt;%</span> </span>
<span id="cb49-289"><a href="#cb49-289" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map_lgl</span>(\(bounds) <span class="fu">between</span>(stat, bounds[<span class="dv">1</span>], bounds[<span class="dv">2</span>])) <span class="sc">%&gt;%</span> </span>
<span id="cb49-290"><a href="#cb49-290" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb49-291"><a href="#cb49-291" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.logical</span>()</span>
<span id="cb49-292"><a href="#cb49-292" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-293"><a href="#cb49-293" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb49-294"><a href="#cb49-294" aria-hidden="true" tabindex="-1"></a>    <span class="at">stat =</span> stat,</span>
<span id="cb49-295"><a href="#cb49-295" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> decision,</span>
<span id="cb49-296"><a href="#cb49-296" aria-hidden="true" tabindex="-1"></a>    <span class="at">H_0 =</span> mu_0</span>
<span id="cb49-297"><a href="#cb49-297" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-298"><a href="#cb49-298" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-299"><a href="#cb49-299" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-300"><a href="#cb49-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-301"><a href="#cb49-301" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">draw_N_tests</span>(</span>
<span id="cb49-302"><a href="#cb49-302" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e5</span>,</span>
<span id="cb49-303"><a href="#cb49-303" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> delta, </span>
<span id="cb49-304"><a href="#cb49-304" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_stat =</span> test_stat, </span>
<span id="cb49-305"><a href="#cb49-305" aria-hidden="true" tabindex="-1"></a>  <span class="at">critical_region =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="fl">1.645</span>, <span class="cn">Inf</span>)), </span>
<span id="cb49-306"><a href="#cb49-306" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_0 =</span> <span class="dv">2</span>, </span>
<span id="cb49-307"><a href="#cb49-307" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="dv">1</span>, </span>
<span id="cb49-308"><a href="#cb49-308" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span>, </span>
<span id="cb49-309"><a href="#cb49-309" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist =</span> rnorm, </span>
<span id="cb49-310"><a href="#cb49-310" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist_params =</span> <span class="fu">list</span>(</span>
<span id="cb49-311"><a href="#cb49-311" aria-hidden="true" tabindex="-1"></a>    <span class="at">mean =</span> <span class="dv">2</span>, </span>
<span id="cb49-312"><a href="#cb49-312" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd=</span> <span class="dv">1</span></span>
<span id="cb49-313"><a href="#cb49-313" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-314"><a href="#cb49-314" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-315"><a href="#cb49-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-316"><a href="#cb49-316" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb49-317"><a href="#cb49-317" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(decision) <span class="sc">%&gt;%</span> </span>
<span id="cb49-318"><a href="#cb49-318" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>()</span>
<span id="cb49-319"><a href="#cb49-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-320"><a href="#cb49-320" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(results<span class="sc">$</span>decision)</span>
<span id="cb49-321"><a href="#cb49-321" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-322"><a href="#cb49-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-323"><a href="#cb49-323" aria-hidden="true" tabindex="-1"></a>This simulation calculated the power of our test given $\mu$. Let's define the power function using this simulation, and calculate the power for $\mu\in<span class="co">[</span><span class="ot">1.8,2.4</span><span class="co">]</span>$</span>
<span id="cb49-324"><a href="#cb49-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-327"><a href="#cb49-327" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-328"><a href="#cb49-328" aria-hidden="true" tabindex="-1"></a><span class="co"># Approximate the power of a test for a given μ using N simulations, assume normal distribution</span></span>
<span id="cb49-329"><a href="#cb49-329" aria-hidden="true" tabindex="-1"></a>power <span class="ot">&lt;-</span> <span class="cf">function</span>(mu, N, delta, test_stat, critical_region, mu_0, sigma, n){</span>
<span id="cb49-330"><a href="#cb49-330" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">draw_N_tests</span>(N, delta, test_stat, critical_region, mu_0, sigma, n, rnorm, <span class="fu">list</span>(mu, sigma)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-331"><a href="#cb49-331" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(</span>
<span id="cb49-332"><a href="#cb49-332" aria-hidden="true" tabindex="-1"></a>      <span class="at">simulated_power =</span> <span class="fu">mean</span>(decision),</span>
<span id="cb49-333"><a href="#cb49-333" aria-hidden="true" tabindex="-1"></a>      <span class="at">t =</span> mu</span>
<span id="cb49-334"><a href="#cb49-334" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb49-335"><a href="#cb49-335" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-336"><a href="#cb49-336" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-337"><a href="#cb49-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-338"><a href="#cb49-338" aria-hidden="true" tabindex="-1"></a>power_curve <span class="ot">&lt;-</span> <span class="cf">function</span>(domain, N, delta, test_stat, critical_region, mu_0, sigma, n){</span>
<span id="cb49-339"><a href="#cb49-339" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> domain <span class="sc">%&gt;%</span></span>
<span id="cb49-340"><a href="#cb49-340" aria-hidden="true" tabindex="-1"></a>      <span class="fu">map_df</span>(\(mu) <span class="fu">power</span>(mu, N, delta, test_stat, critical_region, mu_0, sigma, n))</span>
<span id="cb49-341"><a href="#cb49-341" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-342"><a href="#cb49-342" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-343"><a href="#cb49-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-344"><a href="#cb49-344" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">power_curve</span>(</span>
<span id="cb49-345"><a href="#cb49-345" aria-hidden="true" tabindex="-1"></a>  <span class="at">domain =</span> <span class="fu">seq</span>(<span class="fl">1.8</span>, <span class="fl">2.4</span>, <span class="at">length =</span> <span class="dv">25</span>), </span>
<span id="cb49-346"><a href="#cb49-346" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e4</span>,</span>
<span id="cb49-347"><a href="#cb49-347" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> delta, </span>
<span id="cb49-348"><a href="#cb49-348" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_stat =</span> test_stat, </span>
<span id="cb49-349"><a href="#cb49-349" aria-hidden="true" tabindex="-1"></a>  <span class="at">critical_region =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="fl">1.645</span>, <span class="cn">Inf</span>)), </span>
<span id="cb49-350"><a href="#cb49-350" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_0 =</span> <span class="dv">2</span>, </span>
<span id="cb49-351"><a href="#cb49-351" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="dv">1</span>, </span>
<span id="cb49-352"><a href="#cb49-352" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span></span>
<span id="cb49-353"><a href="#cb49-353" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-354"><a href="#cb49-354" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-355"><a href="#cb49-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-356"><a href="#cb49-356" aria-hidden="true" tabindex="-1"></a>We can plot this simulated power curve over the theoretical curve we calculated for a general $\mu_0$ (see @fig-power).^<span class="co">[</span><span class="ot">This requires us to reparameterize the domain of the theoretical curve in terms of $\mu$ instead of $t$.</span><span class="co">]</span></span>
<span id="cb49-357"><a href="#cb49-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-360"><a href="#cb49-360" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-361"><a href="#cb49-361" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-362"><a href="#cb49-362" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot33</span></span>
<span id="cb49-363"><a href="#cb49-363" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-364"><a href="#cb49-364" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-365"><a href="#cb49-365" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-366"><a href="#cb49-366" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Simulated power function on the interval [1.8, 2.4] using 10,000 simulations for each point."</span></span>
<span id="cb49-367"><a href="#cb49-367" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-368"><a href="#cb49-368" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> results <span class="sc">%&gt;%</span> </span>
<span id="cb49-369"><a href="#cb49-369" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb49-370"><a href="#cb49-370" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> simulated_power,</span>
<span id="cb49-371"><a href="#cb49-371" aria-hidden="true" tabindex="-1"></a>    <span class="at">group =</span> <span class="st">"Simulated Power"</span>,</span>
<span id="cb49-372"><a href="#cb49-372" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb49-373"><a href="#cb49-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-374"><a href="#cb49-374" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb49-375"><a href="#cb49-375" aria-hidden="true" tabindex="-1"></a>  <span class="at">t =</span> <span class="fu">seq</span>(<span class="fl">1.8</span>, <span class="fl">2.4</span>, <span class="at">length =</span> <span class="dv">1000</span>),</span>
<span id="cb49-376"><a href="#cb49-376" aria-hidden="true" tabindex="-1"></a>  <span class="at">group =</span> <span class="st">"Power Curve"</span></span>
<span id="cb49-377"><a href="#cb49-377" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb49-378"><a href="#cb49-378" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">+</span> (t<span class="dv">-2</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">10</span>) )) <span class="sc">%&gt;%</span></span>
<span id="cb49-379"><a href="#cb49-379" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(<span class="fu">data.frame</span>(<span class="at">t =</span><span class="fu">c</span>(<span class="fl">1.8</span>,<span class="dv">2</span>), <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">group =</span> <span class="st">"H0 True, μ &lt; μ0"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb49-380"><a href="#cb49-380" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(<span class="fu">data.frame</span>(<span class="at">t =</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="fl">2.4</span>), <span class="at">y =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="at">group =</span> <span class="st">"H1 True, μ &gt; μ0"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb49-381"><a href="#cb49-381" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t, y, <span class="at">color =</span> group)) <span class="sc">+</span></span>
<span id="cb49-382"><a href="#cb49-382" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb49-383"><a href="#cb49-383" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> df, <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb49-384"><a href="#cb49-384" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-385"><a href="#cb49-385" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="st">"True μ"</span>, <span class="st">"Pr(Reject H0)"</span>, <span class="at">color =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb49-386"><a href="#cb49-386" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"green"</span>, <span class="st">"black"</span>, <span class="st">"blue"</span>)) <span class="sc">+</span></span>
<span id="cb49-387"><a href="#cb49-387" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb49-388"><a href="#cb49-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-389"><a href="#cb49-389" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-390"><a href="#cb49-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-391"><a href="#cb49-391" aria-hidden="true" tabindex="-1"></a>Our simulated probabilities are virtually identical to the theoretical probabilities calculated!</span>
<span id="cb49-392"><a href="#cb49-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-393"><a href="#cb49-393" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-394"><a href="#cb49-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-395"><a href="#cb49-395" aria-hidden="true" tabindex="-1"></a>This example is special for a few reason. Note that we have: </span>
<span id="cb49-396"><a href="#cb49-396" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-397"><a href="#cb49-397" aria-hidden="true" tabindex="-1"></a>\alpha &amp; = \sup_{\mu \le \mu_0}\beta(\mu) = \beta(\mu_0). </span>
<span id="cb49-398"><a href="#cb49-398" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-399"><a href="#cb49-399" aria-hidden="true" tabindex="-1"></a>This equality holds because $\beta$ is monotonically increasing:</span>
<span id="cb49-400"><a href="#cb49-400" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-401"><a href="#cb49-401" aria-hidden="true" tabindex="-1"></a> \frac{\partial}{\partial \mu} \beta(\mu) &amp;= \frac{\partial }{\partial \mu}\Phi(-1.645 + t)  <span class="sc">\\</span> </span>
<span id="cb49-402"><a href="#cb49-402" aria-hidden="true" tabindex="-1"></a> &amp; = \frac{\partial t}{\partial \mu}\varphi(-1.645 - t) &amp; (\varphi \text{ standard normal pdf})<span class="sc">\\</span></span>
<span id="cb49-403"><a href="#cb49-403" aria-hidden="true" tabindex="-1"></a> &amp; = \frac{\partial}{\partial \mu}\left(\frac{\mu - \mu_0}{\sigma/\sqrt n}\right)\varphi\left(-1.645 + \frac{\mu - \mu_0}{\sigma/\sqrt n}\right) &amp;(t = (\mu - \mu_0)/(\sigma/\sqrt n))<span class="sc">\\</span> &amp; = </span>
<span id="cb49-404"><a href="#cb49-404" aria-hidden="true" tabindex="-1"></a>\frac{1}{\sigma/\sqrt n}\varphi\left(-1.645 + \frac{\mu - \mu_0}{\sigma/\sqrt n}\right) <span class="sc">\\</span></span>
<span id="cb49-405"><a href="#cb49-405" aria-hidden="true" tabindex="-1"></a>&amp; &gt; 0 &amp;(\varphi(\cdot) &gt;0 , n &gt;0, \sigma &gt; 0).</span>
<span id="cb49-406"><a href="#cb49-406" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-407"><a href="#cb49-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-408"><a href="#cb49-408" aria-hidden="true" tabindex="-1"></a>If the probability we reject the null hypothesis grows with $\mu\in(-\infty,\mu_0]$, then of course the supremum of these probabilities is the probability at the boundary $\mu_0$. Equivalently, </span>
<span id="cb49-409"><a href="#cb49-409" aria-hidden="true" tabindex="-1"></a>$$ \alpha = \inf_{\mu_0 &lt; \mu}\beta(\mu) = \inf_\mu \beta(\mu \mid \mu_0 &lt; \mu) = \inf_\mu \beta(\mu \mid H_0 \text{ false}).$$ Many people would define power $\beta(\mu)$ only on $(\mu_0,\infty)$ (when $H_0$ is false), so in this case the size is in the infimum of the power. Finally because $$\beta(\mu) = \Phi(-1.645 + t) = \Phi\left(-1.645 + \frac{\mu - \mu_0}{\sigma/\sqrt n}\right),$$</span>
<span id="cb49-410"><a href="#cb49-410" aria-hidden="true" tabindex="-1"></a>we have $\alpha = \beta(\mu_0) = \Phi(-1.645)$. This means if we desire a size of $\alpha$, we can use the standard quantile function to calculate the critical value required -- $c = -\Phi^{-1}(\alpha)$. Just to reiterate, these nice properties hold because $\beta$ is monotonic!   </span>
<span id="cb49-411"><a href="#cb49-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-412"><a href="#cb49-412" aria-hidden="true" tabindex="-1"></a>::: {.hypothesis name="p-Values"}</span>
<span id="cb49-413"><a href="#cb49-413" aria-hidden="true" tabindex="-1"></a>Our decision function $\delta(\X)$ only tells us whether we reject the null hypothesis or not. It doesn't directly give us any information on how confident we should be in our decision, or by what degree we reject the null hypothesis. We can capture this by looking at the distribution of the test statistics $T(\X)$ in relation to the critical region $C(\alpha)$ for size $\alpha$. We can define the  &lt;span style="color:red"&gt;**_$p$-value_**&lt;/span&gt;, denoted $p$, as $$p = \inf<span class="sc">\{</span>\alpha \mid T(\X)\in C(\alpha)<span class="sc">\}</span>.$$ The $p-$value is the minimum level of the test such that we still reject the null hypothesis (because $T(\X)$ is in the critical region). Suppose in the case of the one sided $Z-$test we had $T(\X) = 2$. We reject the null hypothesis because $T(\X) \ge  2$. We would also reject the null hypothesis for any size $\alpha$ such that $2 \ge -\Phi^{-1}(\alpha)$. Because $-\Phi^{-1}$ is monotonic, </span>
<span id="cb49-414"><a href="#cb49-414" aria-hidden="true" tabindex="-1"></a>$$p = \inf<span class="sc">\{</span>\alpha\mid 2 \ge -\Phi^{-1}(\alpha)<span class="sc">\}</span> = <span class="sc">\{</span>\alpha\mid 2= -\Phi^{-1}(\alpha)<span class="sc">\}</span> = \Phi(-2) \approx 0.02275.$$ One important result which follows immediately from the definition of of $p$:</span>
<span id="cb49-415"><a href="#cb49-415" aria-hidden="true" tabindex="-1"></a>$$T(\X) \in C\iff \alpha(\delta) &lt; p.$$ We reject $H_0$ *if and only if* the $p-$value associated with $T(\X)$ is less than the size of the test. One interpretation related to this is that the $p-$value tells you the degree to which you reject the null hypothesis. If $p\approx0.02275$, not only do we reject the null hypothesis for $\alpha(\delta) = 0.05$, but we also reject it for more stringent tests with smaller sizes.</span>
<span id="cb49-416"><a href="#cb49-416" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-417"><a href="#cb49-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-418"><a href="#cb49-418" aria-hidden="true" tabindex="-1"></a>So if we can pick $\alpha$ by virtue of the critical value $c$, then why don't we simply pick $\alpha\approx 0$. This would mean that we almost always fail to reject the null hypothesis, and in doing so we're bound to fail to reject the null hypothesis even when it is false, increasing the probability of a type II error </span>
<span id="cb49-419"><a href="#cb49-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-420"><a href="#cb49-420" aria-hidden="true" tabindex="-1"></a>:::{#exm-}</span>
<span id="cb49-421"><a href="#cb49-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-422"><a href="#cb49-422" aria-hidden="true" tabindex="-1"></a><span class="fu">## Power vs. Size</span></span>
<span id="cb49-423"><a href="#cb49-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-424"><a href="#cb49-424" aria-hidden="true" tabindex="-1"></a>Again consider</span>
<span id="cb49-425"><a href="#cb49-425" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-426"><a href="#cb49-426" aria-hidden="true" tabindex="-1"></a>H_0:&amp;\mu \le \mu_0<span class="sc">\\</span></span>
<span id="cb49-427"><a href="#cb49-427" aria-hidden="true" tabindex="-1"></a>H_1:&amp;\mu &gt; \mu_0</span>
<span id="cb49-428"><a href="#cb49-428" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-429"><a href="#cb49-429" aria-hidden="true" tabindex="-1"></a>where $X_i\iid N(\mu,\sigma^2)$ for a known $\sigma^2$, and $\delta(\X) = 1<span class="co">[</span><span class="ot">T(\X) \ge c</span><span class="co">]</span>$ for some critical value $c$. If we desire a test of size $\alpha$ we set our critical value as $c = -\Phi^{-1}(\alpha)$.</span>
<span id="cb49-430"><a href="#cb49-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-433"><a href="#cb49-433" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-434"><a href="#cb49-434" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-435"><a href="#cb49-435" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot34</span></span>
<span id="cb49-436"><a href="#cb49-436" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-437"><a href="#cb49-437" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-438"><a href="#cb49-438" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-439"><a href="#cb49-439" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "The relationship between critical value and size."</span></span>
<span id="cb49-440"><a href="#cb49-440" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-441"><a href="#cb49-441" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">1000</span><span class="sc">/</span><span class="dv">1000</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-442"><a href="#cb49-442" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="sc">-</span><span class="fu">qnorm</span>(x)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-443"><a href="#cb49-443" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x,y)) <span class="sc">+</span></span>
<span id="cb49-444"><a href="#cb49-444" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb49-445"><a href="#cb49-445" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-446"><a href="#cb49-446" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Desired Size, α"</span>, <span class="at">y =</span> <span class="st">"Required Critical Value, c"</span>)</span>
<span id="cb49-447"><a href="#cb49-447" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-448"><a href="#cb49-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-449"><a href="#cb49-449" aria-hidden="true" tabindex="-1"></a>Define $t = (\mu - \mu_0)/(\sigma/\sqrt n)$ to be the standardized distance between $\mu_0$ and the true $\mu$. The power of the test is $$\beta(\mu)= \Phi(- c + t) = \Phi(\Phi^{-1}(\alpha) + t),$$ which is increasing in $\alpha$:</span>
<span id="cb49-450"><a href="#cb49-450" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-451"><a href="#cb49-451" aria-hidden="true" tabindex="-1"></a>\frac{\partial \beta}{\partial \alpha} &amp; = \frac{\partial \Phi^{-1}(\alpha)}{\partial \alpha} \varphi(\Phi^{-1}(\alpha) + t) <span class="sc">\\</span></span>
<span id="cb49-452"><a href="#cb49-452" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{\varphi(\Phi^{-1}(\alpha) + t)}{\varphi(\Phi^{-1}(\alpha))} &amp; (\text{inverse function theorem}) <span class="sc">\\</span></span>
<span id="cb49-453"><a href="#cb49-453" aria-hidden="true" tabindex="-1"></a>&amp; &gt; 0 &amp; (\varphi(\cdot) &gt; 0).</span>
<span id="cb49-454"><a href="#cb49-454" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-455"><a href="#cb49-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-456"><a href="#cb49-456" aria-hidden="true" tabindex="-1"></a>As we let $\alpha \to 0$, we have $\beta \to 0$.</span>
<span id="cb49-457"><a href="#cb49-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-460"><a href="#cb49-460" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-461"><a href="#cb49-461" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-462"><a href="#cb49-462" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot35</span></span>
<span id="cb49-463"><a href="#cb49-463" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-464"><a href="#cb49-464" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-465"><a href="#cb49-465" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-466"><a href="#cb49-466" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "There is an inherent tradeoff between the power and size of a test, as small values of α result in less power."</span></span>
<span id="cb49-467"><a href="#cb49-467" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-468"><a href="#cb49-468" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb49-469"><a href="#cb49-469" aria-hidden="true" tabindex="-1"></a>  <span class="at">a =</span> <span class="fu">c</span>(<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.10</span>, <span class="fl">0.25</span>), </span>
<span id="cb49-470"><a href="#cb49-470" aria-hidden="true" tabindex="-1"></a>  <span class="at">t =</span> <span class="sc">-</span><span class="dv">2000</span><span class="sc">:</span><span class="dv">4000</span><span class="sc">/</span><span class="dv">1000</span></span>
<span id="cb49-471"><a href="#cb49-471" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-472"><a href="#cb49-472" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">power =</span> <span class="fu">pnorm</span>(<span class="sc">-</span>(<span class="sc">-</span><span class="fu">qnorm</span>(a)) <span class="sc">+</span> t)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-473"><a href="#cb49-473" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t, power, <span class="at">color =</span> <span class="fu">as.factor</span>(a))) <span class="sc">+</span> </span>
<span id="cb49-474"><a href="#cb49-474" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb49-475"><a href="#cb49-475" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-476"><a href="#cb49-476" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"t =  (μ - μ0)/(σ√n)"</span>, <span class="at">y =</span> <span class="st">"Power"</span>, <span class="at">color =</span> <span class="st">"size"</span>) <span class="sc">+</span></span>
<span id="cb49-477"><a href="#cb49-477" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb49-478"><a href="#cb49-478" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-479"><a href="#cb49-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-480"><a href="#cb49-480" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-481"><a href="#cb49-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-482"><a href="#cb49-482" aria-hidden="true" tabindex="-1"></a>So how do we select $\alpha$? Do we care more about type I error or type II error? Furthermore, how do we even construct test statistics?  We can begin to answer this question with the guidance of @neyman1933.</span>
<span id="cb49-483"><a href="#cb49-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-484"><a href="#cb49-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-485"><a href="#cb49-485" aria-hidden="true" tabindex="-1"></a><span class="fu">## Neyman-Pearson Lemma and UMP Tests</span></span>
<span id="cb49-486"><a href="#cb49-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-487"><a href="#cb49-487" aria-hidden="true" tabindex="-1"></a>One of the key ideas presented proposed by @neyman1933 is that type II errors are more erroneous than their type I counterparts, so we should minimize the probability of committing a type II error subject to a predetermined test size $\alpha$. If someone if getting tested for a disease, a false positive (type I) is much better than a false negative (type II). On the other hand, many would argue it is worse to sentence an innocent person to jail (type I error) than let a guilty person go free, so whether this assumption holds depends on the context of our test. </span>
<span id="cb49-488"><a href="#cb49-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-489"><a href="#cb49-489" aria-hidden="true" tabindex="-1"></a>The Neyman-Pearson lemma solves this problem by maximizing the power of a test subject to a specified $\alpha$:</span>
<span id="cb49-490"><a href="#cb49-490" aria-hidden="true" tabindex="-1"></a>$$ \max_{\delta\in \mathcal D}<span class="sc">\{</span>\beta(\delta, P_\thet) \mid \alpha(\delta) &lt; \alpha<span class="sc">\}</span>,$$ *fixing* $P_\thet$. The test which solves this maximization problem may vary across $P_\thet$. As such, the Neyman-Pearson lemma solves our problem in the context of simplified hypotheses. </span>
<span id="cb49-491"><a href="#cb49-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-492"><a href="#cb49-492" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-493"><a href="#cb49-493" aria-hidden="true" tabindex="-1"></a>A null hypothesis $H_0$ is &lt;span style="color:red"&gt;**_simple_**&lt;/span&gt; if $\mathcal P_0$ is a singleton, $\mathcal P_0 = <span class="sc">\{</span>P_{\thet_0}<span class="sc">\}</span>$. Similarly, an alternative hypothesis $H_1$ is simple if $\mathcal P_1 = <span class="sc">\{</span>P_{\thet_1}<span class="sc">\}</span>$.</span>
<span id="cb49-494"><a href="#cb49-494" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-495"><a href="#cb49-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-496"><a href="#cb49-496" aria-hidden="true" tabindex="-1"></a>The Neyman-Pearson Lemma will only apply directly to hypotheses of the form:</span>
<span id="cb49-497"><a href="#cb49-497" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-498"><a href="#cb49-498" aria-hidden="true" tabindex="-1"></a>H_0:P_\thet &amp;= P_{\thet_0}<span class="sc">\\</span></span>
<span id="cb49-499"><a href="#cb49-499" aria-hidden="true" tabindex="-1"></a>H_1:P_\thet &amp;=P_{\thet_1}</span>
<span id="cb49-500"><a href="#cb49-500" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-501"><a href="#cb49-501" aria-hidden="true" tabindex="-1"></a>Note that for simple hypotheses $$ \alpha(\delta) = \sup_{P_\thet \in \mathcal P_0} \Pr(T(\X)\in C \mid P_\thet \in \mathcal P_0) = \Pr(T(\X)\in C \mid P_\thet =P_{\thet_0}) $$</span>
<span id="cb49-502"><a href="#cb49-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-503"><a href="#cb49-503" aria-hidden="true" tabindex="-1"></a>:::{#thm-  #NPlemma name="Neyman-Pearson Lemma"}</span>
<span id="cb49-504"><a href="#cb49-504" aria-hidden="true" tabindex="-1"></a>Consider a test with simple hypotheses $H_0:P_\thet = P_{\thet_0}$ and $H_1:P_\thet=P_{\thet_1}$. If $\delta(\X)$ is test with size $\alpha$ and defined as </span>
<span id="cb49-505"><a href="#cb49-505" aria-hidden="true" tabindex="-1"></a>$$\delta(\X)=\begin{cases} P_{\thet_0} &amp; \frac{f_{\X}(\x \mid \thet_1)}{f_{\X}(\x \mid \thet_0)} &gt; \eta<span class="sc">\\</span>  P_{\thet_1} &amp; \frac{f_{\X}(\x \mid \thet_1)}{f_{\X}(\x \mid \thet_0)} &lt; \eta\end{cases}$$ for $\eta &gt; 0$, then $\beta(\delta, \theta_1) \ge \beta(\delta', \theta_1)$ for all $\delta' \in \mathcal D$ with a size less than or equal to $\alpha$. In this case we refer to $\delta(\X)$ as the &lt;span style="color:red"&gt;**_most powerful (MP) test_**&lt;/span&gt; for our hypotheses.</span>
<span id="cb49-506"><a href="#cb49-506" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-507"><a href="#cb49-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-508"><a href="#cb49-508" aria-hidden="true" tabindex="-1"></a>:::{.proof}</span>
<span id="cb49-509"><a href="#cb49-509" aria-hidden="true" tabindex="-1"></a>Let $\delta(\X)$ be some arbitrary decision rule in $\mathcal D$ with size $\alpha$, and let $\delta'\in\mathcal D$ be some other decision rule with size less than or equal to $\alpha$. </span>
<span id="cb49-510"><a href="#cb49-510" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-511"><a href="#cb49-511" aria-hidden="true" tabindex="-1"></a>\delta(\X) &amp;= \begin{cases}P_{\thet_1} &amp; \X \in C <span class="sc">\\</span> P_{\thet_0} &amp; \X \notin C\end{cases}<span class="sc">\\</span></span>
<span id="cb49-512"><a href="#cb49-512" aria-hidden="true" tabindex="-1"></a>\delta'(\X)&amp; = \begin{cases}P_{\thet_1} &amp; \X \in C' <span class="sc">\\</span> P_{\thet_0} &amp; \X \notin C'\end{cases}<span class="sc">\\</span></span>
<span id="cb49-513"><a href="#cb49-513" aria-hidden="true" tabindex="-1"></a> \Pr(\delta'(\X) = P_{\thet_1} \mid P_{\thet} = P_{\thet_0} ) &amp;\le \alpha = \Pr(\delta(\X) = P_{\thet_1} \mid P_{\thet} = P_{\thet_0} )</span>
<span id="cb49-514"><a href="#cb49-514" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-515"><a href="#cb49-515" aria-hidden="true" tabindex="-1"></a>Without loss of generality, we've taken $T(\X) = \X$.^<span class="co">[</span><span class="ot">How is this WLOG? If $\delta(\X) = 1[T(\X) \in C]$, we can always write it as $\delta(\X) = 1[\X \in T^{-1}(C)]$ where $T^{-1}$ is the preimage of the test statistic. This is convenient for two reasons. Firstly we're comparing arbitrary elements from an infinite set of decision rules $\mathcal D$, so it's much easier just to assume they both have the trivial test statistic $T(\X)=\X$, because in this case decision rules are determined only by critical regions. Comparing decision rules now amounts to comparing critical regions. Secondly, we'll want to calculate the probability of errors, which requires us to know the distribution of $T(\X)$. If $T(\X) = \X$, then we have $T(\X) \sim F_\X(\x \mid \thet)$ where $\thet \in \{\thet_1, \thet_2\}$. We know this distribution, so we can easily calculate the probability of errors. The proof is exactly the same without taking this step, but it looks a bit gnarlier with the additional notation.</span><span class="co">]</span> The only assumption we have made about our decision rules is,</span>
<span id="cb49-516"><a href="#cb49-516" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb49-517"><a href="#cb49-517" aria-hidden="true" tabindex="-1"></a>&amp; \Pr(\delta'(\X) = P_{\thet_1} \mid P_{\thet} = P_{\thet_0} ) \le \alpha = \Pr(\delta(\X) = P_{\thet_1} \mid P_{\thet} = P_{\thet_0} )<span class="sc">\\</span></span>
<span id="cb49-518"><a href="#cb49-518" aria-hidden="true" tabindex="-1"></a>\implies &amp; \Pr(\X\in C' \mid \thet_0 ) \le \Pr(\X\in C \mid \thet_0 ) (<span class="sc">\#</span>eq:npa).</span>
<span id="cb49-519"><a href="#cb49-519" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb49-520"><a href="#cb49-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-521"><a href="#cb49-521" aria-hidden="true" tabindex="-1"></a>In order to compare $\delta$ and $\delta'$, we'll want to write their powers in term of the critical regions of both tests. We can write $C$ in terms of the disjoint union of its intersection with the disjoint sets $C'$ and $(C')^c$, as $C'$ and $(C')^c$ partition the sample space $\mathcal X$. We can also do the same with $C'$ and the disjoint sets $C$ and $C^c$. </span>
<span id="cb49-522"><a href="#cb49-522" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-523"><a href="#cb49-523" aria-hidden="true" tabindex="-1"></a>C &amp; = (C\cap C') \cup (C\cap (C')^c)<span class="sc">\\</span></span>
<span id="cb49-524"><a href="#cb49-524" aria-hidden="true" tabindex="-1"></a>C' &amp; = (C'\cap C) \cup (C'\cap C^c)</span>
<span id="cb49-525"><a href="#cb49-525" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-526"><a href="#cb49-526" aria-hidden="true" tabindex="-1"></a>Accounting for these being disjoint unions, we have the following conditional probabilities:</span>
<span id="cb49-527"><a href="#cb49-527" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb49-528"><a href="#cb49-528" aria-hidden="true" tabindex="-1"></a>\Pr(\X \in C\mid \thet) &amp; = \Pr(\X \in C\cap C' \mid \thet) + \Pr(\X \in C\cap (C')^c \mid \thet)&amp; \text{for }\thet\in<span class="sc">\{</span>\thet_0, \thet_1<span class="sc">\}</span> (<span class="sc">\#</span>eq:npa2)<span class="sc">\\</span></span>
<span id="cb49-529"><a href="#cb49-529" aria-hidden="true" tabindex="-1"></a>\Pr(\X \in C'\mid\thet) &amp; = \Pr(\X \in C'\cap C \mid \thet) + \Pr(\X \in C'\cap C^c \mid \thet) &amp; \text{for }\thet\in<span class="sc">\{</span>\thet_0, \thet_1<span class="sc">\}</span> (<span class="sc">\#</span>eq:npa3)</span>
<span id="cb49-530"><a href="#cb49-530" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb49-531"><a href="#cb49-531" aria-hidden="true" tabindex="-1"></a>We can use these two equations to rewrite Equation \@ref(eq:npa). </span>
<span id="cb49-532"><a href="#cb49-532" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb49-533"><a href="#cb49-533" aria-hidden="true" tabindex="-1"></a>&amp;  \Pr(\X\in C' \mid \thet_0 ) \le \Pr(\X\in C \mid \thet_0 )<span class="sc">\\</span></span>
<span id="cb49-534"><a href="#cb49-534" aria-hidden="true" tabindex="-1"></a>\implies &amp; \Pr(\X \in C'\cap C \mid \thet_0) + \Pr(\X \in C'\cap C^c \mid \thet_0) \le \Pr(\X \in C\cap C' \mid \thet_0) + \Pr(\X \in C\cap (C')^c \mid \thet_0)<span class="sc">\\</span></span>
<span id="cb49-535"><a href="#cb49-535" aria-hidden="true" tabindex="-1"></a>\implies &amp; \Pr(\X \in C'\cap C^c \mid \thet_0) \le\Pr(\X \in C\cap (C')^c \mid \thet_0) (<span class="sc">\#</span>eq:npa4)</span>
<span id="cb49-536"><a href="#cb49-536" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb49-537"><a href="#cb49-537" aria-hidden="true" tabindex="-1"></a>Similarly, </span>
<span id="cb49-538"><a href="#cb49-538" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb49-539"><a href="#cb49-539" aria-hidden="true" tabindex="-1"></a>\beta(\delta,\thet_1) &amp; = \Pr(\X\in C \mid \theta_1) &amp;(\text{definition of }\beta)  (<span class="sc">\#</span>eq:npa5)<span class="sc">\\</span></span>
<span id="cb49-540"><a href="#cb49-540" aria-hidden="true" tabindex="-1"></a>&amp; = \Pr(\X \in C\cap C' \mid \thet_1) + \Pr(\X \in C\cap (C')^c \mid \thet_1) &amp; (\text{Equation }(4.2))<span class="sc">\\</span></span>
<span id="cb49-541"><a href="#cb49-541" aria-hidden="true" tabindex="-1"></a>\beta(\delta',\thet_1) &amp; =\Pr(\X \in C'\cap C \mid \thet_1) + \Pr(\X \in C'\cap C^c \mid \thet_1) &amp; (\text{Equation }(4.3))  (<span class="sc">\#</span>eq:npa6)</span>
<span id="cb49-542"><a href="#cb49-542" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb49-543"><a href="#cb49-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-544"><a href="#cb49-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-545"><a href="#cb49-545" aria-hidden="true" tabindex="-1"></a>We want to construct $\delta(\X)$ such that </span>
<span id="cb49-546"><a href="#cb49-546" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-547"><a href="#cb49-547" aria-hidden="true" tabindex="-1"></a>&amp;\beta(\delta,\thet_1)  \ge\beta(\delta',\thet_1),<span class="sc">\\</span></span>
<span id="cb49-548"><a href="#cb49-548" aria-hidden="true" tabindex="-1"></a>\implies&amp;\Pr(\X \in C\cap C' \mid \thet_1) + \Pr(\X \in C\cap (C')^c \mid \thet_1) \le  \Pr(\X \in C'\cap C \mid \thet_1) + \Pr(\X \in C'\cap C^c \mid \thet_1) &amp;(\text{Equation }(4.5)\text{ and }(4.6)),<span class="sc">\\</span></span>
<span id="cb49-549"><a href="#cb49-549" aria-hidden="true" tabindex="-1"></a> \implies &amp;\Pr(\X \in C\cap (C')^c \mid \thet_1)  \ge \Pr(\X \in C'\cap C^c \mid \thet_1),<span class="sc">\\</span></span>
<span id="cb49-550"><a href="#cb49-550" aria-hidden="true" tabindex="-1"></a> \implies &amp; \int 1<span class="co">[</span><span class="ot">\X \in C\cap (C')^c</span><span class="co">]</span>\ dF_\X(\x\mid \thet_1) \ge \int 1<span class="co">[</span><span class="ot">\X \in C'\cap C^c</span><span class="co">]</span>\ dF_\X(\x\mid \thet_1),<span class="sc">\\</span></span>
<span id="cb49-551"><a href="#cb49-551" aria-hidden="true" tabindex="-1"></a> \implies &amp; \int_{C\cap (C')^c} f_\X(\x\mid \thet_1) \ d\x \ge \int_{C'\cap C^c} f_\X(\x\mid \thet_1) \ d\x</span>
<span id="cb49-552"><a href="#cb49-552" aria-hidden="true" tabindex="-1"></a>\end{align*} In other words, we need to define $C$ such that </span>
<span id="cb49-553"><a href="#cb49-553" aria-hidden="true" tabindex="-1"></a>$$ \int_{C\cap (C')^c} f_\X(\x\mid \thet_1)\stackrel{?}{\ge}\int_{C'\cap C^c} f_\X(\x\mid \thet_1) \ d\x$$ using the fact that </span>
<span id="cb49-554"><a href="#cb49-554" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-555"><a href="#cb49-555" aria-hidden="true" tabindex="-1"></a>\int_{C'\cap C^c }f_\X(\x\mid \thet_0)\ d\x &amp; \le \int_{C\cap (C')^c }f_\X(\x\mid \thet_0)\ d\x &amp; (\text{Equation (4.4)}).</span>
<span id="cb49-556"><a href="#cb49-556" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-557"><a href="#cb49-557" aria-hidden="true" tabindex="-1"></a>We can write the left hand side of this known inequality as </span>
<span id="cb49-558"><a href="#cb49-558" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-559"><a href="#cb49-559" aria-hidden="true" tabindex="-1"></a>\int_{C'\cap C^c }f_\X(\x\mid \thet_0)\ d\x = \int_{C'\cap C^c}f_\X(\x\mid \thet_1) \cdot \frac{f_\X(\x\mid \thet_0)}{f_\X(\x\mid \thet_1)}\ d\x.</span>
<span id="cb49-560"><a href="#cb49-560" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-561"><a href="#cb49-561" aria-hidden="true" tabindex="-1"></a>We want to somehow relate this to the integral of $f_\X(\x\mid\thet_1)$, but in general cannot "remove" $f_\X(\x\mid\thet_0)/f_\X(\x\mid\thet_1)$ from the integrand without an assumption about $f_\X(\x\mid\thet_0)/f_\X(\x\mid\thet_1)$. Namely, if we assume $f_\X(\x\mid\thet_0)/f_\X(\x\mid\thet_1) &gt;\eta^{-1}$ on $C'\cap C^c$ for some constant $\eta$,^<span class="co">[</span><span class="ot">Recall that $\int f(x)g(x)\ dx \le M \int f(x) $ if $g(x)\le M$ on the domain of integration.</span><span class="co">]</span> we have </span>
<span id="cb49-562"><a href="#cb49-562" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-563"><a href="#cb49-563" aria-hidden="true" tabindex="-1"></a>\int_{C'\cap C^c }f_\X(\x\mid \thet_0)\ d\x= \int_{C'\cap C^c }f_\X(\x\mid \thet_1) \cdot \frac{f_\X(\x\mid \thet_0)}{f_\X(\x\mid \thet_1)}\ d\x</span>
<span id="cb49-564"><a href="#cb49-564" aria-hidden="true" tabindex="-1"></a> \ge \eta^{-1}\int_{C'\cap C^c}f_\X(\x\mid \thet_0) \ d\x.</span>
<span id="cb49-565"><a href="#cb49-565" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-566"><a href="#cb49-566" aria-hidden="true" tabindex="-1"></a>Similarly, the right hand side of Equation 4.4 in integral form can be written as</span>
<span id="cb49-567"><a href="#cb49-567" aria-hidden="true" tabindex="-1"></a>$$\int_{C\cap (C')^c }f_\X(\x\mid \thet_0)\ d\x = \int_{C\cap (C')^c }f_\X(\x\mid \thet_1) \cdot \frac{f_\X(\x\mid \thet_0)}{f_\X(\x\mid \thet_1)}\ d\x\le \eta^{-1}\int_{C\cap (C')^c }f_\X(\x\mid \thet_0) \ d\x,$$ assuming $f_\X(\x\mid\thet_0)/f_\X(\x\mid\thet_1) &lt; \eta^{-1}$ on $C\cap (C')^c$. Therefore, </span>
<span id="cb49-568"><a href="#cb49-568" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-569"><a href="#cb49-569" aria-hidden="true" tabindex="-1"></a>\int_{C\cap (C')^c} f_\X(\x\mid \thet_1)\ d\x &amp; = \int_{C\cap (C')^c}f_\X(\x\mid \thet_1)  \cdot \frac{f_\X(\x\mid \thet_0)}{f_\X(\x\mid \thet_1)}\ d\x <span class="sc">\\</span></span>
<span id="cb49-570"><a href="#cb49-570" aria-hidden="true" tabindex="-1"></a>&amp; \ge \eta^{-1}\int_{C\cap (C')^c}f_\X(\x\mid \thet_0)\ d\x &amp; (f_\X(\x\mid\thet_0)/f_\X(\x\mid\thet_1) &lt; \eta^{-1} \text{ on } C\cap (C')^c)<span class="sc">\\</span></span>
<span id="cb49-571"><a href="#cb49-571" aria-hidden="true" tabindex="-1"></a>&amp; =\eta^{-1}\Pr(\X \in C\cap (C')^c \mid \thet_0)<span class="sc">\\</span></span>
<span id="cb49-572"><a href="#cb49-572" aria-hidden="true" tabindex="-1"></a>&amp; \ge  \eta^{-1}\Pr(\X \in C'\cap C^c \mid \thet_0) &amp; (\text{Equation }(4.4))<span class="sc">\\</span></span>
<span id="cb49-573"><a href="#cb49-573" aria-hidden="true" tabindex="-1"></a>&amp; =\eta^{-1}\int_{ C'\cap C^c}f_\X(\x\mid \thet_0)\ d\x<span class="sc">\\</span></span>
<span id="cb49-574"><a href="#cb49-574" aria-hidden="true" tabindex="-1"></a>&amp; \ge \int_{C'\cap C^c }f_\X(\x\mid \thet_1) \cdot \frac{f_\X(\x\mid \thet_0)}{f_\X(\x\mid \thet_1)}\ d\x &amp; (f_\X(\x\mid\thet_0)/f_\X(\x\mid\thet_1) &gt; \eta^{-1} \text{ on } C'\cap C^c)<span class="sc">\\</span></span>
<span id="cb49-575"><a href="#cb49-575" aria-hidden="true" tabindex="-1"></a>&amp; = \int_{C'\cap C^c} f_\X(\x\mid \thet_1)\ d\x, </span>
<span id="cb49-576"><a href="#cb49-576" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-577"><a href="#cb49-577" aria-hidden="true" tabindex="-1"></a>which is the desired result for a fixed $\delta'$. If we extend $f_\X(\x\mid\thet_0)/f_\X(\x\mid\thet_1) &gt; \eta^{-1}$ to all of $C^c$ and $f_\X(\x\mid\thet_0)/f_\X(\x\mid\thet_1) &lt; \eta^{-1}$ to all of $C$, then this will hold *for all* $\delta'\in \mathcal D$ (with a size of at least $\alpha$, otherwise Equation \@ref(eq:npa4) needn't hold). What then is the explicit form of $\delta(\X)$? It is defined using the bounds which allowed us to establish the desired inequality using properties of integrals. The critical region is,</span>
<span id="cb49-578"><a href="#cb49-578" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-579"><a href="#cb49-579" aria-hidden="true" tabindex="-1"></a>C &amp;= \left<span class="sc">\{</span>\x \ \bigg|\ \frac{f_{\X}(\x \mid \thet_1)}{f_{\X}(\x \mid \thet_0)} &gt; \eta \right<span class="sc">\}</span></span>
<span id="cb49-580"><a href="#cb49-580" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-581"><a href="#cb49-581" aria-hidden="true" tabindex="-1"></a>and $\delta(\X) = 1<span class="co">[</span><span class="ot">\x \in C</span><span class="co">]</span>$.</span>
<span id="cb49-582"><a href="#cb49-582" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-583"><a href="#cb49-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-584"><a href="#cb49-584" aria-hidden="true" tabindex="-1"></a>Before discussing the intuition behind Theorem \@ref(thm:NPlemma), here are some technical points:</span>
<span id="cb49-585"><a href="#cb49-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-586"><a href="#cb49-586" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>In the event $f_{\X}(\x \mid \thet_1)/f_{\X}(\x \mid \thet_0) = \eta$, then it doesn't matter if $\delta(\X)$ rejects the null hypothesis or not.^<span class="co">[</span><span class="ot">For the measure theory fans, this equality holds with measure zero, so we can just sweep it under the rug.</span><span class="co">]</span> </span>
<span id="cb49-587"><a href="#cb49-587" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>A more general version of the result can be found in @bickel2015mathematical or @lehmann2005testing, and concerns non-deterministic decision rules which the reject the null hypothesis with some probability when $T(\X) \in C$ (instead of with probability one)</span>
<span id="cb49-588"><a href="#cb49-588" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>The result says nothing about the uniqueness of the MP test.</span>
<span id="cb49-589"><a href="#cb49-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-590"><a href="#cb49-590" aria-hidden="true" tabindex="-1"></a>Theorem \@ref(thm:NPlemma) tells us that for simple hypotheses, our test statistic should be $T(\X) = \frac{f_\X(\x\mid\thet_1)}{f_\X(\x\mid\thet_0)}$, which makes a fair bit of sense. If we observe $\x$, then $f_\X(\x\mid\thet_1)$ and $f_\X(\x\mid\thet_0)$ are the probabilities we observe $\x$ given $\thet_1$ and $\thet_0$, respectively. In the event that $f_\X(\x\mid\thet_1) \gg f_\X(\x\mid\thet_0)$, it's so likely that $\thet = \thet_1$, that we should reject the null hypothesis. In other words, we reject the null hypothesis is the ratio of these probabilities is high enough. This ratio actually pops up elsewhere in statistics and has its own name.</span>
<span id="cb49-591"><a href="#cb49-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-592"><a href="#cb49-592" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-593"><a href="#cb49-593" aria-hidden="true" tabindex="-1"></a>The &lt;span style="color:red"&gt;**_likelihood ratio_**&lt;/span&gt; associated with densities $f_\X(\x\mid\thet_1)$ and  $f_\X(\x\mid\thet_0)$ is defined as </span>
<span id="cb49-594"><a href="#cb49-594" aria-hidden="true" tabindex="-1"></a>$$ L(\thet_1, \thet_0 \mid \x) = \frac{f_\X(\x\mid\thet_1)}{f_\X(\x\mid\thet_0)}.$$ </span>
<span id="cb49-595"><a href="#cb49-595" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-596"><a href="#cb49-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-597"><a href="#cb49-597" aria-hidden="true" tabindex="-1"></a>So how large does this ratio need to be such that we reject the null hypothesis? The Neyman-Pearson Lemma seems a bit vague here, as it only says that it needs to exceed *some* $\eta$. The proof gives us some mathematical context on $\eta$, but also fails to explicitly define it, so can we really pick *any* constant? Of course not, because we assume that $\delta(\X)$ has size $\alpha$. The actual value $\eta$ is implicitly given when we assume the size of $\delta(\X)$, but we can define is explicitly.</span>
<span id="cb49-598"><a href="#cb49-598" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-599"><a href="#cb49-599" aria-hidden="true" tabindex="-1"></a>&amp; \alpha = \Pr(T(\X) &gt; \eta \mid P_\thet = P_{\thet_0})<span class="sc">\\</span></span>
<span id="cb49-600"><a href="#cb49-600" aria-hidden="true" tabindex="-1"></a>\implies &amp; \alpha = 1 - \Pr(T(\X) \le \eta \mid P_\thet = P_{\thet_0})<span class="sc">\\</span></span>
<span id="cb49-601"><a href="#cb49-601" aria-hidden="true" tabindex="-1"></a>\implies &amp; \alpha = 1 - F_{T(\X)}(\eta \mid P_{\thet_0})<span class="sc">\\</span></span>
<span id="cb49-602"><a href="#cb49-602" aria-hidden="true" tabindex="-1"></a>\implies &amp; \eta = F_{T(\X)}^{-1}(1-\alpha \mid P_{\thet_0})</span>
<span id="cb49-603"><a href="#cb49-603" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-604"><a href="#cb49-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-605"><a href="#cb49-605" aria-hidden="true" tabindex="-1"></a>Let's see the Neyman-Pearson Lemma in action. </span>
<span id="cb49-606"><a href="#cb49-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-607"><a href="#cb49-607" aria-hidden="true" tabindex="-1"></a>:::{#exm-npnorm}</span>
<span id="cb49-608"><a href="#cb49-608" aria-hidden="true" tabindex="-1"></a>Suppose $X_i \iid N(\mu,\sigma^2)$ for a known $\sigma^2$, and </span>
<span id="cb49-609"><a href="#cb49-609" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-610"><a href="#cb49-610" aria-hidden="true" tabindex="-1"></a>H_0:\mu=\mu_0,<span class="sc">\\</span></span>
<span id="cb49-611"><a href="#cb49-611" aria-hidden="true" tabindex="-1"></a>H_1:\mu=\mu_1,</span>
<span id="cb49-612"><a href="#cb49-612" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-613"><a href="#cb49-613" aria-hidden="true" tabindex="-1"></a>where $\mu_1 &gt; \mu_0$. Our likelihood ratio is </span>
<span id="cb49-614"><a href="#cb49-614" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-615"><a href="#cb49-615" aria-hidden="true" tabindex="-1"></a>\frac{f_\X(\x\mid\mu_1)}{f_\X(\x\mid\mu_0)} &amp; = \frac{\prod_{i=1}^nf_{X_i}(x\mid\mu_1)}{\prod_{i=1}^nf_{X_i}(x\mid\mu_0)} <span class="sc">\\</span></span>
<span id="cb49-616"><a href="#cb49-616" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{\prod_{i=1}^n\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left<span class="co">[</span><span class="ot">-\frac{(x-\mu_1)^2}{2\sigma^2}\right</span><span class="co">]</span>}{\prod_{i=1}^n\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left<span class="co">[</span><span class="ot">-\frac{(x-\mu_0)^2}{2\sigma^2}\right</span><span class="co">]</span>}<span class="sc">\\</span></span>
<span id="cb49-617"><a href="#cb49-617" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{\prod_{i=1}^n\exp\left<span class="co">[</span><span class="ot">-\frac{(x-\mu_1)^2}{2\sigma^2}\right</span><span class="co">]</span>}{\prod_{i=1}^n\exp\left<span class="co">[</span><span class="ot">-\frac{(x-\mu_0)^2}{2\sigma^2}\right</span><span class="co">]</span>}<span class="sc">\\</span></span>
<span id="cb49-618"><a href="#cb49-618" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{\exp\left<span class="co">[</span><span class="ot">-\sum_{i=1}^n\frac{(x-\mu_1)^2}{2\sigma^2}\right</span><span class="co">]</span>}{\exp\left<span class="co">[</span><span class="ot">-\sum_{i=1}^n\frac{(x-\mu_0)^2}{2\sigma^2}\right</span><span class="co">]</span>}<span class="sc">\\</span> </span>
<span id="cb49-619"><a href="#cb49-619" aria-hidden="true" tabindex="-1"></a>&amp; = \exp\left<span class="co">[</span><span class="ot">\frac{1}{2\sigma^2}\left(\sum_{i=1}^n(x_i - \mu_0)^2 - \sum_{i=1}^n(x_i - \mu_1)^2\right)\right</span><span class="co">]</span><span class="sc">\\</span> </span>
<span id="cb49-620"><a href="#cb49-620" aria-hidden="true" tabindex="-1"></a>&amp; = \exp\left<span class="co">[</span><span class="ot">\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i^2 - x_i\mu_0 + \mu_0^2 - x_i^2  - x_i\mu_1 + \mu_1^2)\right</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb49-621"><a href="#cb49-621" aria-hidden="true" tabindex="-1"></a>&amp; = \exp\left<span class="co">[</span><span class="ot">\frac{1}{2\sigma^2}[n(\mu_0^2 - \mu_1^2) - 2n\bar x(\mu_0 - \mu_1)]\right</span><span class="co">]</span>.</span>
<span id="cb49-622"><a href="#cb49-622" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-623"><a href="#cb49-623" aria-hidden="true" tabindex="-1"></a>The Neyman-Pearson lemma says the critical region of our test should take the form</span>
<span id="cb49-624"><a href="#cb49-624" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-625"><a href="#cb49-625" aria-hidden="true" tabindex="-1"></a>C &amp; = \left<span class="sc">\{</span>\x\ \Big| \  \exp\left<span class="co">[</span><span class="ot">\frac{1}{2\sigma^2}[n(\mu_0^2 - \mu_1^2) - 2n\bar x(\mu_0 - \mu_1)]\right</span><span class="co">]</span> &gt; \eta\right<span class="sc">\}\\</span></span>
<span id="cb49-626"><a href="#cb49-626" aria-hidden="true" tabindex="-1"></a>  &amp; = \left<span class="sc">\{</span>\x\ \Big| \ \bar x &gt; \frac{\mu_0+\mu_1}{2} - \frac{\sigma^2 \ln \eta}{n(\mu_0-\mu_1)}\right<span class="sc">\}</span></span>
<span id="cb49-627"><a href="#cb49-627" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-628"><a href="#cb49-628" aria-hidden="true" tabindex="-1"></a>...okay so this looks like a monstrosity. Let's define the constant $\eta^*$ to as</span>
<span id="cb49-629"><a href="#cb49-629" aria-hidden="true" tabindex="-1"></a>$$\eta^* = \frac{\mu_0+\mu_1}{2} - \frac{\sigma^2 \ln \eta}{n(\mu_0-\mu_1)},$$ as to give us </span>
<span id="cb49-630"><a href="#cb49-630" aria-hidden="true" tabindex="-1"></a>$$ C = <span class="sc">\{</span>\x \mid \bar x &gt; \eta^*<span class="sc">\}</span>.$$</span>
<span id="cb49-631"><a href="#cb49-631" aria-hidden="true" tabindex="-1"></a>If we want our test to have a size of $\alpha$, we let $\eta^* = \mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}$, which is the same one sided test we've been exploring in this section! Therefore the most powerful test for $H_0 : \mu = \mu_1$ versus $H_1 : \mu = \mu_1$ is: </span>
<span id="cb49-632"><a href="#cb49-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-633"><a href="#cb49-633" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-634"><a href="#cb49-634" aria-hidden="true" tabindex="-1"></a>\delta(\X) &amp; = \begin{cases}\mu_0 &amp; \bar X &lt; \mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n} <span class="sc">\\</span> \mu_1 &amp; \bar X &gt; \mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}\end{cases} &amp; (T(\X) = \bar X)<span class="sc">\\</span></span>
<span id="cb49-635"><a href="#cb49-635" aria-hidden="true" tabindex="-1"></a>&amp; = \begin{cases}\mu_0 &amp; \frac{\bar X - \mu_0}{\sigma/\sqrt n} &lt; \Phi^{-1}(1-\alpha) <span class="sc">\\</span> \mu_1 &amp; \frac{\bar X - \mu_0}{\sigma/\sqrt n} &gt; \Phi^{-1}(1-\alpha) \end{cases}&amp; (T(\X) = (\bar X - \mu_0)/(\sigma/\sqrt n))</span>
<span id="cb49-636"><a href="#cb49-636" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-637"><a href="#cb49-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-638"><a href="#cb49-638" aria-hidden="true" tabindex="-1"></a>These decision rules are equivalent to the likelihood ratio test given by the Neyman-Pearson lemma. If we want to keep with the spirit of the lemma and insist on using the test statistic $T(\X) = \frac{f_\X(\x\mid\mu_1)}{f_\X(\x\mid\mu_0)}$, we need to solve for $\eta$.</span>
<span id="cb49-639"><a href="#cb49-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-640"><a href="#cb49-640" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-641"><a href="#cb49-641" aria-hidden="true" tabindex="-1"></a>&amp;\eta^* = \mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}<span class="sc">\\</span></span>
<span id="cb49-642"><a href="#cb49-642" aria-hidden="true" tabindex="-1"></a>\implies &amp; \frac{\mu_0+\mu_1}{2} - \frac{\sigma^2 \ln \eta}{n(\mu_0-\mu_1)} = \mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}<span class="sc">\\</span></span>
<span id="cb49-643"><a href="#cb49-643" aria-hidden="true" tabindex="-1"></a>\implies &amp; \eta = \exp\left<span class="co">[</span><span class="ot">-\left(\mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}\right)\left(\frac{n(\mu_0-\mu_1)}{\sigma^2}\right)\right</span><span class="co">]</span></span>
<span id="cb49-644"><a href="#cb49-644" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-645"><a href="#cb49-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-646"><a href="#cb49-646" aria-hidden="true" tabindex="-1"></a>This gives the decision rule </span>
<span id="cb49-647"><a href="#cb49-647" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-648"><a href="#cb49-648" aria-hidden="true" tabindex="-1"></a>\delta(\X) &amp;= \begin{cases}\mu_0 &amp; \frac{f_\X(\x\mid\mu_1)}{f_\X(\x\mid\mu_0)} &lt; \exp\left<span class="co">[</span><span class="ot">-\left(\mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}\right)\left(\frac{n(\mu_0-\mu_1)}{\sigma^2}\right)\right</span><span class="co">]</span> <span class="sc">\\</span> \mu_1 &amp; \frac{f_\X(\x\mid\mu_1)}{f_\X(\x\mid\mu_0)} &gt;\exp\left<span class="co">[</span><span class="ot">-\left(\mu_0 +\Phi^{-1}(1-\alpha) \frac{\sigma}{\sqrt n}\right)\left(\frac{n(\mu_0-\mu_1)}{\sigma^2}\right)\right</span><span class="co">]</span>\end{cases} &amp; (T(\X) = f_\X(\x\mid\mu_1)/f_\X(\x\mid\mu_0))</span>
<span id="cb49-649"><a href="#cb49-649" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-650"><a href="#cb49-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-651"><a href="#cb49-651" aria-hidden="true" tabindex="-1"></a>To confirm these three test are equivalent, let's simulate the decision rule for $H_0:\mu = 0$ versus $H_1: \mu = 3$, where $\sigma^2 = 1$, $n = 100$, $\alpha = 0.05$, and null hypothesis $\mu = 0$ is true. Not only should the tests agree for each simulation, but we should also see that we reject the null hypothesis (commit a type I error) with probability $\alpha$.</span>
<span id="cb49-652"><a href="#cb49-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-655"><a href="#cb49-655" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-656"><a href="#cb49-656" aria-hidden="true" tabindex="-1"></a>sample_mean_test <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu0, alpha, sigma){</span>
<span id="cb49-657"><a href="#cb49-657" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb49-658"><a href="#cb49-658" aria-hidden="true" tabindex="-1"></a>  test_stat <span class="ot">&lt;-</span> <span class="cf">function</span>(X) {</span>
<span id="cb49-659"><a href="#cb49-659" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>(X)</span>
<span id="cb49-660"><a href="#cb49-660" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb49-661"><a href="#cb49-661" aria-hidden="true" tabindex="-1"></a>  <span class="fu">test_stat</span>(X) <span class="sc">&gt;</span> mu0 <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha)<span class="sc">*</span>(sigma<span class="sc">/</span><span class="fu">sqrt</span>(n))    </span>
<span id="cb49-662"><a href="#cb49-662" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-663"><a href="#cb49-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-664"><a href="#cb49-664" aria-hidden="true" tabindex="-1"></a>z_score_test <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu0, alpha, sigma){</span>
<span id="cb49-665"><a href="#cb49-665" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb49-666"><a href="#cb49-666" aria-hidden="true" tabindex="-1"></a>  test_stat <span class="ot">&lt;-</span> <span class="cf">function</span>(X) {</span>
<span id="cb49-667"><a href="#cb49-667" aria-hidden="true" tabindex="-1"></a>    (<span class="fu">mean</span>(X) <span class="sc">-</span> mu0)<span class="sc">/</span>(sigma<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb49-668"><a href="#cb49-668" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb49-669"><a href="#cb49-669" aria-hidden="true" tabindex="-1"></a>  <span class="fu">test_stat</span>(X) <span class="sc">&gt;</span> <span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha)   </span>
<span id="cb49-670"><a href="#cb49-670" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-671"><a href="#cb49-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-672"><a href="#cb49-672" aria-hidden="true" tabindex="-1"></a>likelihood_ratio_test <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu0, mu1, alpha, sigma){</span>
<span id="cb49-673"><a href="#cb49-673" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb49-674"><a href="#cb49-674" aria-hidden="true" tabindex="-1"></a>  test_stat <span class="ot">&lt;-</span> <span class="cf">function</span>(X) {</span>
<span id="cb49-675"><a href="#cb49-675" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prod</span>(<span class="fu">dnorm</span>(X, mu1, sigma)) <span class="sc">/</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(X, mu0, sigma))</span>
<span id="cb49-676"><a href="#cb49-676" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb49-677"><a href="#cb49-677" aria-hidden="true" tabindex="-1"></a>  eta <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="sc">-</span>(mu0 <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha)<span class="sc">*</span>(sigma<span class="sc">/</span><span class="fu">sqrt</span>(n)) <span class="sc">-</span> (mu1<span class="sc">+</span>mu0)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>((n<span class="sc">*</span>(mu0<span class="sc">-</span>mu1)) <span class="sc">/</span>(sigma<span class="sc">^</span><span class="dv">2</span>)))</span>
<span id="cb49-678"><a href="#cb49-678" aria-hidden="true" tabindex="-1"></a>  <span class="fu">test_stat</span>(X) <span class="sc">&gt;</span> eta</span>
<span id="cb49-679"><a href="#cb49-679" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-680"><a href="#cb49-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-681"><a href="#cb49-681" aria-hidden="true" tabindex="-1"></a>iter <span class="ot">&lt;-</span> <span class="cf">function</span>(mu0, mu1, alpha, sigma, n, dist, dist_params, s){</span>
<span id="cb49-682"><a href="#cb49-682" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb49-683"><a href="#cb49-683" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb49-684"><a href="#cb49-684" aria-hidden="true" tabindex="-1"></a>    <span class="at">smt =</span> <span class="fu">sample_mean_test</span>(X, mu0, alpha, sigma),</span>
<span id="cb49-685"><a href="#cb49-685" aria-hidden="true" tabindex="-1"></a>    <span class="at">zst =</span> <span class="fu">z_score_test</span>(X, mu0, alpha, sigma),</span>
<span id="cb49-686"><a href="#cb49-686" aria-hidden="true" tabindex="-1"></a>    <span class="at">lrt =</span> <span class="fu">likelihood_ratio_test</span>(X, mu0, mu1, alpha, sigma),</span>
<span id="cb49-687"><a href="#cb49-687" aria-hidden="true" tabindex="-1"></a>    <span class="at">iter_num =</span> s</span>
<span id="cb49-688"><a href="#cb49-688" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-689"><a href="#cb49-689" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-690"><a href="#cb49-690" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-691"><a href="#cb49-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-692"><a href="#cb49-692" aria-hidden="true" tabindex="-1"></a>sim <span class="ot">&lt;-</span> <span class="cf">function</span>(N, mu0, mu1, alpha, sigma, n, dist, dist_params){</span>
<span id="cb49-693"><a href="#cb49-693" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb49-694"><a href="#cb49-694" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(</span>
<span id="cb49-695"><a href="#cb49-695" aria-hidden="true" tabindex="-1"></a>      iter, </span>
<span id="cb49-696"><a href="#cb49-696" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu0 =</span> mu0, </span>
<span id="cb49-697"><a href="#cb49-697" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu1 =</span> mu1, </span>
<span id="cb49-698"><a href="#cb49-698" aria-hidden="true" tabindex="-1"></a>      <span class="at">alpha =</span> alpha, </span>
<span id="cb49-699"><a href="#cb49-699" aria-hidden="true" tabindex="-1"></a>      <span class="at">sigma =</span> sigma, </span>
<span id="cb49-700"><a href="#cb49-700" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n, </span>
<span id="cb49-701"><a href="#cb49-701" aria-hidden="true" tabindex="-1"></a>      <span class="at">dist =</span> dist, </span>
<span id="cb49-702"><a href="#cb49-702" aria-hidden="true" tabindex="-1"></a>      <span class="at">dist_params =</span> dist_params</span>
<span id="cb49-703"><a href="#cb49-703" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-704"><a href="#cb49-704" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb49-705"><a href="#cb49-705" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-706"><a href="#cb49-706" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-707"><a href="#cb49-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-708"><a href="#cb49-708" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">sim</span>(<span class="fl">1e5</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="fl">0.05</span>, <span class="dv">1</span>, <span class="dv">100</span>, rnorm, <span class="fu">list</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb49-709"><a href="#cb49-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-710"><a href="#cb49-710" aria-hidden="true" tabindex="-1"></a><span class="co">#If all decisions were the same, this should be 1</span></span>
<span id="cb49-711"><a href="#cb49-711" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb49-712"><a href="#cb49-712" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob =</span> <span class="fu">mean</span>(smt <span class="sc">==</span> zst <span class="sc">&amp;</span> zst <span class="sc">==</span> lrt))</span>
<span id="cb49-713"><a href="#cb49-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-714"><a href="#cb49-714" aria-hidden="true" tabindex="-1"></a><span class="co">#Check number of rejections of the true null hypothesis</span></span>
<span id="cb49-715"><a href="#cb49-715" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(results<span class="sc">$</span>smt)</span>
<span id="cb49-716"><a href="#cb49-716" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-717"><a href="#cb49-717" aria-hidden="true" tabindex="-1"></a>This example is particularly special, because we were able to write the most powerful test in a form that did not depend on $\mu_1$:</span>
<span id="cb49-718"><a href="#cb49-718" aria-hidden="true" tabindex="-1"></a>$$\delta(\X) =\begin{cases}\mu_0 &amp; \frac{\bar X - \mu_0}{\sigma/\sqrt n} &gt; \Phi^{-1}(1-\alpha) <span class="sc">\\</span> \mu_1 &amp; \frac{\bar X - \mu_0}{\sigma/\sqrt n} &lt; \Phi^{-1}(1-\alpha) \end{cases}$$ The test statistic and critical region do not depend on $\mu_1$, so this test is the most powerful test for any alternative $\mu_1 &gt; \mu_0$. This means that this test is the most powerful test for any hypothesis of the form $H_0:\mu = \mu_0$ versus $\mu \ge \mu_0$. In fact, we can even go one step further -- this test is the most powerful test for any hypotheses of the form $H_0:\mu\le \mu_0$ versus $H_1:\mu &gt; \mu_0$! Consider testing $H_0:\mu = \mu_0$ versus $H_1:\mu \ge \mu_0$, and testing the modified hypothesis $H_0':\mu = \mu_0'$ versus $H_1':\mu \ge \mu_0'$, where $\mu_0'&lt;\mu_0$.</span>
<span id="cb49-719"><a href="#cb49-719" aria-hidden="true" tabindex="-1"></a>All we've done is slightly tweaked $H_0 : \mu \le \mu_0$ by lowering the value of $\mu_0'$. What happens if we attempt to test $H_0'$ versus $H_1'$ using the test statistic for $\delta(\X)$ (as given above) instead of the test statistic of its modified counterpart $\delta'(\X)$? </span>
<span id="cb49-720"><a href="#cb49-720" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-721"><a href="#cb49-721" aria-hidden="true" tabindex="-1"></a>T(\X)&amp;=\frac{\bar X - \mu_0}{\sigma/\sqrt n}<span class="sc">\\</span></span>
<span id="cb49-722"><a href="#cb49-722" aria-hidden="true" tabindex="-1"></a>T'(\X)&amp;=\frac{\bar X - \mu_0'}{\sigma/\sqrt n}</span>
<span id="cb49-723"><a href="#cb49-723" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-724"><a href="#cb49-724" aria-hidden="true" tabindex="-1"></a>Under $H_0'$: </span>
<span id="cb49-725"><a href="#cb49-725" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-726"><a href="#cb49-726" aria-hidden="true" tabindex="-1"></a>T'(\X) &amp; \sim N(0,1)<span class="sc">\\</span></span>
<span id="cb49-727"><a href="#cb49-727" aria-hidden="true" tabindex="-1"></a>T(\X) &amp; = \frac{\bar X - \mu_0'}{\sigma/\sqrt n} + \frac{\mu_0' - \mu_0}{\sigma/\sqrt n} = T'(\X) + \frac{\mu_0' - \mu_0}{\sigma/\sqrt n} \sim N\left(\frac{\mu_0' - \mu_0}{\sigma/\sqrt n}, 1\right)</span>
<span id="cb49-728"><a href="#cb49-728" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-729"><a href="#cb49-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-730"><a href="#cb49-730" aria-hidden="true" tabindex="-1"></a>If we calculate the power of $\delta'$, we find that</span>
<span id="cb49-731"><a href="#cb49-731" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-732"><a href="#cb49-732" aria-hidden="true" tabindex="-1"></a>c' &amp; = -\Phi^{-1}(\alpha),<span class="sc">\\</span></span>
<span id="cb49-733"><a href="#cb49-733" aria-hidden="true" tabindex="-1"></a>c &amp; = -\left<span class="co">[</span><span class="ot">\Phi^{-1}\left(\alpha\right) - \frac{\mu_0' - \mu_0}{\sigma/\sqrt n}\right</span><span class="co">]</span> = \frac{\mu_0' - \mu_0}{\sigma/\sqrt n}- \Phi^{-1}(\alpha).</span>
<span id="cb49-734"><a href="#cb49-734" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-735"><a href="#cb49-735" aria-hidden="true" tabindex="-1"></a>The power of the tests are </span>
<span id="cb49-736"><a href="#cb49-736" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-737"><a href="#cb49-737" aria-hidden="true" tabindex="-1"></a>\beta(\delta, \mu) &amp; = \Pr\left(T(\X) &gt; \frac{\mu_0' - \mu_0}{\sigma/\sqrt n}- \Phi^{-1}(\alpha)\ \bigg| \ \mu\right)<span class="sc">\\</span></span>
<span id="cb49-738"><a href="#cb49-738" aria-hidden="true" tabindex="-1"></a>&amp; = \Pr\left(T(\X) - \frac{\mu_0' - \mu_0}{\sigma/\sqrt n} &gt;  \Phi^{-1}(\alpha)\ \bigg| \ \mu\right)<span class="sc">\\</span></span>
<span id="cb49-739"><a href="#cb49-739" aria-hidden="true" tabindex="-1"></a>&amp; = \Pr\left(T'(\X) &gt; - \Phi^{-1}(\alpha)  \mid \mu\right)<span class="sc">\\</span></span>
<span id="cb49-740"><a href="#cb49-740" aria-hidden="true" tabindex="-1"></a>&amp; = \beta(\delta', \mu).</span>
<span id="cb49-741"><a href="#cb49-741" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-742"><a href="#cb49-742" aria-hidden="true" tabindex="-1"></a>Both tests have the same power, and same size, so $\delta$ is the most powerful test for any $H_0':\mu \neq \mu_0'$ versus $H_1':\mu &gt; \mu_0'$ where $\mu_0'&lt;\mu_0$. We can confirm this with simulations:</span>
<span id="cb49-743"><a href="#cb49-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-746"><a href="#cb49-746" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-747"><a href="#cb49-747" aria-hidden="true" tabindex="-1"></a>curve <span class="ot">&lt;-</span> <span class="fu">power_curve</span>(</span>
<span id="cb49-748"><a href="#cb49-748" aria-hidden="true" tabindex="-1"></a>  <span class="at">domain =</span> <span class="fu">seq</span>(<span class="fl">2.6</span>, <span class="fl">3.3</span>, <span class="at">length =</span> <span class="dv">10</span>), <span class="do">## update to 40</span></span>
<span id="cb49-749"><a href="#cb49-749" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e3</span>, <span class="do">## update to 1e4</span></span>
<span id="cb49-750"><a href="#cb49-750" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> delta, </span>
<span id="cb49-751"><a href="#cb49-751" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_stat =</span> test_stat,</span>
<span id="cb49-752"><a href="#cb49-752" aria-hidden="true" tabindex="-1"></a>  <span class="at">critical_region =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="fu">qnorm</span>(<span class="fl">0.05</span>), <span class="cn">Inf</span>)),</span>
<span id="cb49-753"><a href="#cb49-753" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_0 =</span> <span class="fl">2.7</span>,</span>
<span id="cb49-754"><a href="#cb49-754" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="dv">1</span>, </span>
<span id="cb49-755"><a href="#cb49-755" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span></span>
<span id="cb49-756"><a href="#cb49-756" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-757"><a href="#cb49-757" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">decision =</span> <span class="st">"δ"</span>)</span>
<span id="cb49-758"><a href="#cb49-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-759"><a href="#cb49-759" aria-hidden="true" tabindex="-1"></a>curve_prime <span class="ot">&lt;-</span> <span class="fu">power_curve</span>(</span>
<span id="cb49-760"><a href="#cb49-760" aria-hidden="true" tabindex="-1"></a>  <span class="at">domain =</span> <span class="fu">seq</span>(<span class="fl">2.6</span>, <span class="fl">3.3</span>, <span class="at">length =</span> <span class="dv">10</span>), <span class="do">## update to 40</span></span>
<span id="cb49-761"><a href="#cb49-761" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e3</span> , <span class="do">## update to 1e4</span></span>
<span id="cb49-762"><a href="#cb49-762" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> delta, </span>
<span id="cb49-763"><a href="#cb49-763" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_stat =</span> test_stat,</span>
<span id="cb49-764"><a href="#cb49-764" aria-hidden="true" tabindex="-1"></a>  <span class="at">critical_region =</span> <span class="fu">list</span>(<span class="fu">c</span>((<span class="fl">2.7</span> <span class="sc">-</span> <span class="dv">3</span>)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">100</span>)) <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="fl">0.05</span>), <span class="cn">Inf</span>)),</span>
<span id="cb49-765"><a href="#cb49-765" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_0 =</span> <span class="dv">3</span>,</span>
<span id="cb49-766"><a href="#cb49-766" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="dv">1</span>, </span>
<span id="cb49-767"><a href="#cb49-767" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span></span>
<span id="cb49-768"><a href="#cb49-768" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-769"><a href="#cb49-769" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">decision =</span> <span class="st">"δ'"</span>)</span>
<span id="cb49-770"><a href="#cb49-770" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-771"><a href="#cb49-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-774"><a href="#cb49-774" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-775"><a href="#cb49-775" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-776"><a href="#cb49-776" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot36</span></span>
<span id="cb49-777"><a href="#cb49-777" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-778"><a href="#cb49-778" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-779"><a href="#cb49-779" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-780"><a href="#cb49-780" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Simulated power curve for the two null hypotheses"</span></span>
<span id="cb49-781"><a href="#cb49-781" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-782"><a href="#cb49-782" aria-hidden="true" tabindex="-1"></a>curve <span class="sc">%&gt;%</span> </span>
<span id="cb49-783"><a href="#cb49-783" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(curve_prime) <span class="sc">%&gt;%</span> </span>
<span id="cb49-784"><a href="#cb49-784" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t, simulated_power, <span class="at">color =</span> decision)) <span class="sc">+</span></span>
<span id="cb49-785"><a href="#cb49-785" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb49-786"><a href="#cb49-786" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>)) <span class="sc">+</span></span>
<span id="cb49-787"><a href="#cb49-787" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-788"><a href="#cb49-788" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"μ"</span>, <span class="at">y =</span> <span class="st">"Simulated Power"</span>, <span class="at">color =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb49-789"><a href="#cb49-789" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb49-790"><a href="#cb49-790" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-791"><a href="#cb49-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-792"><a href="#cb49-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-793"><a href="#cb49-793" aria-hidden="true" tabindex="-1"></a>This will hold for all hypotheses $H_1':\mu\le \mu_0'$ where $\mu_0'$, as $\mu_0'$ was arbitrary. This means that if we are testing $H_0:\mu \le \mu_0$ versus $H_1:\mu&gt;\mu_0$, the most powerful test is the z-test, regardless of the specified $\mu_0$ or alternative $\mu$. Because we pick the test that was derived using $H_0:\mu = \mu_0$, we often write </span>
<span id="cb49-794"><a href="#cb49-794" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-795"><a href="#cb49-795" aria-hidden="true" tabindex="-1"></a>H_0&amp;:\mu=\mu_0,<span class="sc">\\</span></span>
<span id="cb49-796"><a href="#cb49-796" aria-hidden="true" tabindex="-1"></a>H_1&amp;:\mu&gt;\mu_0.</span>
<span id="cb49-797"><a href="#cb49-797" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-798"><a href="#cb49-798" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-799"><a href="#cb49-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-800"><a href="#cb49-800" aria-hidden="true" tabindex="-1"></a>While this example started as an application of the Neyman-Pearson lemma, it took several interesting turns. Firstly, while the Neyman-Pearson lemma gives the most powerful test in terms of the likelihood ratio, we were able to find several equivalent tests. Secondly, the most powerful test for the simple hypothesis $H_0: \mu = \mu_0$ versus $H_1:\mu = \mu_1$ (where $\mu_1 &gt; \mu_0$), as given by the Neyman-Pearson lemma, did not depend on $\mu_1$. This meant it was the most powerful test for $H_0: \mu = \mu_0$ versus $H_1:\mu &gt; \mu_0$. It is uniform in its status as the most powerful test.</span>
<span id="cb49-801"><a href="#cb49-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-802"><a href="#cb49-802" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-803"><a href="#cb49-803" aria-hidden="true" tabindex="-1"></a>A decision rule $\delta(\X)$, with size $\alpha$, is the  &lt;span style="color:red"&gt;**_uniformly most powerful (UMP)_**&lt;/span&gt; test for $H_0: P_{\thet}\in\mathcal P_0$ versus $H_1: P_{\thet}\in\mathcal P_1$ if </span>
<span id="cb49-804"><a href="#cb49-804" aria-hidden="true" tabindex="-1"></a>$$ \beta(\delta,P_\thet) \ge \beta(\delta',P_\thet) \ \ \ \text{for all }P_\thet\in\mathcal P_1$$</span>
<span id="cb49-805"><a href="#cb49-805" aria-hidden="true" tabindex="-1"></a>for all other decision rules $\delta'$ with a size of at least $\alpha$.</span>
<span id="cb49-806"><a href="#cb49-806" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-807"><a href="#cb49-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-808"><a href="#cb49-808" aria-hidden="true" tabindex="-1"></a>We also were able to establish that the UMP test for $H_0: \mu = \mu_0$ versus $H_1:\mu &gt; \mu_0$, is the UMP for any test of the form $H_0:\mu \le \mu_0$ versus $H_1:\mu &gt;\mu_0$. Despite the Neyman-Pearson lemma only holding for simple hypotheses, we were able to derive the optimal (in the sense of power) test for composite hypotheses in this case. Is this always the case, or was there something special at work? Let's look at another example to get a better lay of the land. </span>
<span id="cb49-809"><a href="#cb49-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-810"><a href="#cb49-810" aria-hidden="true" tabindex="-1"></a>:::{#exm-}</span>
<span id="cb49-811"><a href="#cb49-811" aria-hidden="true" tabindex="-1"></a>Suppose we draw a single observation of $X$ where $X\sim \text{Cauchy}(\theta,1)$ and want to test $H_0:\theta = 0$ versus $H_1:\theta = \theta_1$. In this case</span>
<span id="cb49-812"><a href="#cb49-812" aria-hidden="true" tabindex="-1"></a>$$f_X(x\mid\theta)= \frac{1}{\pi(1+(x-\theta)^2)},$$ so the Neyman-Pearson lemma tells us the most powerful test is </span>
<span id="cb49-813"><a href="#cb49-813" aria-hidden="true" tabindex="-1"></a>$$\delta(X) = \begin{cases}0 &amp; \frac{1+x^2}{1+(x-\theta_1)^2} &lt; \eta<span class="sc">\\</span> \theta_1 &amp; \frac{1+x^2}{1+(x-\theta_1)^2} &gt; \eta\end{cases}.$$</span>
<span id="cb49-814"><a href="#cb49-814" aria-hidden="true" tabindex="-1"></a>To get a better sense of what the critical region for this test is, let's plot the likelihood ratio. </span>
<span id="cb49-815"><a href="#cb49-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-818"><a href="#cb49-818" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-819"><a href="#cb49-819" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-820"><a href="#cb49-820" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-821"><a href="#cb49-821" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot37</span></span>
<span id="cb49-822"><a href="#cb49-822" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-823"><a href="#cb49-823" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-824"><a href="#cb49-824" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "The liklihood ratio associated with the Cauchy distribution. The liklihood ratio test tells us to reject the null hypothesis whenever the ratio exceeds η"</span></span>
<span id="cb49-825"><a href="#cb49-825" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-826"><a href="#cb49-826" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb49-827"><a href="#cb49-827" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">10</span>, <span class="at">length =</span> <span class="dv">3000</span>), </span>
<span id="cb49-828"><a href="#cb49-828" aria-hidden="true" tabindex="-1"></a>  <span class="at">alt_par =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">1.2</span>, <span class="fl">1.4</span>,<span class="fl">1.6</span>,<span class="fl">1.8</span>,<span class="dv">2</span>)</span>
<span id="cb49-829"><a href="#cb49-829" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-830"><a href="#cb49-830" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">dcauchy</span>(x, alt_par, <span class="dv">1</span>)<span class="sc">/</span><span class="fu">dcauchy</span>(x, <span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-831"><a href="#cb49-831" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x,y, <span class="at">color =</span> <span class="fu">as.factor</span>(alt_par))) <span class="sc">+</span> </span>
<span id="cb49-832"><a href="#cb49-832" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb49-833"><a href="#cb49-833" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Likelihood Ratio"</span>) <span class="sc">+</span></span>
<span id="cb49-834"><a href="#cb49-834" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Value of Single Observation"</span>) <span class="sc">+</span></span>
<span id="cb49-835"><a href="#cb49-835" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-836"><a href="#cb49-836" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">2</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb49-837"><a href="#cb49-837" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">color =</span> <span class="st">"Alternative θ"</span>) <span class="sc">+</span></span>
<span id="cb49-838"><a href="#cb49-838" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>) <span class="sc">+</span></span>
<span id="cb49-839"><a href="#cb49-839" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="sc">-</span><span class="dv">3</span>, <span class="at">y =</span> <span class="fl">2.3</span>, <span class="at">label =</span> <span class="st">"η"</span>)</span>
<span id="cb49-840"><a href="#cb49-840" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-841"><a href="#cb49-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-842"><a href="#cb49-842" aria-hidden="true" tabindex="-1"></a>Our rejection region will be a bounded interval. After some quick algebra, we find that the critical region is </span>
<span id="cb49-843"><a href="#cb49-843" aria-hidden="true" tabindex="-1"></a>$$C = \left<span class="sc">\{</span>x\ \Bigg| \ \frac{\eta\theta_1-\sqrt{\eta\theta_1^2+2\eta-\eta^2-1}}{\eta-1}&lt; x &lt;\frac{\eta\theta_1+\sqrt{\eta\theta_1^2+2\eta-\eta^2-1}}{\eta-1} \right<span class="sc">\}</span>.$$ Fixing $\eta$ to be some value, say $\eta = 2$, we can plot these critical regions across values of $\theta_1$.</span>
<span id="cb49-844"><a href="#cb49-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-847"><a href="#cb49-847" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-848"><a href="#cb49-848" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-849"><a href="#cb49-849" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-850"><a href="#cb49-850" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot38</span></span>
<span id="cb49-851"><a href="#cb49-851" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-852"><a href="#cb49-852" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-853"><a href="#cb49-853" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "The critical regions associated with the liklihood ratio test for varying alternatives. None of the critial regions are subsets of others."</span></span>
<span id="cb49-854"><a href="#cb49-854" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-855"><a href="#cb49-855" aria-hidden="true" tabindex="-1"></a>eta <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb49-856"><a href="#cb49-856" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(<span class="at">par =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="fl">1.2</span>,<span class="fl">1.4</span>,<span class="fl">1.6</span>,<span class="fl">1.8</span>,<span class="dv">2</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-857"><a href="#cb49-857" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb49-858"><a href="#cb49-858" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> (eta<span class="sc">*</span>par <span class="sc">-</span> <span class="fu">sqrt</span>(eta<span class="sc">*</span>par<span class="sc">^</span><span class="dv">2</span><span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>eta<span class="sc">-</span>eta<span class="sc">^</span><span class="dv">2-1</span>)) <span class="sc">/</span> (eta <span class="sc">-</span> <span class="dv">1</span>),</span>
<span id="cb49-859"><a href="#cb49-859" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper =</span> (eta<span class="sc">*</span>par <span class="sc">+</span> <span class="fu">sqrt</span>(eta<span class="sc">*</span>par<span class="sc">^</span><span class="dv">2</span><span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>eta<span class="sc">-</span>eta<span class="sc">^</span><span class="dv">2-1</span>)) <span class="sc">/</span> (eta <span class="sc">-</span> <span class="dv">1</span>),</span>
<span id="cb49-860"><a href="#cb49-860" aria-hidden="true" tabindex="-1"></a>    <span class="at">val =</span> (upper <span class="sc">+</span> lower)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb49-861"><a href="#cb49-861" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-862"><a href="#cb49-862" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(par, val)) <span class="sc">+</span></span>
<span id="cb49-863"><a href="#cb49-863" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper)) <span class="sc">+</span></span>
<span id="cb49-864"><a href="#cb49-864" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-865"><a href="#cb49-865" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Alternative θ"</span>, <span class="at">y =</span> <span class="st">"Critical Region"</span>)</span>
<span id="cb49-866"><a href="#cb49-866" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-867"><a href="#cb49-867" aria-hidden="true" tabindex="-1"></a>The upper and lower bounds depend on the alternate $\theta_1$ so the most powerful test for one choice of $\theta_1$ fails to be the most powerful test for another $\theta_1'$.</span>
<span id="cb49-868"><a href="#cb49-868" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-869"><a href="#cb49-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-870"><a href="#cb49-870" aria-hidden="true" tabindex="-1"></a>So what makes this different from the example with the normal distribution? Fixing $H_0:\mu_0 = 0$, $\sigma^2 = 1$, and $n=1$, Let's see if the likelihood ratio for normally distributed data has any clues.</span>
<span id="cb49-871"><a href="#cb49-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-874"><a href="#cb49-874" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-875"><a href="#cb49-875" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-876"><a href="#cb49-876" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-877"><a href="#cb49-877" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot39</span></span>
<span id="cb49-878"><a href="#cb49-878" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-879"><a href="#cb49-879" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-880"><a href="#cb49-880" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "The liklihood ratio associated with the standard normal distribution"</span></span>
<span id="cb49-881"><a href="#cb49-881" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-882"><a href="#cb49-882" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb49-883"><a href="#cb49-883" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="at">length =</span> <span class="dv">3000</span>), </span>
<span id="cb49-884"><a href="#cb49-884" aria-hidden="true" tabindex="-1"></a>  <span class="at">alt_par =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">1.2</span>, <span class="fl">1.4</span>,<span class="fl">1.6</span>,<span class="fl">1.8</span>,<span class="dv">2</span>)</span>
<span id="cb49-885"><a href="#cb49-885" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-886"><a href="#cb49-886" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">dnorm</span>(x, alt_par, <span class="dv">1</span>)<span class="sc">/</span><span class="fu">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-887"><a href="#cb49-887" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x,y, <span class="at">color =</span> <span class="fu">as.factor</span>(alt_par))) <span class="sc">+</span> </span>
<span id="cb49-888"><a href="#cb49-888" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb49-889"><a href="#cb49-889" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-890"><a href="#cb49-890" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Value of Single Observation"</span>, <span class="at">y =</span> <span class="st">"Likelihood Ratio"</span>, <span class="at">color =</span> <span class="st">"Alternative μ"</span>) <span class="sc">+</span></span>
<span id="cb49-891"><a href="#cb49-891" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb49-892"><a href="#cb49-892" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-893"><a href="#cb49-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-894"><a href="#cb49-894" aria-hidden="true" tabindex="-1"></a>Now let's plot the critical region </span>
<span id="cb49-895"><a href="#cb49-895" aria-hidden="true" tabindex="-1"></a>$$ C = \left<span class="sc">\{</span>x \mid x &gt; \mu_1/2 + \ln \eta / \mu_1\right<span class="sc">\}</span>$$</span>
<span id="cb49-896"><a href="#cb49-896" aria-hidden="true" tabindex="-1"></a>for varying alternatives $\mu_1$, fixing $\eta = 2$ (which is equivalent to fixing the size $\alpha$).</span>
<span id="cb49-897"><a href="#cb49-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-900"><a href="#cb49-900" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-901"><a href="#cb49-901" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-902"><a href="#cb49-902" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-903"><a href="#cb49-903" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot310</span></span>
<span id="cb49-904"><a href="#cb49-904" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-905"><a href="#cb49-905" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-906"><a href="#cb49-906" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: " The critical regions associated with the liklihood ratio test for varying alternatives. As we increase the alternative μ, each critical region is a subset of the prior one."</span></span>
<span id="cb49-907"><a href="#cb49-907" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-908"><a href="#cb49-908" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(<span class="at">par =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="fl">1.2</span>,<span class="fl">1.4</span>,<span class="fl">1.6</span>,<span class="fl">1.8</span>,<span class="dv">2</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-909"><a href="#cb49-909" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb49-910"><a href="#cb49-910" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> par<span class="sc">/</span><span class="dv">2</span> <span class="sc">-</span> (<span class="fu">log</span>(<span class="dv">2</span>))<span class="sc">/</span>(par),</span>
<span id="cb49-911"><a href="#cb49-911" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper =</span> <span class="cn">Inf</span>,</span>
<span id="cb49-912"><a href="#cb49-912" aria-hidden="true" tabindex="-1"></a>    <span class="at">val =</span> (upper <span class="sc">+</span> lower)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb49-913"><a href="#cb49-913" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-914"><a href="#cb49-914" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(par, val)) <span class="sc">+</span></span>
<span id="cb49-915"><a href="#cb49-915" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper)) <span class="sc">+</span></span>
<span id="cb49-916"><a href="#cb49-916" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-917"><a href="#cb49-917" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Alternative μ"</span>, <span class="at">y =</span> <span class="st">"Critical Region"</span>)</span>
<span id="cb49-918"><a href="#cb49-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-919"><a href="#cb49-919" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-920"><a href="#cb49-920" aria-hidden="true" tabindex="-1"></a>As $\mu_1$ increases, each critical region is a subset of the prior. In other words, for $\mu_1' &gt; \mu_1$,</span>
<span id="cb49-921"><a href="#cb49-921" aria-hidden="true" tabindex="-1"></a>$$ x &gt; \frac{\mu_1'}{2} + \frac{\ln \eta}{\mu_1'} \implies x &gt; \frac{\mu_1}{2} + \frac{\ln \eta}{\mu_1}.$$ If we reject the null hypothesis for $\mu_1'$, we will reject it for $\mu_1$. If we want to pick the critical region that gives us the most power out of these options (subject to the fixed size $\alpha$), we should pick the largest one, as it maximizes our chance of rejecting the null hypothesis, and is is a superset of the other choices of critical region. It is essential that the critical regions nest in one another like this as. Such sets are often called a monotonic sequence of sets, which is interesting, as the corresponding likelihood ratio is monotonically increasing for any $\theta_1&gt;\theta_0$. This monotonicity turns out to be the key to extending the Neyman-Pearson lemma to composite hypotheses.</span>
<span id="cb49-922"><a href="#cb49-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-923"><a href="#cb49-923" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-924"><a href="#cb49-924" aria-hidden="true" tabindex="-1"></a>A density $f_{\X}(\x\mid \theta)$ has a &lt;span style="color:red"&gt;**_monotone likelihood ratio (MLR) with respect to a statistic $T$_**&lt;/span&gt; if $f(\x \mid \theta_1)/f(\x \mid \theta_0)$ can be written as $f_{\X}(T(\x) \mid \theta_1)/f_{\X}(T(\x) \mid \theta_0)$, and $f_{\X}(T(\x) \mid \theta_1)/f_{\X}(T(\x) \mid \theta_0)$ is a monotonically increasing function in $T(\x)$ for $\theta_1 &gt; \theta_0$.</span>
<span id="cb49-925"><a href="#cb49-925" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-926"><a href="#cb49-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-927"><a href="#cb49-927" aria-hidden="true" tabindex="-1"></a>In Example \@ref(exm:npnorm), the normal distribution has an increasing MLR in the statistic $T(\X) = \bar X$.</span>
<span id="cb49-928"><a href="#cb49-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-929"><a href="#cb49-929" aria-hidden="true" tabindex="-1"></a>:::{#thm-KR}</span>
<span id="cb49-930"><a href="#cb49-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-931"><a href="#cb49-931" aria-hidden="true" tabindex="-1"></a><span class="fu">## Karlin-Rubin Theorem</span></span>
<span id="cb49-932"><a href="#cb49-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-933"><a href="#cb49-933" aria-hidden="true" tabindex="-1"></a>Suppose $f_{\X}(\x\mid \theta)$ has an increasing MLR in the statistic $T$. The decision rule $\delta(\X)$ defined as </span>
<span id="cb49-934"><a href="#cb49-934" aria-hidden="true" tabindex="-1"></a>$$ \delta(\X) = \begin{cases} \mathcal P_1 &amp; T(\X) &gt; \eta <span class="sc">\\</span></span>
<span id="cb49-935"><a href="#cb49-935" aria-hidden="true" tabindex="-1"></a>\mathcal P_0  &amp; T(\X) &lt; \eta</span>
<span id="cb49-936"><a href="#cb49-936" aria-hidden="true" tabindex="-1"></a>\end{cases}$$ is the UMP test for $H_0: \theta \le \theta_0$ versus $H_1:\theta &gt; \theta_0$. Additionally, the power function $\beta(\delta, \theta)$ is monotonically increasing. Analogously, </span>
<span id="cb49-937"><a href="#cb49-937" aria-hidden="true" tabindex="-1"></a>$$ \delta(\X) = \begin{cases} \mathcal P_1 &amp; T(\X) &lt; \eta <span class="sc">\\</span></span>
<span id="cb49-938"><a href="#cb49-938" aria-hidden="true" tabindex="-1"></a>\mathcal P_0  &amp; T(\X) &gt; \eta</span>
<span id="cb49-939"><a href="#cb49-939" aria-hidden="true" tabindex="-1"></a>\end{cases}$$ is the UMP test for $H_0: \theta \ge \theta_0$ versus $H_1:\theta &lt; \theta_0$, and the power function is monotonically decreasing.</span>
<span id="cb49-940"><a href="#cb49-940" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-941"><a href="#cb49-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-942"><a href="#cb49-942" aria-hidden="true" tabindex="-1"></a>:::{.proof}</span>
<span id="cb49-943"><a href="#cb49-943" aria-hidden="true" tabindex="-1"></a>See @degroot2012probability.</span>
<span id="cb49-944"><a href="#cb49-944" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-945"><a href="#cb49-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-946"><a href="#cb49-946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-947"><a href="#cb49-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-948"><a href="#cb49-948" aria-hidden="true" tabindex="-1"></a>:::{#exm- name="Testing Variance"}</span>
<span id="cb49-949"><a href="#cb49-949" aria-hidden="true" tabindex="-1"></a>Suppose we want to test $H_0:\sigma^2 \ge \sigma_0^2$ versus $H_1:\sigma^2 &lt; \sigma_0^2$ where $X_i \iid N(\mu,\sigma^2)$ for a known $\mu$. For $\sigma_1^2 &lt; \sigma_0^2$, the likelihood ratio of the joint distribution of our data is \begin{align*}</span>
<span id="cb49-950"><a href="#cb49-950" aria-hidden="true" tabindex="-1"></a>\frac{f_\X(\x\mid\sigma_1^2)}{f_\X(\x\mid\sigma_0^2)} &amp; = \frac{\prod_{i=1}^nf_{X_i}(x\mid\sigma_1^2)}{\prod_{i=1}^nf_{X_i}(x\mid\sigma_0^2)} <span class="sc">\\</span> </span>
<span id="cb49-951"><a href="#cb49-951" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{\left(\frac{1}{\sigma_1\sqrt{2\pi}}\right)^n}{\left(\frac{1}{\sigma_0\sqrt{2\pi}}\right)^n}\frac{\exp\left<span class="co">[</span><span class="ot">-\sum_{i=1}^n\frac{(x_i-\mu)^2}{2\sigma_1^2}\right</span><span class="co">]</span>}{\exp\left<span class="co">[</span><span class="ot">-\sum_{i=1}^n\frac{(x_i-\mu)^2}{2\sigma_0^2}\right</span><span class="co">]</span>}<span class="sc">\\</span> &amp; = \left(\frac{\sigma_0}{\sigma_1}\right)^{n}</span>
<span id="cb49-952"><a href="#cb49-952" aria-hidden="true" tabindex="-1"></a>\exp \left<span class="co">[</span><span class="ot">\sum_{i=1}^n\frac{(x_i-\mu)^2}{2\sigma_0^2}-\sum_{i=1}^n\frac{(x_i-\mu)^2}{2\sigma_1^2}  \right</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb49-953"><a href="#cb49-953" aria-hidden="true" tabindex="-1"></a>&amp; = \left(\frac{\sigma_1^2}{\sigma_0^2}\right)^{-n/2}</span>
<span id="cb49-954"><a href="#cb49-954" aria-hidden="true" tabindex="-1"></a>\exp \left<span class="co">[</span><span class="ot">-\frac{1}{2(\sigma_1^2 - \sigma_0^2)}\sum_{i=1}^n(x_i-\mu)^2 \right</span><span class="co">]</span>  <span class="sc">\\</span></span>
<span id="cb49-955"><a href="#cb49-955" aria-hidden="true" tabindex="-1"></a>&amp; = \left(\frac{\sigma_1^2}{\sigma_0^2}\right)^{-n/2}</span>
<span id="cb49-956"><a href="#cb49-956" aria-hidden="true" tabindex="-1"></a>\exp \left<span class="co">[</span><span class="ot">-\frac{T(\x)}{2(\sigma_1^2 - \sigma_0^2)} \right</span><span class="co">]</span> </span>
<span id="cb49-957"><a href="#cb49-957" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-958"><a href="#cb49-958" aria-hidden="true" tabindex="-1"></a>If we define $T(\X) = \sum_{i=1}^n(X_i-\mu)^2$, then the likelihood ratio is monotonically decreasing for $\sigma_1^2 &lt; \sigma_0^2$ (meaning $\sigma_1^2 - \sigma_0^2 &lt; 0$).  </span>
<span id="cb49-959"><a href="#cb49-959" aria-hidden="true" tabindex="-1"></a>$$ \frac{\partial}{\partial T(\x)}\left<span class="co">[</span><span class="ot">\frac{f_\X(\x\mid\sigma_1^2)}{f_\X(\x\mid\sigma_0^2)}\right</span><span class="co">]</span> = -\frac{1}{2(\sigma_1^2 - \sigma_0^2)}\cdot \left<span class="co">[</span><span class="ot">\frac{f_\X(\x\mid\sigma_1^2)}{f_\X(\x\mid\sigma_0^2)}\right</span><span class="co">]</span> &gt; 0.$$</span>
<span id="cb49-960"><a href="#cb49-960" aria-hidden="true" tabindex="-1"></a>This means the UMP test takes the form </span>
<span id="cb49-961"><a href="#cb49-961" aria-hidden="true" tabindex="-1"></a>$$\delta(\X) = \begin{cases} \sigma^2 &lt; \sigma_0^2 &amp; \sum_{i=1}^n(X_i-\mu)^2 &lt; \eta <span class="sc">\\</span></span>
<span id="cb49-962"><a href="#cb49-962" aria-hidden="true" tabindex="-1"></a>\mathcal \sigma^2 \ge \sigma_0^2 &amp; \sum_{i=1}^n(X_i-\mu)^2 &gt; \eta</span>
<span id="cb49-963"><a href="#cb49-963" aria-hidden="true" tabindex="-1"></a>\end{cases}.$$ If we define $\eta^* = 1/\sigma_0^2$, then </span>
<span id="cb49-964"><a href="#cb49-964" aria-hidden="true" tabindex="-1"></a>$$\delta(\X) = \begin{cases} \sigma^2 &lt; \sigma_0^2 &amp; \sum_{i=1}^n\left(\frac{X_i-\mu}{\sigma_0}\right)^2 &lt; \eta^* <span class="sc">\\</span></span>
<span id="cb49-965"><a href="#cb49-965" aria-hidden="true" tabindex="-1"></a>\mathcal \sigma^2 \ge \sigma_0^2 &amp; \sum_{i=1}^n\left(\frac{X_i-\mu}{\sigma_0}\right)^2 &gt; \eta^*</span>
<span id="cb49-966"><a href="#cb49-966" aria-hidden="true" tabindex="-1"></a>\end{cases}.$$ Writing our test like this is far more useful, because $T(\X)$ is now the sum of $n$ random variables which are distributed according to a standard normal distribution, i.e $T(\X) \sim \chi^2_n$. This allows us to easily calculate $\eta^*$ given a desired size $\alpha$ using the quantile function for $T(\X) \sim \chi^2_n$.</span>
<span id="cb49-967"><a href="#cb49-967" aria-hidden="true" tabindex="-1"></a>$$\delta(\X) = \begin{cases} \sigma^2 &lt; \sigma_0^2 &amp; \sum_{i=1}^n\left(\frac{X_i-\mu}{\sigma_0}\right)^2 &lt; (\chi^2_n)^{-1}(\alpha) <span class="sc">\\</span></span>
<span id="cb49-968"><a href="#cb49-968" aria-hidden="true" tabindex="-1"></a>\mathcal \sigma^2 \ge \sigma_0^2 &amp; \sum_{i=1}^n\left(\frac{X_i-\mu}{\sigma_0}\right)^2 &gt; (\chi^2_n)^{-1}(\alpha)</span>
<span id="cb49-969"><a href="#cb49-969" aria-hidden="true" tabindex="-1"></a>\end{cases}$$</span>
<span id="cb49-970"><a href="#cb49-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-973"><a href="#cb49-973" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-974"><a href="#cb49-974" aria-hidden="true" tabindex="-1"></a>test_stat <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu, sigma_0){</span>
<span id="cb49-975"><a href="#cb49-975" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(((X <span class="sc">-</span> mu)<span class="sc">/</span>sigma_0)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb49-976"><a href="#cb49-976" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-977"><a href="#cb49-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-978"><a href="#cb49-978" aria-hidden="true" tabindex="-1"></a>delta <span class="ot">&lt;-</span> <span class="cf">function</span>(test_stat, critical_region, X, mu, sigma_0){</span>
<span id="cb49-979"><a href="#cb49-979" aria-hidden="true" tabindex="-1"></a>  stat <span class="ot">&lt;-</span> <span class="fu">test_stat</span>(X, mu, sigma_0)</span>
<span id="cb49-980"><a href="#cb49-980" aria-hidden="true" tabindex="-1"></a>  decision <span class="ot">&lt;-</span> critical_region <span class="sc">%&gt;%</span> </span>
<span id="cb49-981"><a href="#cb49-981" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map_lgl</span>(\(bounds) <span class="fu">between</span>(stat, bounds[<span class="dv">1</span>], bounds[<span class="dv">2</span>])) <span class="sc">%&gt;%</span> </span>
<span id="cb49-982"><a href="#cb49-982" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb49-983"><a href="#cb49-983" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.logical</span>()</span>
<span id="cb49-984"><a href="#cb49-984" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-985"><a href="#cb49-985" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb49-986"><a href="#cb49-986" aria-hidden="true" tabindex="-1"></a>    <span class="at">stat =</span> stat,</span>
<span id="cb49-987"><a href="#cb49-987" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> decision,</span>
<span id="cb49-988"><a href="#cb49-988" aria-hidden="true" tabindex="-1"></a>    <span class="at">H_0 =</span> sigma_0</span>
<span id="cb49-989"><a href="#cb49-989" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-990"><a href="#cb49-990" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-991"><a href="#cb49-991" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-992"><a href="#cb49-992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-993"><a href="#cb49-993" aria-hidden="true" tabindex="-1"></a>test_iter <span class="ot">&lt;-</span> <span class="cf">function</span>(delta, test_stat, critical_region, mu, sigma_0, n, dist, dist_params, s){</span>
<span id="cb49-994"><a href="#cb49-994" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb49-995"><a href="#cb49-995" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">delta</span>(test_stat, critical_region, X, mu, sigma_0) <span class="sc">%&gt;%</span> </span>
<span id="cb49-996"><a href="#cb49-996" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">iter =</span> s)</span>
<span id="cb49-997"><a href="#cb49-997" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-998"><a href="#cb49-998" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-999"><a href="#cb49-999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1000"><a href="#cb49-1000" aria-hidden="true" tabindex="-1"></a>test_sim <span class="ot">&lt;-</span> <span class="cf">function</span>(N, delta, test_stat, critical_region, mu, sigma_0, n, dist, dist_params){</span>
<span id="cb49-1001"><a href="#cb49-1001" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb49-1002"><a href="#cb49-1002" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(</span>
<span id="cb49-1003"><a href="#cb49-1003" aria-hidden="true" tabindex="-1"></a>      test_iter, </span>
<span id="cb49-1004"><a href="#cb49-1004" aria-hidden="true" tabindex="-1"></a>      <span class="at">delta =</span> delta, </span>
<span id="cb49-1005"><a href="#cb49-1005" aria-hidden="true" tabindex="-1"></a>      <span class="at">test_stat =</span> test_stat, </span>
<span id="cb49-1006"><a href="#cb49-1006" aria-hidden="true" tabindex="-1"></a>      <span class="at">critical_region =</span> critical_region, </span>
<span id="cb49-1007"><a href="#cb49-1007" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> mu, </span>
<span id="cb49-1008"><a href="#cb49-1008" aria-hidden="true" tabindex="-1"></a>      <span class="at">sigma_0 =</span> sigma_0,</span>
<span id="cb49-1009"><a href="#cb49-1009" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n, </span>
<span id="cb49-1010"><a href="#cb49-1010" aria-hidden="true" tabindex="-1"></a>      <span class="at">dist =</span> dist, </span>
<span id="cb49-1011"><a href="#cb49-1011" aria-hidden="true" tabindex="-1"></a>      <span class="at">dist_params =</span> dist_params</span>
<span id="cb49-1012"><a href="#cb49-1012" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1013"><a href="#cb49-1013" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb49-1014"><a href="#cb49-1014" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1015"><a href="#cb49-1015" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1016"><a href="#cb49-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1017"><a href="#cb49-1017" aria-hidden="true" tabindex="-1"></a><span class="co"># This function assumes dist = rnorm and dist_params = list(0, sigma)</span></span>
<span id="cb49-1018"><a href="#cb49-1018" aria-hidden="true" tabindex="-1"></a>power <span class="ot">&lt;-</span> <span class="cf">function</span>(sigma, N, delta, test_stat, critical_region, mu, sigma_0, n){</span>
<span id="cb49-1019"><a href="#cb49-1019" aria-hidden="true" tabindex="-1"></a>  dist <span class="ot">&lt;-</span> rnorm</span>
<span id="cb49-1020"><a href="#cb49-1020" aria-hidden="true" tabindex="-1"></a>  dist_params <span class="ot">&lt;-</span> <span class="fu">list</span>(mu, sigma)</span>
<span id="cb49-1021"><a href="#cb49-1021" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">test_sim</span>(N, delta, test_stat, critical_region, mu, sigma_0, n, dist, dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1022"><a href="#cb49-1022" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(</span>
<span id="cb49-1023"><a href="#cb49-1023" aria-hidden="true" tabindex="-1"></a>      <span class="at">simulated_power =</span> <span class="fu">mean</span>(decision),</span>
<span id="cb49-1024"><a href="#cb49-1024" aria-hidden="true" tabindex="-1"></a>      <span class="at">t =</span> sigma</span>
<span id="cb49-1025"><a href="#cb49-1025" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb49-1026"><a href="#cb49-1026" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1027"><a href="#cb49-1027" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1028"><a href="#cb49-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1029"><a href="#cb49-1029" aria-hidden="true" tabindex="-1"></a>power_curve <span class="ot">&lt;-</span> <span class="cf">function</span>(domain, N, delta, test_stat, critical_region, mu, sigma_0, n){</span>
<span id="cb49-1030"><a href="#cb49-1030" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> domain <span class="sc">%&gt;%</span> </span>
<span id="cb49-1031"><a href="#cb49-1031" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(</span>
<span id="cb49-1032"><a href="#cb49-1032" aria-hidden="true" tabindex="-1"></a>      power,</span>
<span id="cb49-1033"><a href="#cb49-1033" aria-hidden="true" tabindex="-1"></a>      <span class="at">N =</span> N,</span>
<span id="cb49-1034"><a href="#cb49-1034" aria-hidden="true" tabindex="-1"></a>      <span class="at">delta =</span> delta,</span>
<span id="cb49-1035"><a href="#cb49-1035" aria-hidden="true" tabindex="-1"></a>      <span class="at">test_stat =</span> test_stat,</span>
<span id="cb49-1036"><a href="#cb49-1036" aria-hidden="true" tabindex="-1"></a>      <span class="at">critical_region =</span> critical_region,</span>
<span id="cb49-1037"><a href="#cb49-1037" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> mu,</span>
<span id="cb49-1038"><a href="#cb49-1038" aria-hidden="true" tabindex="-1"></a>      <span class="at">sigma_0 =</span> sigma_0,</span>
<span id="cb49-1039"><a href="#cb49-1039" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n</span>
<span id="cb49-1040"><a href="#cb49-1040" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1041"><a href="#cb49-1041" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb49-1042"><a href="#cb49-1042" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1043"><a href="#cb49-1043" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1044"><a href="#cb49-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1045"><a href="#cb49-1045" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">power_curve</span>(</span>
<span id="cb49-1046"><a href="#cb49-1046" aria-hidden="true" tabindex="-1"></a>  <span class="at">domain =</span> <span class="fu">seq</span>(<span class="fl">0.65</span>, <span class="fl">1.2</span>, <span class="at">length =</span> <span class="dv">10</span>), <span class="do">## change length to 40</span></span>
<span id="cb49-1047"><a href="#cb49-1047" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e3</span>, <span class="do">## change to 1e4</span></span>
<span id="cb49-1048"><a href="#cb49-1048" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> delta,</span>
<span id="cb49-1049"><a href="#cb49-1049" aria-hidden="true" tabindex="-1"></a>  <span class="at">test_stat =</span> test_stat,</span>
<span id="cb49-1050"><a href="#cb49-1050" aria-hidden="true" tabindex="-1"></a>  <span class="at">critical_region =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">qchisq</span>(<span class="fl">0.05</span>, <span class="dv">100</span>))),</span>
<span id="cb49-1051"><a href="#cb49-1051" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="dv">0</span>,</span>
<span id="cb49-1052"><a href="#cb49-1052" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_0 =</span> <span class="dv">1</span>,</span>
<span id="cb49-1053"><a href="#cb49-1053" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span></span>
<span id="cb49-1054"><a href="#cb49-1054" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-1055"><a href="#cb49-1055" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1056"><a href="#cb49-1056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1059"><a href="#cb49-1059" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1060"><a href="#cb49-1060" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1061"><a href="#cb49-1061" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-1062"><a href="#cb49-1062" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot311</span></span>
<span id="cb49-1063"><a href="#cb49-1063" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-1064"><a href="#cb49-1064" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-1065"><a href="#cb49-1065" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Power curve associated with the liklihood ratio for variance"</span></span>
<span id="cb49-1066"><a href="#cb49-1066" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-1067"><a href="#cb49-1067" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb49-1068"><a href="#cb49-1068" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(t, simulated_power)) <span class="sc">+</span> </span>
<span id="cb49-1069"><a href="#cb49-1069" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb49-1070"><a href="#cb49-1070" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-1071"><a href="#cb49-1071" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Alternate σ"</span>, <span class="at">y =</span> <span class="st">"Power"</span>)</span>
<span id="cb49-1072"><a href="#cb49-1072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1073"><a href="#cb49-1073" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1074"><a href="#cb49-1074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1075"><a href="#cb49-1075" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1076"><a href="#cb49-1076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1077"><a href="#cb49-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1078"><a href="#cb49-1078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1079"><a href="#cb49-1079" aria-hidden="true" tabindex="-1"></a>The Karlin-Rubin Theorem is very powerful, but is limited. It only works for scalar parameters $\theta_0$. The second we consider situations with a vector of parameters $\thet_0$, or a situation where are model is semiparametric or nonparametric, UMP tests usually do not exist. The theorem also does not directly apply to two-sided tests. There is some disagreement among sources about whether UMP tests even exist for two-sided tests (@degroot2012probability and @casella2021statistical argue that they do not exist, while @lehmann2005testing say otherwise).</span>
<span id="cb49-1080"><a href="#cb49-1080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1081"><a href="#cb49-1081" aria-hidden="true" tabindex="-1"></a>:::{#exm- name="Two-Sided Z Test"}</span>
<span id="cb49-1082"><a href="#cb49-1082" aria-hidden="true" tabindex="-1"></a>Suppose we want to test $H_0:\mu = \mu_0$ versus $H_1:\mu\neq \mu_0$ where $X_i \iid N(\mu,\sigma^2)$ for a known $\sigma^2$. To test this for some significance level $\alpha$, we usually use a two-sided form of the $z-$test:</span>
<span id="cb49-1083"><a href="#cb49-1083" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-1084"><a href="#cb49-1084" aria-hidden="true" tabindex="-1"></a>\delta(\X) &amp; = \begin{cases}\mu = \mu_0 &amp; \Phi^{-1}(\alpha/2)&lt; \frac{\bar X-\mu_0}{\sigma/\sqrt{n}}&lt;\Phi^{-1}(1-\alpha/2)<span class="sc">\\</span> </span>
<span id="cb49-1085"><a href="#cb49-1085" aria-hidden="true" tabindex="-1"></a>\mu \neq \mu_0 &amp; \frac{\bar X-\mu_0}{\sigma/\sqrt{n}}\le \Phi^{-1}(1-\alpha/2) \text{ or }\frac{\bar X-\mu_0}{\sigma/\sqrt{n}}\ge\Phi^{-1}(1-\alpha/2)\end{cases}  </span>
<span id="cb49-1086"><a href="#cb49-1086" aria-hidden="true" tabindex="-1"></a> = \begin{cases}\mu = \mu_0 &amp; \abs{\frac{\bar X-\mu_0}{\sigma/\sqrt{n}}}&lt;\Phi^{-1}(1-\alpha/2)<span class="sc">\\</span> </span>
<span id="cb49-1087"><a href="#cb49-1087" aria-hidden="true" tabindex="-1"></a>\mu \neq \mu_0 &amp; \abs{\frac{\bar X-\mu_0}{\sigma/\sqrt{n}}}\ge \Phi^{-1}(1-\alpha/2)\end{cases}</span>
<span id="cb49-1088"><a href="#cb49-1088" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-1089"><a href="#cb49-1089" aria-hidden="true" tabindex="-1"></a>Consider the "right-handed" and "left-handed" alternatives $\delta_R(\X)$ and $\delta_L(\X)$, respectively. Let's graph the power functions of these three tests for $\alpha = 0.05$.</span>
<span id="cb49-1090"><a href="#cb49-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1093"><a href="#cb49-1093" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1094"><a href="#cb49-1094" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1095"><a href="#cb49-1095" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-1096"><a href="#cb49-1096" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot312</span></span>
<span id="cb49-1097"><a href="#cb49-1097" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-1098"><a href="#cb49-1098" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-1099"><a href="#cb49-1099" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Power for three versions of the Z-test"</span></span>
<span id="cb49-1100"><a href="#cb49-1100" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-1101"><a href="#cb49-1101" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> (<span class="sc">-</span><span class="dv">500</span><span class="sc">:</span><span class="dv">500</span>)<span class="sc">/</span><span class="dv">100</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1102"><a href="#cb49-1102" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb49-1103"><a href="#cb49-1103" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Right Handed'</span> <span class="ot">=</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">+</span> x), </span>
<span id="cb49-1104"><a href="#cb49-1104" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Left Handed'</span> <span class="ot">=</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">-</span> x),</span>
<span id="cb49-1105"><a href="#cb49-1105" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Two Sided'</span> <span class="ot">=</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.956</span> <span class="sc">+</span> <span class="fu">abs</span>(x))</span>
<span id="cb49-1106"><a href="#cb49-1106" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1107"><a href="#cb49-1107" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> <span class="st">"test"</span>, <span class="at">value =</span> <span class="st">"power"</span>, <span class="sc">-</span>x) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1108"><a href="#cb49-1108" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x, power, <span class="at">color =</span> test)) <span class="sc">+</span></span>
<span id="cb49-1109"><a href="#cb49-1109" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb49-1110"><a href="#cb49-1110" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-1111"><a href="#cb49-1111" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"(μ - μ0)/(σ√n)"</span>, <span class="at">y =</span> <span class="st">"Power"</span>, <span class="at">color =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb49-1112"><a href="#cb49-1112" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb49-1113"><a href="#cb49-1113" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1114"><a href="#cb49-1114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1115"><a href="#cb49-1115" aria-hidden="true" tabindex="-1"></a>We see that $\beta(\delta_R) &gt; \beta(\delta)$ when $\mu &gt; \mu_0$ and $\beta(\delta_L) &gt; \beta(\delta)$ when $\mu &lt; \mu_0$, so clearly $\delta$ is not a UMP. Despite this @lehmann2005testing would argue this test is UMP, because it actually has significance level $\alpha/2$. For two sided tests in this setting, @lehmann2005testing define a size $\alpha$ test to be one where </span>
<span id="cb49-1116"><a href="#cb49-1116" aria-hidden="true" tabindex="-1"></a>$$ \alpha(\delta \mid \mu &lt; \mu_0) =  \alpha(\delta \mid \mu &gt; \mu_0) = \alpha.$$</span>
<span id="cb49-1117"><a href="#cb49-1117" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1118"><a href="#cb49-1118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1119"><a href="#cb49-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1120"><a href="#cb49-1120" aria-hidden="true" tabindex="-1"></a>:::{.remark}</span>
<span id="cb49-1121"><a href="#cb49-1121" aria-hidden="true" tabindex="-1"></a>The approach to testing proposed by @neyman1933 was/is not without controversy. Ronald Fisher, one of the central figures in the formalization of statistics, took issue with approach of Neyman and Pearson. A debate raged between the scientists as to the proper way of testing statistical hypotheses. The full details of this dispute is summarized by @lehmann1993fisher and @lehmann2011fisher. </span>
<span id="cb49-1122"><a href="#cb49-1122" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1123"><a href="#cb49-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1124"><a href="#cb49-1124" aria-hidden="true" tabindex="-1"></a><span class="fu">## Asymptotics</span></span>
<span id="cb49-1125"><a href="#cb49-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1126"><a href="#cb49-1126" aria-hidden="true" tabindex="-1"></a>Until now, all of our examples have assumed $X_i \iid N(\mu,\sigma^2)$. In this case, we were able to find the exact distribution of test statistics used to test hypotheses about $\mu$ and $\sigma$. This will usually not be possible, and we will need to use the tools developed in Section @sec-asy to determine the asymptotic distribution of test statistics. To highlight this, we will consider a situation where we can derive the distribution of a test statistic, but as $n\to\infty$, it converges in distribution such that there is virtually no harm done from using the asymptotic distribution instead.</span>
<span id="cb49-1127"><a href="#cb49-1127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1128"><a href="#cb49-1128" aria-hidden="true" tabindex="-1"></a>:::{#exm- name="t-Test"}</span>
<span id="cb49-1129"><a href="#cb49-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1130"><a href="#cb49-1130" aria-hidden="true" tabindex="-1"></a>For one final time, assume $X_i \iid N(\mu,\sigma^2)$, *but* drop the assumption that $\sigma^2$ is known. Assuming that we knew $\sigma^2$ made little to no sense. If we don't know $\mu$, then how would we possibly know $\sigma^2$ (which is calculated using $\mu$)?! If we want to test $H_0:\mu = \mu_0$ versus $H_1: \mu \neq \mu_0$, which decision rule do we pick? We can no longer calculate the statistic $Z = \frac{\bar X - \mu_0}{\sigma/\sqrt n}$, as we do not know $\sigma$. What if we simply replaced $\sigma$ with the (unbiased) sample standard deviation?</span>
<span id="cb49-1131"><a href="#cb49-1131" aria-hidden="true" tabindex="-1"></a>$$T(\X) = \frac{\bar X - \mu_0}{s/\sqrt n}$$</span>
<span id="cb49-1132"><a href="#cb49-1132" aria-hidden="true" tabindex="-1"></a>By replacing $\sigma$ with $s$, we now have $T(\X)\not\sim N(0,1)$, so we can no longer define the critical region using $\Phi^{-1}$. Instead we have $T(\X)\sim t_{n-1}$,^<span class="co">[</span><span class="ot">This follows from the definition of the student's $t$-distribution.</span><span class="co">]</span> so we can still test $H_0$ versus $H_1$. This new test is the classic **_(student's) $t-$test_**, and we usually write the test statistic as $t = T(\X)$. </span>
<span id="cb49-1133"><a href="#cb49-1133" aria-hidden="true" tabindex="-1"></a>$$\delta(\X) = \begin{cases} \mu \neq \mu_0&amp; \abs{\frac{\bar X - \mu_0}{s/\sqrt n}} \ge t_{n-1}^{-1}(1-\alpha/2)<span class="sc">\\</span> \mu = \mu_0 &amp; \abs{\frac{\bar X - \mu_0}{s/\sqrt n}} &lt; t_{n-1}^{-1}(1-\alpha/2)\end{cases} $$</span>
<span id="cb49-1134"><a href="#cb49-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1135"><a href="#cb49-1135" aria-hidden="true" tabindex="-1"></a>But does this difference in distribution really matter? In Section \@ref(asymptotic-properties-of-estimators), one example highlighted that if $Y \sim t_{n}$, then $Y\dto N(0,1)$. This means that $t\dto Z$, and the $t-$test is asymptotically equivalent to the $z-$test. To illustrate this, suppose $X_i \iid N(4,1)$, $H_0:\mu = 2$, and $H_1:\mu \neq 2$. For $\alpha = 0.01$, we can compare the results of the two tests as $n$ increases.</span>
<span id="cb49-1136"><a href="#cb49-1136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1139"><a href="#cb49-1139" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1140"><a href="#cb49-1140" aria-hidden="true" tabindex="-1"></a><span class="co">#Define t-test</span></span>
<span id="cb49-1141"><a href="#cb49-1141" aria-hidden="true" tabindex="-1"></a>t_test <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu_0, alpha){</span>
<span id="cb49-1142"><a href="#cb49-1142" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb49-1143"><a href="#cb49-1143" aria-hidden="true" tabindex="-1"></a>  T_stat <span class="ot">&lt;-</span> (<span class="fu">mean</span>(X) <span class="sc">-</span> mu_0)<span class="sc">/</span>(<span class="fu">sd</span>(X)<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb49-1144"><a href="#cb49-1144" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abs</span>(T_stat) <span class="sc">&gt;</span> <span class="fu">qt</span>(<span class="dv">1</span> <span class="sc">-</span> alpha<span class="sc">/</span><span class="dv">2</span>, <span class="at">df =</span> n <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb49-1145"><a href="#cb49-1145" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1146"><a href="#cb49-1146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1147"><a href="#cb49-1147" aria-hidden="true" tabindex="-1"></a><span class="co">#Define an "incorrect" z-test using the sample standard deviation</span></span>
<span id="cb49-1148"><a href="#cb49-1148" aria-hidden="true" tabindex="-1"></a>z_test <span class="ot">&lt;-</span> <span class="cf">function</span>(X, mu_0, alpha){</span>
<span id="cb49-1149"><a href="#cb49-1149" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(X)</span>
<span id="cb49-1150"><a href="#cb49-1150" aria-hidden="true" tabindex="-1"></a>  Z <span class="ot">&lt;-</span> (<span class="fu">mean</span>(X) <span class="sc">-</span> mu_0)<span class="sc">/</span>(<span class="fu">sd</span>(X)<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb49-1151"><a href="#cb49-1151" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abs</span>(Z) <span class="sc">&gt;</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb49-1152"><a href="#cb49-1152" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1153"><a href="#cb49-1153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1154"><a href="#cb49-1154" aria-hidden="true" tabindex="-1"></a>iter <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, mu_0, n, mu, sigma, t){</span>
<span id="cb49-1155"><a href="#cb49-1155" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, mu, sigma)</span>
<span id="cb49-1156"><a href="#cb49-1156" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb49-1157"><a href="#cb49-1157" aria-hidden="true" tabindex="-1"></a>    <span class="at">iter_num =</span> t,</span>
<span id="cb49-1158"><a href="#cb49-1158" aria-hidden="true" tabindex="-1"></a>    <span class="at">agree =</span> (<span class="fu">t_test</span>(X, mu_0, alpha) <span class="sc">==</span> <span class="fu">z_test</span>(X, mu_0, alpha))</span>
<span id="cb49-1159"><a href="#cb49-1159" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1160"><a href="#cb49-1160" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1161"><a href="#cb49-1161" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1162"><a href="#cb49-1162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1163"><a href="#cb49-1163" aria-hidden="true" tabindex="-1"></a>sim <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha, mu_0, n, mu, sigma){</span>
<span id="cb49-1164"><a href="#cb49-1164" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb49-1165"><a href="#cb49-1165" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(iter, <span class="at">alpha =</span> alpha, <span class="at">mu_0 =</span> mu_0, <span class="at">n =</span> n, <span class="at">mu =</span> mu, <span class="at">sigma =</span> sigma) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1166"><a href="#cb49-1166" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb49-1167"><a href="#cb49-1167" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">sample_size =</span> n)</span>
<span id="cb49-1168"><a href="#cb49-1168" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1169"><a href="#cb49-1169" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1170"><a href="#cb49-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1171"><a href="#cb49-1171" aria-hidden="true" tabindex="-1"></a>outer_sim <span class="ot">&lt;-</span> <span class="cf">function</span>(n_vals, N, alpha, mu_0, mu, sigma){</span>
<span id="cb49-1172"><a href="#cb49-1172" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> n_vals <span class="sc">%&gt;%</span> </span>
<span id="cb49-1173"><a href="#cb49-1173" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(sim, <span class="at">N =</span> N, <span class="at">alpha =</span> alpha, <span class="at">mu_0 =</span> mu_0, <span class="at">mu =</span> mu, <span class="at">sigma =</span> sigma) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1174"><a href="#cb49-1174" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb49-1175"><a href="#cb49-1175" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1176"><a href="#cb49-1176" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1177"><a href="#cb49-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1178"><a href="#cb49-1178" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">outer_sim</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">15</span>, <span class="fl">1e4</span>, <span class="fl">0.01</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>)</span>
<span id="cb49-1179"><a href="#cb49-1179" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1180"><a href="#cb49-1180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1181"><a href="#cb49-1181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1184"><a href="#cb49-1184" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1185"><a href="#cb49-1185" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1186"><a href="#cb49-1186" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot313</span></span>
<span id="cb49-1187"><a href="#cb49-1187" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-1188"><a href="#cb49-1188" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-1189"><a href="#cb49-1189" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-1190"><a href="#cb49-1190" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "As the sample size increases, the frequency at which the Z-test and t-test agree increase"</span></span>
<span id="cb49-1191"><a href="#cb49-1191" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-1192"><a href="#cb49-1192" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb49-1193"><a href="#cb49-1193" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(sample_size) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1194"><a href="#cb49-1194" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop =</span> <span class="fu">sum</span>(agree)<span class="sc">/</span><span class="fu">n</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1195"><a href="#cb49-1195" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(sample_size, prop)) <span class="sc">+</span></span>
<span id="cb49-1196"><a href="#cb49-1196" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb49-1197"><a href="#cb49-1197" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-1198"><a href="#cb49-1198" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Sample Size, n"</span>, <span class="at">y =</span> <span class="st">"Frequency of Tests Agreeing over 10000 Simulations"</span>)</span>
<span id="cb49-1199"><a href="#cb49-1199" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1200"><a href="#cb49-1200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1201"><a href="#cb49-1201" aria-hidden="true" tabindex="-1"></a>Even for modest values of $n$, the tests return the same results for 10,000 simulations. </span>
<span id="cb49-1202"><a href="#cb49-1202" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1203"><a href="#cb49-1203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1204"><a href="#cb49-1204" aria-hidden="true" tabindex="-1"></a>While this example illustrates how we can leverage asymptotics when testing hypotheses, we weren't "required" by any means to take advantage of the fact that $t\dto N(0,1)$, because we knew that $t\sim t_{n-1}$. Unfortunately, $t\sim t_{n-1}$ will only hold if $X_i\iid N(\mu,\sigma^2)$. Once we drop this assumption we must rely on the fact that $t \dto N(0,1)$ </span>
<span id="cb49-1205"><a href="#cb49-1205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1206"><a href="#cb49-1206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1207"><a href="#cb49-1207" aria-hidden="true" tabindex="-1"></a>:::{#exm- name="Non-normal Data"}</span>
<span id="cb49-1208"><a href="#cb49-1208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1209"><a href="#cb49-1209" aria-hidden="true" tabindex="-1"></a>Suppose $X_i\iid F_X$, and we want to test $H_0:\mu = \mu_0$ versus $H_1: \mu \neq \mu_0$. The (irregular) model $\mathcal P$ is a collection of sets, each comprised of all the distributions with a common expected value $\mu$.</span>
<span id="cb49-1210"><a href="#cb49-1210" aria-hidden="true" tabindex="-1"></a>$$P_\mu = \left<span class="sc">\{</span>f_\X(\x)\ \Bigg|\ f_\X(\x) = \prod_{i=1}^n f_{X_i}(x) \text{ and } f_{X_i} = f_{X_j}\ \forall i,j \text{ and }\E{X_i}=\mu\ \forall i\right<span class="sc">\}</span>$$In this case, the CLT tells us that $\sqrt{n}(\bar X - \mu_0) \dto N(0,1)$, so</span>
<span id="cb49-1211"><a href="#cb49-1211" aria-hidden="true" tabindex="-1"></a>$$ t = \frac{(\bar X - \mu_0)}{S/\sqrt{n}} = \frac{\sqrt{n}(\bar X - \mu_0)}{S}  \dto  \frac{N(0,\sigma^2)}{S} = t_{n-1}.$$ Even though we do not know the actual distribution of $T$, we know the asymptotic distribution, and can calculate critical regions when $n$ is sufficiently large. To demonstrate this, let's simulate $\Pr(T\in C\mid \mu=\mu_0)$ for $$\delta(\X) = \begin{cases} \mu \neq \mu_0&amp; \abs{\frac{\bar X - \mu_0}{s/\sqrt n}} \ge t_{n-1}^{-1}(1-\alpha/2)<span class="sc">\\</span> \mu = \mu_0 &amp; \abs{\frac{\bar X - \mu_0}{s/\sqrt n}} &lt; t_{n-1}^{-1}(1-\alpha/2)\end{cases}$$ when $X_i \iid \text{Exp}(1/\mu)$ (such that $\E{X_i}=\mu$). As $n\to\infty$, we should see $\Pr(T\in C\mid \mu=\mu_0)\to \alpha$, indicating that $t_{n-1}$ does indeed provide a sufficient approximation to calculate critical values. We will test $H_0:\mu=2$ versus $H_0:\mu=8$ where $\alpha = 0.05$.</span>
<span id="cb49-1212"><a href="#cb49-1212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1215"><a href="#cb49-1215" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1216"><a href="#cb49-1216" aria-hidden="true" tabindex="-1"></a>simulate_test <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, mu_0, n, dist, dist_params, t){</span>
<span id="cb49-1217"><a href="#cb49-1217" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb49-1218"><a href="#cb49-1218" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb49-1219"><a href="#cb49-1219" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> <span class="fu">t_test</span>(X, mu_0, alpha),</span>
<span id="cb49-1220"><a href="#cb49-1220" aria-hidden="true" tabindex="-1"></a>    <span class="at">iter_num =</span> t</span>
<span id="cb49-1221"><a href="#cb49-1221" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1222"><a href="#cb49-1222" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1223"><a href="#cb49-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1224"><a href="#cb49-1224" aria-hidden="true" tabindex="-1"></a>simulate_alpha_at_n <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha, mu_0, n, dist, dist_params){</span>
<span id="cb49-1225"><a href="#cb49-1225" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb49-1226"><a href="#cb49-1226" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(simulate_test, <span class="at">alpha =</span> alpha, <span class="at">mu_0 =</span> mu_0, <span class="at">n =</span> n, <span class="at">dist =</span> dist, <span class="at">dist_params =</span> dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1227"><a href="#cb49-1227" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb49-1228"><a href="#cb49-1228" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(</span>
<span id="cb49-1229"><a href="#cb49-1229" aria-hidden="true" tabindex="-1"></a>      <span class="at">alpha =</span> <span class="fu">mean</span>(decision),</span>
<span id="cb49-1230"><a href="#cb49-1230" aria-hidden="true" tabindex="-1"></a>      <span class="at">sample_size =</span> n</span>
<span id="cb49-1231"><a href="#cb49-1231" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb49-1232"><a href="#cb49-1232" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1233"><a href="#cb49-1233" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1234"><a href="#cb49-1234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1235"><a href="#cb49-1235" aria-hidden="true" tabindex="-1"></a>simulate_alpha_over_n <span class="ot">&lt;-</span> <span class="cf">function</span>(n_vals, N, alpha, mu_0, dist, dist_params){</span>
<span id="cb49-1236"><a href="#cb49-1236" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> n_vals <span class="sc">%&gt;%</span> </span>
<span id="cb49-1237"><a href="#cb49-1237" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(simulate_alpha_at_n, <span class="at">N =</span> N, <span class="at">alpha =</span> alpha, <span class="at">mu_0 =</span> mu_0, <span class="at">dist =</span> dist, dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1238"><a href="#cb49-1238" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb49-1239"><a href="#cb49-1239" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1240"><a href="#cb49-1240" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1241"><a href="#cb49-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1242"><a href="#cb49-1242" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">simulate_alpha_over_n</span>(</span>
<span id="cb49-1243"><a href="#cb49-1243" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_vals =</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>)<span class="sc">*</span><span class="dv">10</span>, </span>
<span id="cb49-1244"><a href="#cb49-1244" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e2</span>,  <span class="co"># increase to 1e5</span></span>
<span id="cb49-1245"><a href="#cb49-1245" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fl">0.05</span>, </span>
<span id="cb49-1246"><a href="#cb49-1246" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_0 =</span> <span class="dv">2</span>, </span>
<span id="cb49-1247"><a href="#cb49-1247" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist =</span> rexp, </span>
<span id="cb49-1248"><a href="#cb49-1248" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist_params =</span> <span class="fu">list</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb49-1249"><a href="#cb49-1249" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-1250"><a href="#cb49-1250" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1251"><a href="#cb49-1251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1252"><a href="#cb49-1252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1255"><a href="#cb49-1255" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1256"><a href="#cb49-1256" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1257"><a href="#cb49-1257" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-1258"><a href="#cb49-1258" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot314</span></span>
<span id="cb49-1259"><a href="#cb49-1259" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-1260"><a href="#cb49-1260" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-1261"><a href="#cb49-1261" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Despite our data being drawn from an exponential distribution, the test statistic is asympotically distributed according to the t-distribution, so the simulated size approaches the theoretical size of 0.05"</span></span>
<span id="cb49-1262"><a href="#cb49-1262" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-1263"><a href="#cb49-1263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1264"><a href="#cb49-1264" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb49-1265"><a href="#cb49-1265" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(sample_size, alpha)) <span class="sc">+</span></span>
<span id="cb49-1266"><a href="#cb49-1266" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb49-1267"><a href="#cb49-1267" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-1268"><a href="#cb49-1268" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Sample Size, n"</span>, <span class="at">y =</span> <span class="st">"Simulated α"</span>) <span class="sc">+</span></span>
<span id="cb49-1269"><a href="#cb49-1269" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.05</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>)</span>
<span id="cb49-1270"><a href="#cb49-1270" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1271"><a href="#cb49-1271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1272"><a href="#cb49-1272" aria-hidden="true" tabindex="-1"></a>We also have that $t\dto N(0,1)$ when $X_i\iid F_X$. We have $S\to\sigma$, so by Slutsky's theorem </span>
<span id="cb49-1273"><a href="#cb49-1273" aria-hidden="true" tabindex="-1"></a>$$ t = \underbrace{\sqrt{n}(\bar X - \mu_0)}_{\dto N(0,\sigma^2)} / \underbrace{S}_{\pto \sigma} \dto N(0,1).$$ If we wanted to, we could still calculate critical values using the standard normal distribution, even with non-normal data, but those calculated with $t_{n-1}$ would be more slightly more accurate (with this advantage quickly diminishing as $n\to\infty$). </span>
<span id="cb49-1274"><a href="#cb49-1274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1275"><a href="#cb49-1275" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1276"><a href="#cb49-1276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1277"><a href="#cb49-1277" aria-hidden="true" tabindex="-1"></a>In practice, the overwhelming majority of our tests will rely on asymptotic distributions of test statistics. What does this mean when considering the power of a test? The Neyman-Pearson lemma and Karlin-Rubin theorem assumed a fixed sample size. In this sense, we were consider finite sample properties of tests, just like how we considered finite sample properties of estimators in \@ref(finite-sample-properties-of-estimators). This was a bit shortsighted considering the effect sample size has on power. </span>
<span id="cb49-1278"><a href="#cb49-1278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1279"><a href="#cb49-1279" aria-hidden="true" tabindex="-1"></a>:::{#exm- name="Power and Sample Size"}</span>
<span id="cb49-1280"><a href="#cb49-1280" aria-hidden="true" tabindex="-1"></a>Consider testing $H_0:\mu \le \mu_0$ versus $H_1:\mu &gt; \mu_0$ using the $z-$test. where $X_i\iid N(\mu,\sigma^2)$. The power of this test is $$\beta(\mu) = \Phi\left(-1.645 + \frac{\mu-\mu_0}{\sigma / \sqrt{n}} \right).$$ Power is increasing in $n$ as </span>
<span id="cb49-1281"><a href="#cb49-1281" aria-hidden="true" tabindex="-1"></a>$$ \frac{\partial \beta}{\partial n} = \frac{\mu-\mu_0}{2\sigma\sqrt n}\varphi\left(-1.645 + \frac{\mu-\mu_0}{\sigma / \sqrt{n}} \right) &gt; 0.$$</span>
<span id="cb49-1282"><a href="#cb49-1282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1283"><a href="#cb49-1283" aria-hidden="true" tabindex="-1"></a>If we plot $\beta(\mu)$ for various sample sizes, it appears that that $\beta(\mu \mid \mu &gt; \mu_0) \to 1$, and $\beta(\mu \mid \mu \le \mu_0) \to 0$. For example if $\mu_0 = 2$ and $\sigma = 1$, we have:</span>
<span id="cb49-1284"><a href="#cb49-1284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1287"><a href="#cb49-1287" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1288"><a href="#cb49-1288" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1289"><a href="#cb49-1289" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot315</span></span>
<span id="cb49-1290"><a href="#cb49-1290" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-1291"><a href="#cb49-1291" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-1292"><a href="#cb49-1292" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-1293"><a href="#cb49-1293" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "As the sample size increases, the power curve approaches a step function that is 0 where the null hypothesis is true, and 1 where is is false"</span></span>
<span id="cb49-1294"><a href="#cb49-1294" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-1295"><a href="#cb49-1295" aria-hidden="true" tabindex="-1"></a>mu_0 <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb49-1296"><a href="#cb49-1296" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb49-1297"><a href="#cb49-1297" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb49-1298"><a href="#cb49-1298" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">seq</span>(<span class="fl">1.8</span>, <span class="fl">2.2</span>, <span class="at">length =</span> <span class="dv">1000</span>), </span>
<span id="cb49-1299"><a href="#cb49-1299" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="fu">c</span>((<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>)<span class="sc">*</span><span class="dv">10</span>, (<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>)<span class="sc">*</span><span class="dv">100</span>, (<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>)<span class="sc">*</span><span class="dv">1000</span>, (<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>)<span class="sc">*</span><span class="dv">10000</span>)</span>
<span id="cb49-1300"><a href="#cb49-1300" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1301"><a href="#cb49-1301" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">power =</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.645</span> <span class="sc">+</span> (mu <span class="sc">-</span> mu_0)<span class="sc">/</span>(sigma<span class="sc">/</span><span class="fu">sqrt</span>(n)))) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1302"><a href="#cb49-1302" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(mu, power)) <span class="sc">+</span></span>
<span id="cb49-1303"><a href="#cb49-1303" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb49-1304"><a href="#cb49-1304" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-1305"><a href="#cb49-1305" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fl">1.8</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">xend =</span> <span class="dv">2</span>, <span class="at">yend =</span> <span class="dv">0</span>), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb49-1306"><a href="#cb49-1306" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">2</span>, <span class="at">y =</span> <span class="dv">1</span>, <span class="at">xend =</span> <span class="fl">2.2</span>, <span class="at">yend =</span> <span class="dv">1</span>), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb49-1307"><a href="#cb49-1307" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">2</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">xend =</span> <span class="dv">2</span>, <span class="at">yend =</span> <span class="dv">1</span>), <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb49-1308"><a href="#cb49-1308" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>) <span class="sc">+</span></span>
<span id="cb49-1309"><a href="#cb49-1309" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Alternate μ"</span>, <span class="at">y =</span> <span class="st">"Power"</span>, <span class="at">color =</span> <span class="st">"Sample Size"</span>) <span class="sc">+</span></span>
<span id="cb49-1310"><a href="#cb49-1310" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">colour =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb49-1311"><a href="#cb49-1311" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transition_states</span>(n) <span class="sc">+</span> </span>
<span id="cb49-1312"><a href="#cb49-1312" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">'n = {closest_state}'</span>)</span>
<span id="cb49-1313"><a href="#cb49-1313" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1314"><a href="#cb49-1314" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1315"><a href="#cb49-1315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1316"><a href="#cb49-1316" aria-hidden="true" tabindex="-1"></a>This example highlights that as $n\to\infty$, tests become optimal in the sense that the probability of committing any error (whether it be type I or type II) approaches zero. </span>
<span id="cb49-1317"><a href="#cb49-1317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1318"><a href="#cb49-1318" aria-hidden="true" tabindex="-1"></a>::: {#def-}</span>
<span id="cb49-1319"><a href="#cb49-1319" aria-hidden="true" tabindex="-1"></a>Suppose $\delta(\X)$ is a decision rule for the hypotheses $H_0:P_{\thet}\in\mathcal P_0$ versus $H_1:P_{\thet}\in\mathcal P_0$. The decision rule has &lt;span style="color:red"&gt;**_asymptotic size $\alpha$_**&lt;/span&gt; if </span>
<span id="cb49-1320"><a href="#cb49-1320" aria-hidden="true" tabindex="-1"></a>$$ \lim_{n\to\infty} \beta(\delta, P_{\thet} \mid P_{\thet}\in\mathcal P_0) = \alpha.$$</span>
<span id="cb49-1321"><a href="#cb49-1321" aria-hidden="true" tabindex="-1"></a>The decision rule has &lt;span style="color:red"&gt;**_consistent_**&lt;/span&gt; if </span>
<span id="cb49-1322"><a href="#cb49-1322" aria-hidden="true" tabindex="-1"></a>$$ \lim_{n\to\infty} \beta(\delta, P_{\thet} \mid P_{\thet}\in\mathcal P_1) = 1.$$</span>
<span id="cb49-1323"><a href="#cb49-1323" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1324"><a href="#cb49-1324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1325"><a href="#cb49-1325" aria-hidden="true" tabindex="-1"></a>These two definitions are somewhat informal, and barely scratch the surface of asymptotic properties of hypothesis testing. For a detailed treatment, see @lehmann2005testing. </span>
<span id="cb49-1326"><a href="#cb49-1326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1327"><a href="#cb49-1327" aria-hidden="true" tabindex="-1"></a><span class="fu">## Confidence Intervals</span></span>
<span id="cb49-1328"><a href="#cb49-1328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1329"><a href="#cb49-1329" aria-hidden="true" tabindex="-1"></a>An alternate way to think about hypothesis testing is in terms of confidence intervals. An inherent flaw in point estimation is that is necessarily provides a single estimate. We may want to provide a set of plausible estimates in an effort to address the inherent uncertainty that arises from point estimation. </span>
<span id="cb49-1330"><a href="#cb49-1330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1331"><a href="#cb49-1331" aria-hidden="true" tabindex="-1"></a>::: {#def-}</span>
<span id="cb49-1332"><a href="#cb49-1332" aria-hidden="true" tabindex="-1"></a>A statistic $\underline\theta(\X)$ is a &lt;span style="color:red"&gt;**_level $(1-\alpha)$ lower confidence bound for $\theta$_**&lt;/span&gt; if $\Pr[\underline\theta(\X) \le \theta] \ge 1 - \alpha$ for all $\theta \in \Theta$. A statistic $\bar\theta(\X)$ is a &lt;span style="color:red"&gt;**_level $(1-\alpha)$ upper confidence bound for $\theta$_**&lt;/span&gt; if $\Pr[\bar\theta(\X) \ge \theta] \ge 1 - \alpha$ for all $\theta \in \Theta$. Together these statistics form an interval $[\underline\theta(\X),\bar\theta(\X)]$ known as a level &lt;span style="color:red"&gt;**_level $(1-\alpha)$ confidence interval for $\theta$_**&lt;/span&gt; when </span>
<span id="cb49-1333"><a href="#cb49-1333" aria-hidden="true" tabindex="-1"></a>$$ \Pr<span class="co">[</span><span class="ot">\underline\theta(\X) \le \theta \le \bar\theta(\X)</span><span class="co">]</span> \ge 1-\alpha$$ The &lt;span style="color:red"&gt;**_confidence coefficient_**&lt;/span&gt; for a confidence interval is the largest possible confidence level given as </span>
<span id="cb49-1334"><a href="#cb49-1334" aria-hidden="true" tabindex="-1"></a>$$ \inf_{\theta \in \Theta}<span class="sc">\{</span>\Pr<span class="co">[</span><span class="ot">\underline\theta(\X) \le \theta \le \bar\theta(\X)</span><span class="co">]</span><span class="sc">\}</span>.$$ A confidence interval with confidence coefficient $1-\alpha$ is called a &lt;span style="color:red"&gt;**_$100(1-\alpha)$% confidence interval_**&lt;/span&gt;.</span>
<span id="cb49-1335"><a href="#cb49-1335" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1336"><a href="#cb49-1336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1337"><a href="#cb49-1337" aria-hidden="true" tabindex="-1"></a>The level of a confidence interval is not unique. If $\Pr<span class="co">[</span><span class="ot">\underline\theta(\X) \le \theta \le \bar\theta(\X)</span><span class="co">]</span> \ge 1-\alpha$, then $\Pr<span class="co">[</span><span class="ot">\underline\theta(\X) \le \theta \le \bar\theta(\X)</span><span class="co">]</span> \ge 1-\alpha'$ for all $\alpha'&gt;\alpha$, so a confidence interval of level $(1-\alpha)$ will be a confidence interval of level $(1-\alpha')$ for all $\alpha'&gt;\alpha$. The confidence coefficient eliminates this ambiguity by taking the maximum level of confidence $(1-\alpha)$.</span>
<span id="cb49-1338"><a href="#cb49-1338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1339"><a href="#cb49-1339" aria-hidden="true" tabindex="-1"></a>It's important to emphasize that the probability $\Pr<span class="co">[</span><span class="ot">\underline\theta(\X) \le \theta \le \bar\theta(\X)</span><span class="co">]</span>$ does *not* correspond to the probability that $\theta$ is contained in $<span class="co">[</span><span class="ot">\underline\theta,\bar\theta</span><span class="co">]</span>$. The parameter $\theta$ is a constant, and not a random variable. It is either in the interval or not. Instead $\Pr<span class="co">[</span><span class="ot">\underline\theta(\X) \le \theta \le \bar\theta(\X)</span><span class="co">]</span>$ is related to the calculation of the statistics $\underline\theta$ and $\bar\theta$, both of which are random variables. If we construct a 95% confidence interval for $\theta$, then there is a 95% chance that the interval $<span class="co">[</span><span class="ot">\underline\theta,\bar\theta</span><span class="co">]</span>$ contains $\theta$, where probability is taken over all possible samples $\X$.  </span>
<span id="cb49-1340"><a href="#cb49-1340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1341"><a href="#cb49-1341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1342"><a href="#cb49-1342" aria-hidden="true" tabindex="-1"></a>:::{#exm-}</span>
<span id="cb49-1343"><a href="#cb49-1343" aria-hidden="true" tabindex="-1"></a>Suppose we want to construct a confidence interval for $\mu$, where $X_i\iid N(\mu,\sigma^2)$ for an unknown $\sigma$. In order to construct some confidence interval $<span class="co">[</span><span class="ot">\underline\mu(\X),\bar \mu(\X)</span><span class="co">]</span>$, we need to define $\underline\mu$ and $\bar \mu$ such that we know their respective probability distributions, thereby allowing us to calculate $\Pr<span class="co">[</span><span class="ot">\underline\mu(\X) \le \mu \le \bar\mu(\X)</span><span class="co">]</span>$. One statistic for which we know the distribution is $t = \frac{\bar X - \mu}{s/\sqrt n}$, as $t \sim t_{n-1}$. The distribution $t_{n-1}$ is symmetric, so we can use the quantile function $t_{n-1}^{-1}$ to determine a confidence interval for $t$.</span>
<span id="cb49-1344"><a href="#cb49-1344" aria-hidden="true" tabindex="-1"></a>$$\Pr<span class="co">[</span><span class="ot">-t_{n-1}^{-1}(1-\alpha/2)\le t\le t_{n-1}^{-1}(1-\alpha/2)</span><span class="co">]</span> = 1-\alpha $$ This is a key step in the direction of finding a confidence interval for $\mu$, as $t$ is a function of $\mu$.</span>
<span id="cb49-1345"><a href="#cb49-1345" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-1346"><a href="#cb49-1346" aria-hidden="true" tabindex="-1"></a>&amp;\Pr<span class="co">[</span><span class="ot">-t_{n-1}^{-1}(1-\alpha/2)\le t\le t_{n-1}^{-1}(1-\alpha/2)</span><span class="co">]</span> = 1-\alpha <span class="sc">\\</span></span>
<span id="cb49-1347"><a href="#cb49-1347" aria-hidden="true" tabindex="-1"></a>\implies &amp;\Pr\left<span class="co">[</span><span class="ot">-t_{n-1}^{-1}(1-\alpha/2)\le \frac{\bar X - \mu}{s/\sqrt n}\le t_{n-1}^{-1}(1-\alpha/2)\right</span><span class="co">]</span> = 1-\alpha <span class="sc">\\</span></span>
<span id="cb49-1348"><a href="#cb49-1348" aria-hidden="true" tabindex="-1"></a>\implies &amp;\Pr\left<span class="co">[</span><span class="ot"> \bar X - (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}} \le \mu \le \bar X + (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}}\right</span><span class="co">]</span> = 1-\alpha</span>
<span id="cb49-1349"><a href="#cb49-1349" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-1350"><a href="#cb49-1350" aria-hidden="true" tabindex="-1"></a>Therefore we have a $(1-\alpha)$ level confidence interval for $\mu$ in the form of </span>
<span id="cb49-1351"><a href="#cb49-1351" aria-hidden="true" tabindex="-1"></a>$$ \left<span class="co">[</span><span class="ot"> \bar X - (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}} , \bar X + (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}}\right</span><span class="co">]</span>.$$</span>
<span id="cb49-1352"><a href="#cb49-1352" aria-hidden="true" tabindex="-1"></a>If we let $\alpha = 0.05$, $\mu = 0$, $\sigma = 1$, and $n = 10$, we can generate confidence intervals for a large number of simulated samples. About 95% of the constructed intervals will contain the true mean $\mu = 0$. </span>
<span id="cb49-1353"><a href="#cb49-1353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1356"><a href="#cb49-1356" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1357"><a href="#cb49-1357" aria-hidden="true" tabindex="-1"></a>confidence_interval <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, n, dist, dist_params, t){</span>
<span id="cb49-1358"><a href="#cb49-1358" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb49-1359"><a href="#cb49-1359" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb49-1360"><a href="#cb49-1360" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> <span class="fu">mean</span>(X) <span class="sc">-</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, n<span class="dv">-1</span>)<span class="sc">*</span>(<span class="fu">sd</span>(X)<span class="sc">/</span><span class="fu">sqrt</span>(n)),</span>
<span id="cb49-1361"><a href="#cb49-1361" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper =</span> <span class="fu">mean</span>(X) <span class="sc">+</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, n<span class="dv">-1</span>)<span class="sc">*</span>(<span class="fu">sd</span>(X)<span class="sc">/</span><span class="fu">sqrt</span>(n)),</span>
<span id="cb49-1362"><a href="#cb49-1362" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> alpha,</span>
<span id="cb49-1363"><a href="#cb49-1363" aria-hidden="true" tabindex="-1"></a>    <span class="at">iter_num =</span> t</span>
<span id="cb49-1364"><a href="#cb49-1364" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1365"><a href="#cb49-1365" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1366"><a href="#cb49-1366" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1367"><a href="#cb49-1367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1368"><a href="#cb49-1368" aria-hidden="true" tabindex="-1"></a>draw_confidence_intervals <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha, n, dist, dist_params){</span>
<span id="cb49-1369"><a href="#cb49-1369" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb49-1370"><a href="#cb49-1370" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(confidence_interval, <span class="at">alpha =</span> alpha, <span class="at">n =</span> n, <span class="at">dist =</span> dist, <span class="at">dist_params =</span> dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1371"><a href="#cb49-1371" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb49-1372"><a href="#cb49-1372" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1373"><a href="#cb49-1373" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1374"><a href="#cb49-1374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1375"><a href="#cb49-1375" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">draw_confidence_intervals</span>(<span class="fl">1e5</span>, <span class="fl">0.05</span>, <span class="dv">10</span>, rnorm, <span class="fu">list</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb49-1376"><a href="#cb49-1376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1377"><a href="#cb49-1377" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb49-1378"><a href="#cb49-1378" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob_contains =</span> <span class="fu">mean</span>((lower <span class="sc">&lt;=</span> <span class="dv">0</span>)<span class="sc">*</span>(<span class="dv">0</span> <span class="sc">&lt;=</span> upper)))</span>
<span id="cb49-1379"><a href="#cb49-1379" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1380"><a href="#cb49-1380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1381"><a href="#cb49-1381" aria-hidden="true" tabindex="-1"></a>Let's plot 100 of our constructed 95% confidence intervals (drawn at random).</span>
<span id="cb49-1382"><a href="#cb49-1382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1385"><a href="#cb49-1385" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1386"><a href="#cb49-1386" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1387"><a href="#cb49-1387" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-1388"><a href="#cb49-1388" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot316</span></span>
<span id="cb49-1389"><a href="#cb49-1389" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-1390"><a href="#cb49-1390" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-1391"><a href="#cb49-1391" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "100 of the 10,000 simulated confidence intervals drawn at random. Approximately 5% of the 100 do not contain the true parameter value"</span></span>
<span id="cb49-1392"><a href="#cb49-1392" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-1393"><a href="#cb49-1393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1394"><a href="#cb49-1394" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb49-1395"><a href="#cb49-1395" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1396"><a href="#cb49-1396" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">contains =</span> (lower <span class="sc">&lt;=</span> <span class="dv">0</span>)<span class="sc">*</span>(<span class="dv">0</span> <span class="sc">&lt;=</span> upper)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1397"><a href="#cb49-1397" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(iter_num, <span class="at">color =</span> <span class="fu">as.factor</span>(contains))) <span class="sc">+</span></span>
<span id="cb49-1398"><a href="#cb49-1398" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper)) <span class="sc">+</span></span>
<span id="cb49-1399"><a href="#cb49-1399" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">color =</span> <span class="st">"Interval Contains   μ = 0:"</span>, <span class="at">x =</span> <span class="st">"Sample"</span>, <span class="at">y =</span> <span class="st">"Parameter Space"</span>) <span class="sc">+</span></span>
<span id="cb49-1400"><a href="#cb49-1400" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"green"</span>)) <span class="sc">+</span></span>
<span id="cb49-1401"><a href="#cb49-1401" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-1402"><a href="#cb49-1402" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb49-1403"><a href="#cb49-1403" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1404"><a href="#cb49-1404" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1405"><a href="#cb49-1405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1406"><a href="#cb49-1406" aria-hidden="true" tabindex="-1"></a>We can also construct approximate confidence intervals using asymptotic theory. If we modified the previous example such that $X_i$ had some arbitrary distribution $F_X$ with mean $\mu$, then $t\asim t_{n-1}$, so </span>
<span id="cb49-1407"><a href="#cb49-1407" aria-hidden="true" tabindex="-1"></a>$$ \lim_{n\to\infty}\Pr\left<span class="co">[</span><span class="ot"> \bar X - (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}} \le \mu \le \bar X + (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}}\right</span><span class="co">]</span> = 1- \alpha. $$ In other words, for a sufficiently large $n$, we will have </span>
<span id="cb49-1408"><a href="#cb49-1408" aria-hidden="true" tabindex="-1"></a>$$ \Pr\left<span class="co">[</span><span class="ot"> \bar X - (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}} \le \mu \le \bar X + (t_{n-1}^{-1}(1-\alpha/2))\frac{s}{\sqrt{n}}\right</span><span class="co">]</span> \approx 1- \alpha.$$</span>
<span id="cb49-1409"><a href="#cb49-1409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1410"><a href="#cb49-1410" aria-hidden="true" tabindex="-1"></a>The previous example also suggests that we may be able to use confidence intervals to test hypotheses. We derived an interval $<span class="co">[</span><span class="ot">\underline\mu(\X),\bar \mu(\X)</span><span class="co">]</span>$ such that $\Pr(0 \notin <span class="co">[</span><span class="ot">\underline\mu(\X),\bar \mu(\X)</span><span class="co">]</span>) = \alpha$. If we wanted to test $H_0:\mu=0$ versus $H_1:\mu\neq0$ with a significance level of $\alpha$, then perhaps we define a decision rule $\delta$ such that we fail to reject $H_0$ if and only if $\bar X\in<span class="co">[</span><span class="ot">\underline\mu(\X),\bar \mu(\X)</span><span class="co">]</span>$. Not only does this work, but it highlights how confidence intervals and hypothesis tests are two sides of the same coin.</span>
<span id="cb49-1411"><a href="#cb49-1411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1412"><a href="#cb49-1412" aria-hidden="true" tabindex="-1"></a>:::{#thm-}</span>
<span id="cb49-1413"><a href="#cb49-1413" aria-hidden="true" tabindex="-1"></a>Suppose $\delta(\X)$ is a decision rule with level $\alpha$ for the hypothesis $H_0:\thet = \thet_0$. If $A(\thet_0)=<span class="sc">\{</span>\x \mid \delta(\x) = 0<span class="sc">\}</span>$ is the set of observations for which we fail to reject $H_0$, then the set </span>
<span id="cb49-1414"><a href="#cb49-1414" aria-hidden="true" tabindex="-1"></a>$$S(\x) = <span class="sc">\{</span>\thet \mid \x\in A(\thet)<span class="sc">\}</span> $$ is a family of confidence intervals for $\thet$ with level $1-\alpha$.</span>
<span id="cb49-1415"><a href="#cb49-1415" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1416"><a href="#cb49-1416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1417"><a href="#cb49-1417" aria-hidden="true" tabindex="-1"></a>:::{.proof}</span>
<span id="cb49-1418"><a href="#cb49-1418" aria-hidden="true" tabindex="-1"></a>We've defined $S(\x)$ such that $\thet\in S(\x)$ holds if and only if $\x\in A(\thet)$, so </span>
<span id="cb49-1419"><a href="#cb49-1419" aria-hidden="true" tabindex="-1"></a>$$ \Pr<span class="co">[</span><span class="ot">\thet \in S(\X)</span><span class="co">]</span> = \Pr<span class="co">[</span><span class="ot">\X \in A(\thet)</span><span class="co">]</span> .$$ Since $\delta$ is a level $\alpha$ test, </span>
<span id="cb49-1420"><a href="#cb49-1420" aria-hidden="true" tabindex="-1"></a>$\Pr<span class="co">[</span><span class="ot">\X \in A(\thet)</span><span class="co">]</span> \ge 1-\alpha$, so $$\Pr<span class="co">[</span><span class="ot">\thet \in S(\X)</span><span class="co">]</span> \ge 1-\alpha.$$</span>
<span id="cb49-1421"><a href="#cb49-1421" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb49-1422"><a href="#cb49-1422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1423"><a href="#cb49-1423" aria-hidden="true" tabindex="-1"></a><span class="fu">## Wald Test and t-Test</span></span>
<span id="cb49-1424"><a href="#cb49-1424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1425"><a href="#cb49-1425" aria-hidden="true" tabindex="-1"></a>While we've talked a fair amount about the properties tests can have, and considered very specific examples of tests, we have only defined one test in general -- the likelihood ratio test given by Theorem \@ref(thm:NPlemma). This test has appealing properties in finite samples, especially if \@ref(thm:KR) holds. Unfortunately, the distribution of the test statistic in finite samples depends on the model which generates the data, so the likelihood ratio is not very robust. Instead, we will consider a large-sample alternative. </span>
<span id="cb49-1426"><a href="#cb49-1426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1427"><a href="#cb49-1427" aria-hidden="true" tabindex="-1"></a>Suppose we are testing $H_0: P_{\thet} \in \mathcal P_0$ versus $H_1: P_{\thet} \in \mathcal P_1$ where </span>
<span id="cb49-1428"><a href="#cb49-1428" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-1429"><a href="#cb49-1429" aria-hidden="true" tabindex="-1"></a>\mathcal P_0 = <span class="sc">\{</span>P_{\thet}\in\mathcal P \mid \mathbf h(\thet) = \mathbf 0<span class="sc">\}</span>,<span class="sc">\\</span></span>
<span id="cb49-1430"><a href="#cb49-1430" aria-hidden="true" tabindex="-1"></a>\mathcal P_1 = <span class="sc">\{</span>P_{\thet}\in\mathcal P \mid \mathbf h(\thet) \neq \mathbf 0<span class="sc">\}</span>,</span>
<span id="cb49-1431"><a href="#cb49-1431" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-1432"><a href="#cb49-1432" aria-hidden="true" tabindex="-1"></a>for some function $\mathbf h:\boldsymbol\Theta \to \mathbb R^q$. In other words, we are testing $H_0:\mathbf h(\thet) = \mathbf 0$ versus $H_1: \mathbf h(\thet) \neq \mathbf 0$. See @wolak1989local for the case where $\mathbf h(\thet) \ge \zer$ or $\mathbf h(\thet) \le \zer$. The function $\mathbf h:\boldsymbol\Theta \to \mathbb R^q$ describes the $q$ relationships we are testing between the $k=\dim(\boldsymbol\Theta)$ components of $\thet = (\theta_1,\ldots,\theta_k)$. For example, if $\boldsymbol\Theta = \mathbb R^4$ and our null hypothesis was comprised of the following equations:</span>
<span id="cb49-1433"><a href="#cb49-1433" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-1434"><a href="#cb49-1434" aria-hidden="true" tabindex="-1"></a>\theta_1 &amp;= 2\theta_3<span class="sc">\\</span></span>
<span id="cb49-1435"><a href="#cb49-1435" aria-hidden="true" tabindex="-1"></a>\theta_2 &amp;= \theta_1\ln \theta_4<span class="sc">\\</span></span>
<span id="cb49-1436"><a href="#cb49-1436" aria-hidden="true" tabindex="-1"></a>\theta_3 &amp;= 3</span>
<span id="cb49-1437"><a href="#cb49-1437" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-1438"><a href="#cb49-1438" aria-hidden="true" tabindex="-1"></a>then $\mathbf h: \mathbb R^4 \to \mathbb R^3$ is </span>
<span id="cb49-1439"><a href="#cb49-1439" aria-hidden="true" tabindex="-1"></a>$$ \mathbf h(\thet) = \begin{bmatrix} \theta_1 - 2\theta_3<span class="sc">\\</span> \theta_2 -\theta_1\ln \theta_4<span class="sc">\\</span>\theta_3-3\end{bmatrix}.$$ There are two special cases of hypotheses we should consider. </span>
<span id="cb49-1440"><a href="#cb49-1440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1441"><a href="#cb49-1441" aria-hidden="true" tabindex="-1"></a>:::{#exm- name="Linear Hypotheses"}</span>
<span id="cb49-1442"><a href="#cb49-1442" aria-hidden="true" tabindex="-1"></a>In the event our null hypothesis postulates that the components of $\thet$ are linear combinations of each other, we can write $\mathbf h(\thet) = \mathbf H\thet$ for some $q\times k$ matrix of constants. </span>
<span id="cb49-1443"><a href="#cb49-1443" aria-hidden="true" tabindex="-1"></a>$$\begin{cases}\sum_{i=1}^k c_{1i}\theta_i = 0<span class="sc">\\</span>\ \ \ \ \ \ \ \ \ \vdots<span class="sc">\\</span> \sum_{i=1}^k c_{qi}\theta_i = 0\end{cases} \implies \mathbf H = \begin{bmatrix} c_{11} &amp; \cdots &amp;c_{1k} <span class="sc">\\</span> \vdots &amp; \ddots &amp; \vdots <span class="sc">\\</span> c_{q1} &amp; \cdots &amp;c_{qk} \end{bmatrix}$$ Our null hypothesis is $\mathbf H\thet = \mathbf 0$. </span>
<span id="cb49-1444"><a href="#cb49-1444" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1445"><a href="#cb49-1445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1446"><a href="#cb49-1446" aria-hidden="true" tabindex="-1"></a>:::{#exm-}</span>
<span id="cb49-1447"><a href="#cb49-1447" aria-hidden="true" tabindex="-1"></a>In many settings, the default null hypothesis considered is $H_0:\thet = \mathbf 0$. In this case, $\mathbf h(\thet) = \thet$. If we are only interested in one parameter $\theta_j$, then $\mathbf h(\thet) = \theta_j$. </span>
<span id="cb49-1448"><a href="#cb49-1448" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1449"><a href="#cb49-1449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1450"><a href="#cb49-1450" aria-hidden="true" tabindex="-1"></a>In order to determine the asymptotic distribution of the test statistics prescribed by each test, we need to adopt a distributional assumption about our estimator.</span>
<span id="cb49-1451"><a href="#cb49-1451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1452"><a href="#cb49-1452" aria-hidden="true" tabindex="-1"></a>::: {.exercise #assone}</span>
<span id="cb49-1453"><a href="#cb49-1453" aria-hidden="true" tabindex="-1"></a>We have an estimator $\hat {\thet}$ satisfying $\sqrt{n}(\hat{\thet} - \thet) \dto N(\zer, \mathbf V)$ for a PSD matrix $\mathbf V$. That is, $\hat {\thet}$ is root-$n$ CAN and $\hat  {\thet}\asim N(\thet, \mathbf V/n)$ where $\avar{\hat{\thet}}= \mathbf V/n$</span>
<span id="cb49-1454"><a href="#cb49-1454" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1455"><a href="#cb49-1455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1456"><a href="#cb49-1456" aria-hidden="true" tabindex="-1"></a>We are making no assumptions about the distribution of $\X$, the asymptotic distribution of $\X$, or the distribution of $\hat{\thet}$. We are only making an assumption about the asymptotic distribution of some $\hat{\thet}$. Because of the LLN and CLT, this assumption turns out to be fairly weak, as nearly all common estimators are  root-$n$ CAN. </span>
<span id="cb49-1457"><a href="#cb49-1457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1458"><a href="#cb49-1458" aria-hidden="true" tabindex="-1"></a>The first test we consider will be the most familiar, and will not involve the likelihood function in our general setting. Suppose $\theta$ and $h(\theta)=\theta_0$ are scalars. If we want to test $h(\theta)=0 $, we may want to decide whether or not to reject the null hypothesis based on the discrepancy between $h(\theta)$ and $h(\hat\theta)$. If the true parameter value is $\theta_0$, then we would reject the null hypothesis if $\hat\theta- \theta_0 \gg 0$ or  $\hat\theta- \theta_0 \ll 0$. We can consider these cases simultaneously by rejecting the null hypothesis if $(\hat\theta-\theta_0)^2 \gg 0$. This is a bit ambiguous though, because it isn't clear what distance $\hat\theta- \theta_0$ is surprising enough to merit rejecting the null hypothesis. Fortunately, we've assumed that $\avar{\hat{\theta}}=  V/n$ so we can standardize the distance using the standard deviation of $\hat\theta$. This standard deviation has a special name.</span>
<span id="cb49-1459"><a href="#cb49-1459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1460"><a href="#cb49-1460" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-1461"><a href="#cb49-1461" aria-hidden="true" tabindex="-1"></a>The &lt;span style="color:red"&gt;**_standard error_**&lt;/span&gt; of an estimator $\hat{\thet}$ is its standard deviation. $$\se{\hat{\thet}}=\text{diag}\left<span class="co">[</span><span class="ot">\var{\hat{\thet}}\right</span><span class="co">]</span>^{1/2} $$ </span>
<span id="cb49-1462"><a href="#cb49-1462" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1463"><a href="#cb49-1463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1464"><a href="#cb49-1464" aria-hidden="true" tabindex="-1"></a>Using the standard error we can measure the non-negative distance as </span>
<span id="cb49-1465"><a href="#cb49-1465" aria-hidden="true" tabindex="-1"></a>$$ \left(\frac{\hat\theta-\theta_0}{\se{\hat{\theta}}}\right)^2 = \frac{(\hat\theta-\theta_0)^2}{\var{\hat\theta}}.$$ This still doesn't do though, because we do not know $\var{\hat\theta}$. Perhaps instead we can use $\avar{\hat\theta}$, giving </span>
<span id="cb49-1466"><a href="#cb49-1466" aria-hidden="true" tabindex="-1"></a>$$ \frac{(\hat\theta-\theta_0)^2}{\avar{\hat\theta}} = \frac{(\hat\theta-\theta_0)^2}{V/n} .$$ Unfortunately, if $\avar{\hat\theta}$ is a function of $\theta$ (which is more often than not the case), then we must estimate $\avar{\hat\theta}$, giving the statistic </span>
<span id="cb49-1467"><a href="#cb49-1467" aria-hidden="true" tabindex="-1"></a>$$ \frac{(\hat\theta-\theta_0)^2}{\widehat{\text{Avar}}(\hat\theta)} = \frac{(\hat\theta-\theta_0)^2}{\hat V/n}.$$ This should look *very familiar*. For example, if we have $X_i\iid N(\mu,\sigma^2)$ and want to test $H_0:\mu\neq \mu_0$, a situation where $\sqrt n(\bar X-\mu_0) \dto N(0,\sigma^2)$ and $\avar(\bar X) = \sigma^2/n$, we have </span>
<span id="cb49-1468"><a href="#cb49-1468" aria-hidden="true" tabindex="-1"></a>$$ \frac{(\hat\theta-\theta_0)^2}{\widehat{\text{Avar}}(\hat\theta)} = \frac{(\bar X-\mu_0)^2}{\widehat{(\sigma^2/n)}} = \frac{(\bar X-\mu_0)^2}{S^2/n}.$$ This is just the squared test statistic for the $t-$test!</span>
<span id="cb49-1469"><a href="#cb49-1469" aria-hidden="true" tabindex="-1"></a>$$ \left<span class="co">[</span><span class="ot">\frac{(\bar X-\mu_0)^2}{S^2/n}\right</span><span class="co">]</span>^{1/2} = \frac{\bar X -\mu_0}{S/\sqrt n}.$$ In the event we know $\sigma^2$, we don't even need to estimate $\avar{\bar X}$, and this statistic becomes the squared version of test statistic from the $z-$test. In general this test statistic simply reports how many estimated standard deviations $\theta$ is from $\theta_0$, squared. This statistic is due to @wald1943tests, and we will now define it in higher dimensions for possibly nonlinear hypotheses.</span>
<span id="cb49-1470"><a href="#cb49-1470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1471"><a href="#cb49-1471" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-1472"><a href="#cb49-1472" aria-hidden="true" tabindex="-1"></a>Given the hypotheses $H_0:\mathbf h(\thet) = \mathbf 0$ versus $H_1: \mathbf h(\thet) \neq \mathbf 0$, the &lt;span style="color:red"&gt;**_Wald statistic_**&lt;/span&gt; is defined as </span>
<span id="cb49-1473"><a href="#cb49-1473" aria-hidden="true" tabindex="-1"></a>$$ W(\X) = \mathbf h(\hat{\thet})'\left<span class="co">[</span><span class="ot">\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})\widehat{\text{Avar}}(\hat{\thet})\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})'\right</span><span class="co">]</span>^{-1}\mathbf h(\hat{\thet}).$$</span>
<span id="cb49-1474"><a href="#cb49-1474" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1475"><a href="#cb49-1475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1476"><a href="#cb49-1476" aria-hidden="true" tabindex="-1"></a>While this looks fairly complex, the following example shows that it does indeed simplify to statistic we used to build intuition.</span>
<span id="cb49-1477"><a href="#cb49-1477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1478"><a href="#cb49-1478" aria-hidden="true" tabindex="-1"></a>:::{#exm-}</span>
<span id="cb49-1479"><a href="#cb49-1479" aria-hidden="true" tabindex="-1"></a>Suppose $\dim(\boldsymbol\Theta)=1$, and $h(\theta) = \theta - \theta_0$. The null hypothesis is $H_0: \theta - \theta_0 = 0$, which is $H_0: \theta  = \theta_0$. We have </span>
<span id="cb49-1480"><a href="#cb49-1480" aria-hidden="true" tabindex="-1"></a>$$\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet}) = \frac{\partial }{\partial \theta}<span class="co">[</span><span class="ot">\theta - \theta_0</span><span class="co">]</span>_{\theta=\hat\theta} = 1.$$ Because we have a single parameter, transposes are trivial:</span>
<span id="cb49-1481"><a href="#cb49-1481" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-1482"><a href="#cb49-1482" aria-hidden="true" tabindex="-1"></a>\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})' &amp; = <span class="co">[</span><span class="ot">1</span><span class="co">]</span>' = 1 = \frac{\partial \mathbf h}{\partial \thet}(\hat{\thet}).<span class="sc">\\</span> </span>
<span id="cb49-1483"><a href="#cb49-1483" aria-hidden="true" tabindex="-1"></a>\mathbf h(\hat{\thet})' &amp;= <span class="co">[</span><span class="ot">\hat\theta - \theta_0</span><span class="co">]</span>'=\hat\theta - \theta_0 = \mathbf h(\hat{\thet}).</span>
<span id="cb49-1484"><a href="#cb49-1484" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-1485"><a href="#cb49-1485" aria-hidden="true" tabindex="-1"></a>Our statistic is </span>
<span id="cb49-1486"><a href="#cb49-1486" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-1487"><a href="#cb49-1487" aria-hidden="true" tabindex="-1"></a>W &amp;= \mathbf h(\hat{\thet})'\left<span class="co">[</span><span class="ot">\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})\widehat{\text{Avar}}(\hat{\thet})\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})'\right</span><span class="co">]</span>^{-1}\mathbf h(\hat{\thet})<span class="sc">\\</span></span>
<span id="cb49-1488"><a href="#cb49-1488" aria-hidden="true" tabindex="-1"></a>&amp; = (\hat\theta - \theta_0)<span class="co">[</span><span class="ot">1\cdot\widehat{\text{Avar}}(\hat{\theta})\cdot 1 </span><span class="co">]</span>^{-1}(\hat\theta - \theta_0)<span class="sc">\\</span></span>
<span id="cb49-1489"><a href="#cb49-1489" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{(\hat\theta - \theta_0)^2}{\widehat{\text{Avar}}(\hat{\theta})}</span>
<span id="cb49-1490"><a href="#cb49-1490" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-1491"><a href="#cb49-1491" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1492"><a href="#cb49-1492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1493"><a href="#cb49-1493" aria-hidden="true" tabindex="-1"></a>To use the Wald statistic in a test, we need to be able to construct critical regions given a choice of size $\alpha$. When $n$ is sufficiently large, this requires knowing the asymptotic  distribution of $W$. It's possible to make an informed guess about this distribution if we think about the Wald statistic as a squared $t-$statistic. We established that </span>
<span id="cb49-1494"><a href="#cb49-1494" aria-hidden="true" tabindex="-1"></a>$$ t = \frac{(\bar X-\mu_0)^2}{S^2/n} \dto N(0,1).$$ If we apply the continuous mapping theorem to $t^2 = W$, we have </span>
<span id="cb49-1495"><a href="#cb49-1495" aria-hidden="true" tabindex="-1"></a>$$ W = t^2 \dto <span class="co">[</span><span class="ot">N(0,1)</span><span class="co">]</span>^2 = \chi^2_1.$$ Not only is $W$ asymptotically distributed according to a chi-square distribution in this simple setting, but it is in the general setting. The only thing we need to account for when showing this in higher dimensions is that we are testing $q$ one dimensional hypotheses simultaneously when $\mathbf h:\boldsymbol \Theta \to \mathbb R^q$.  </span>
<span id="cb49-1496"><a href="#cb49-1496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1497"><a href="#cb49-1497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1498"><a href="#cb49-1498" aria-hidden="true" tabindex="-1"></a>:::{.lemma #quadchi}</span>
<span id="cb49-1499"><a href="#cb49-1499" aria-hidden="true" tabindex="-1"></a>If $\x\sim N(\zer,\mathbf I)$ where $\x = (x_1,\ldots,x_n)$, then $\x'\x\sim \chi_n^2$. </span>
<span id="cb49-1500"><a href="#cb49-1500" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1501"><a href="#cb49-1501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1502"><a href="#cb49-1502" aria-hidden="true" tabindex="-1"></a>:::{.proof}</span>
<span id="cb49-1503"><a href="#cb49-1503" aria-hidden="true" tabindex="-1"></a>We have $\x'\x = \sum_{i=1}^n x_i^2$ where $x_i\sim N(0,1)$, so $\x'\x$ is the sum of $n$ random variables with a standard normal distribution. This means $\x'\x\sim \chi_n^2$. </span>
<span id="cb49-1504"><a href="#cb49-1504" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1505"><a href="#cb49-1505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1506"><a href="#cb49-1506" aria-hidden="true" tabindex="-1"></a>:::{#thm-wald}</span>
<span id="cb49-1507"><a href="#cb49-1507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1508"><a href="#cb49-1508" aria-hidden="true" tabindex="-1"></a>Suppose:</span>
<span id="cb49-1509"><a href="#cb49-1509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1510"><a href="#cb49-1510" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Assumption \@ref(exr:assone) holds;</span>
<span id="cb49-1511"><a href="#cb49-1511" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$\mathbf h:\boldsymbol \Theta \to \mathbb R^q$ is continuously differentiable on $\boldsymbol\Theta\subset\mathbb R^k$ and $\frac{\partial \mathbf h}{\partial \thet}$ is invertible;</span>
<span id="cb49-1512"><a href="#cb49-1512" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$\hat {\mathbf V}$ is a consistent estimator for $\mathbf V$;</span>
<span id="cb49-1513"><a href="#cb49-1513" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>$\thet$ is in the interior of $\boldsymbol\Theta$  .</span>
<span id="cb49-1514"><a href="#cb49-1514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1515"><a href="#cb49-1515" aria-hidden="true" tabindex="-1"></a>Then $W \dto \chi_q^2$ under $H_0$. As a result, the &lt;span style="color:red"&gt;**_Wald test_**&lt;/span&gt; with size $\alpha$ takes the form </span>
<span id="cb49-1516"><a href="#cb49-1516" aria-hidden="true" tabindex="-1"></a>$$\delta(\X) = \begin{cases} \mathbf h(\thet) = \zer &amp; W &lt; (\chi_q^2)^{-1}(1-\alpha)<span class="sc">\\</span></span>
<span id="cb49-1517"><a href="#cb49-1517" aria-hidden="true" tabindex="-1"></a>\mathbf h(\thet) \neq \zer &amp; W \ge (\chi_q^2)^{-1}(1-\alpha)\end{cases}.$$</span>
<span id="cb49-1518"><a href="#cb49-1518" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1519"><a href="#cb49-1519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1520"><a href="#cb49-1520" aria-hidden="true" tabindex="-1"></a>:::{.proof}</span>
<span id="cb49-1521"><a href="#cb49-1521" aria-hidden="true" tabindex="-1"></a>We are given that $\sqrt{n}(\hat{\thet} - \thet) \dto N(\zer, \mathbf V)$. Under assumptions 2 and 4, we can apply the delta method as follows:</span>
<span id="cb49-1522"><a href="#cb49-1522" aria-hidden="true" tabindex="-1"></a>$$ \sqrt{n}(\mathbf h(\hat{\thet}) - \mathbf h(\thet)) \dto N\left(\zer, \frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})\mathbf V\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})'\right).$$ We are assuming $H_0$ holds, so $\mathbf h(\thet) = \zer$, giving </span>
<span id="cb49-1523"><a href="#cb49-1523" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-1524"><a href="#cb49-1524" aria-hidden="true" tabindex="-1"></a>&amp;\sqrt{n}(\mathbf h(\hat{\thet}) - \mathbf h(\thet)) \dto N\left(\zer, \frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})\mathbf V\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})'\right)<span class="sc">\\</span></span>
<span id="cb49-1525"><a href="#cb49-1525" aria-hidden="true" tabindex="-1"></a>\implies &amp; \sqrt{n}\mathbf h(\hat{\thet}) \dto N\left(\zer, \frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})\mathbf V\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})'\right)<span class="sc">\\</span></span>
<span id="cb49-1526"><a href="#cb49-1526" aria-hidden="true" tabindex="-1"></a>\implies &amp; \left<span class="co">[</span><span class="ot">\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})\mathbf V\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})'\right</span><span class="co">]</span>^{-1/2}\sqrt{n}\mathbf h(\hat{\thet}) \dto N(\zer, \mathbf I)</span>
<span id="cb49-1527"><a href="#cb49-1527" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-1528"><a href="#cb49-1528" aria-hidden="true" tabindex="-1"></a>Using the previous lemma we have </span>
<span id="cb49-1529"><a href="#cb49-1529" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-1530"><a href="#cb49-1530" aria-hidden="true" tabindex="-1"></a>&amp;\sqrt{n}\mathbf h(\hat{\thet})'\left<span class="co">[</span><span class="ot">\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})\mathbf V\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})'\right</span><span class="co">]</span>^{-1/2}\left<span class="co">[</span><span class="ot">\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})\mathbf V\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})'\right</span><span class="co">]</span>^{-1/2}\sqrt{n}\mathbf h(\hat{\thet})\dto \chi_q^2<span class="sc">\\</span></span>
<span id="cb49-1531"><a href="#cb49-1531" aria-hidden="true" tabindex="-1"></a>\implies &amp; </span>
<span id="cb49-1532"><a href="#cb49-1532" aria-hidden="true" tabindex="-1"></a>n\mathbf h(\hat{\thet})'\left<span class="co">[</span><span class="ot">\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})\mathbf V\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})'\right</span><span class="co">]</span>^{-1}\mathbf h(\hat{\thet})\dto \chi_q^2<span class="sc">\\</span></span>
<span id="cb49-1533"><a href="#cb49-1533" aria-hidden="true" tabindex="-1"></a>\implies &amp; \mathbf h(\hat{\thet})'\left<span class="co">[</span><span class="ot">\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})(\mathbf V/n)\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})'\right</span><span class="co">]</span>^{-1}\mathbf h(\hat{\thet})\dto \chi_q^2</span>
<span id="cb49-1534"><a href="#cb49-1534" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-1535"><a href="#cb49-1535" aria-hidden="true" tabindex="-1"></a>If we replace $\mathbf V$ with our estimator $\hat {\mathbf V}$ which satisfies $\hat {\mathbf V}\pto \mathbf V$, then we can apply Slutky's theorem and conclude </span>
<span id="cb49-1536"><a href="#cb49-1536" aria-hidden="true" tabindex="-1"></a>$$\mathbf h(\hat{\thet})'\left<span class="co">[</span><span class="ot">\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})(\hat {\mathbf V}/n)\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})'\right</span><span class="co">]</span>^{-1}\mathbf h(\hat{\thet})\dto \chi_q^2$$</span>
<span id="cb49-1537"><a href="#cb49-1537" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1538"><a href="#cb49-1538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1539"><a href="#cb49-1539" aria-hidden="true" tabindex="-1"></a>The intuition behind the Wald test is identical to that of the $z-$test, the $t$-test, and many other familiar tests -- we know the distribution of $W(\X)$ under $H_0$, so if we observe a value of $W(\x)$ that is very unlikely then we should reject $H_0$.</span>
<span id="cb49-1540"><a href="#cb49-1540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1541"><a href="#cb49-1541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1542"><a href="#cb49-1542" aria-hidden="true" tabindex="-1"></a>:::{#exm-}</span>
<span id="cb49-1543"><a href="#cb49-1543" aria-hidden="true" tabindex="-1"></a>We can write a simple function which implements the Wald test.</span>
<span id="cb49-1546"><a href="#cb49-1546" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1547"><a href="#cb49-1547" aria-hidden="true" tabindex="-1"></a>Wald_test <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, h, n, theta_hat, V_hat){</span>
<span id="cb49-1548"><a href="#cb49-1548" aria-hidden="true" tabindex="-1"></a>  <span class="co">#Calculate test stat</span></span>
<span id="cb49-1549"><a href="#cb49-1549" aria-hidden="true" tabindex="-1"></a>  h_prime <span class="ot">&lt;-</span> <span class="fu">jacobian</span>(h, theta_hat)</span>
<span id="cb49-1550"><a href="#cb49-1550" aria-hidden="true" tabindex="-1"></a>  W <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">t</span>(<span class="fu">h</span>(theta_hat)) <span class="sc">%*%</span> <span class="fu">solve</span>(h_prime <span class="sc">%*%</span> (V_hat<span class="sc">/</span>n) <span class="sc">%*%</span> <span class="fu">t</span>(h_prime)) <span class="sc">%*%</span> <span class="fu">h</span>(theta_hat))</span>
<span id="cb49-1551"><a href="#cb49-1551" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-1552"><a href="#cb49-1552" aria-hidden="true" tabindex="-1"></a>  <span class="co">#determine if we reject</span></span>
<span id="cb49-1553"><a href="#cb49-1553" aria-hidden="true" tabindex="-1"></a>  dof <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">h</span>(theta_hat))</span>
<span id="cb49-1554"><a href="#cb49-1554" aria-hidden="true" tabindex="-1"></a>  c <span class="ot">&lt;-</span> <span class="fu">qchisq</span>(<span class="dv">1</span> <span class="sc">-</span> alpha, dof)</span>
<span id="cb49-1555"><a href="#cb49-1555" aria-hidden="true" tabindex="-1"></a>  reject <span class="ot">&lt;-</span> (W <span class="sc">&gt;=</span> c)</span>
<span id="cb49-1556"><a href="#cb49-1556" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-1557"><a href="#cb49-1557" aria-hidden="true" tabindex="-1"></a>  <span class="co">#Output information</span></span>
<span id="cb49-1558"><a href="#cb49-1558" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb49-1559"><a href="#cb49-1559" aria-hidden="true" tabindex="-1"></a>    <span class="at">statistic =</span> W,</span>
<span id="cb49-1560"><a href="#cb49-1560" aria-hidden="true" tabindex="-1"></a>    <span class="at">critical_value =</span> c,</span>
<span id="cb49-1561"><a href="#cb49-1561" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> reject</span>
<span id="cb49-1562"><a href="#cb49-1562" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1563"><a href="#cb49-1563" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-1564"><a href="#cb49-1564" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1565"><a href="#cb49-1565" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1566"><a href="#cb49-1566" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1567"><a href="#cb49-1567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1568"><a href="#cb49-1568" aria-hidden="true" tabindex="-1"></a>In order to calculate $\frac{\partial \mathbf h}{\partial \thet}(\hat{\thet})$, we made use of the <span class="in">`jacobian()`</span> function from the <span class="in">`numDeriv`</span> package instead of requiring an additional argument where we supply the calculated Jacobian. Let's put our function to use. Suppose that $\X \iid N(\boldsymbol\mu, \boldsymbol\Sigma)$ where </span>
<span id="cb49-1569"><a href="#cb49-1569" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-1570"><a href="#cb49-1570" aria-hidden="true" tabindex="-1"></a>\boldsymbol\mu &amp;= \begin{bmatrix}2&amp;2&amp;2\end{bmatrix}',<span class="sc">\\</span></span>
<span id="cb49-1571"><a href="#cb49-1571" aria-hidden="true" tabindex="-1"></a>\boldsymbol\Sigma&amp;= \begin{bmatrix}1&amp;0.4&amp;0.2<span class="sc">\\</span>0.4&amp; 2&amp; 0.1<span class="sc">\\</span>0.2&amp;0.1&amp;1 \end{bmatrix}.</span>
<span id="cb49-1572"><a href="#cb49-1572" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-1573"><a href="#cb49-1573" aria-hidden="true" tabindex="-1"></a>The sample mean satisfies $\sqrt{n}(\bar {\X} - \boldsymbol\mu)\dto N(\zer, \mathbf V)$ trivially, as $\sqrt{n}(\bar {\X} - \boldsymbol\mu)\sim N(\zer, \boldsymbol\Sigma)$. We can use the Wald test to test the hypothesis that $\boldsymbol\mu = (2,2,2)$ with $\alpha = 0.05$ and $n = 100$. In this case we have </span>
<span id="cb49-1574"><a href="#cb49-1574" aria-hidden="true" tabindex="-1"></a>$$ \mathbf h(\boldsymbol\mu) = \begin{bmatrix} \mu_1 - 2<span class="sc">\\</span> \mu_2 -2<span class="sc">\\</span>\mu_3-2\end{bmatrix}.$$ We do need a consistent estimate of $\mathbf V = \boldsymbol \Sigma$, but the most intuitive candidate will do. The sample covariance, calculated using <span class="in">`cov()`</span>, of our observed data is a consistent estimator of  $\boldsymbol \Sigma$ just as the sample variance is a consistent estimator of the actual variance. </span>
<span id="cb49-1575"><a href="#cb49-1575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1578"><a href="#cb49-1578" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1579"><a href="#cb49-1579" aria-hidden="true" tabindex="-1"></a>sim_wald <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, h, n, dist, dist_params, t){</span>
<span id="cb49-1580"><a href="#cb49-1580" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb49-1581"><a href="#cb49-1581" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">Wald_test</span>(alpha, h, n, <span class="fu">colMeans</span>(X), <span class="fu">cov</span>(X)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1582"><a href="#cb49-1582" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">iter_num =</span> t)</span>
<span id="cb49-1583"><a href="#cb49-1583" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1584"><a href="#cb49-1584" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1585"><a href="#cb49-1585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1586"><a href="#cb49-1586" aria-hidden="true" tabindex="-1"></a>draw_N_wald <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha, h, n, dist, dist_params){</span>
<span id="cb49-1587"><a href="#cb49-1587" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb49-1588"><a href="#cb49-1588" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(sim_wald, <span class="at">alpha =</span> alpha, <span class="at">h =</span> h, <span class="at">n =</span> n, <span class="at">dist =</span> dist, <span class="at">dist_params =</span> dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1589"><a href="#cb49-1589" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>()</span>
<span id="cb49-1590"><a href="#cb49-1590" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1591"><a href="#cb49-1591" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1592"><a href="#cb49-1592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1593"><a href="#cb49-1593" aria-hidden="true" tabindex="-1"></a><span class="co">#Define hypothesis</span></span>
<span id="cb49-1594"><a href="#cb49-1594" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="cf">function</span>(t){</span>
<span id="cb49-1595"><a href="#cb49-1595" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(t[<span class="dv">1</span>], t[<span class="dv">2</span>], t[<span class="dv">3</span>]) <span class="sc">-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb49-1596"><a href="#cb49-1596" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1597"><a href="#cb49-1597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1598"><a href="#cb49-1598" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">draw_N_wald</span>(</span>
<span id="cb49-1599"><a href="#cb49-1599" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e5</span>,</span>
<span id="cb49-1600"><a href="#cb49-1600" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fl">0.05</span>, </span>
<span id="cb49-1601"><a href="#cb49-1601" aria-hidden="true" tabindex="-1"></a>  <span class="at">h =</span> h,</span>
<span id="cb49-1602"><a href="#cb49-1602" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="fl">1e3</span>, </span>
<span id="cb49-1603"><a href="#cb49-1603" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist =</span> rmvnorm,</span>
<span id="cb49-1604"><a href="#cb49-1604" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist_params =</span> <span class="fu">list</span>(</span>
<span id="cb49-1605"><a href="#cb49-1605" aria-hidden="true" tabindex="-1"></a>      <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>), </span>
<span id="cb49-1606"><a href="#cb49-1606" aria-hidden="true" tabindex="-1"></a>      <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,.<span class="dv">4</span>,.<span class="dv">2</span>,.<span class="dv">4</span>,<span class="dv">2</span>,.<span class="dv">1</span>,.<span class="dv">2</span>,.<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span> <span class="dv">3</span>)</span>
<span id="cb49-1607"><a href="#cb49-1607" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1608"><a href="#cb49-1608" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-1609"><a href="#cb49-1609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1610"><a href="#cb49-1610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1611"><a href="#cb49-1611" aria-hidden="true" tabindex="-1"></a><span class="co">#Should be ≈ 0.05</span></span>
<span id="cb49-1612"><a href="#cb49-1612" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb49-1613"><a href="#cb49-1613" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob_reject =</span> <span class="fu">mean</span>(decision))</span>
<span id="cb49-1614"><a href="#cb49-1614" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1615"><a href="#cb49-1615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1616"><a href="#cb49-1616" aria-hidden="true" tabindex="-1"></a>If we plot the test statistics from our 10,000 simulations, we can illustrate that $W\asim \chi_3^2$. </span>
<span id="cb49-1617"><a href="#cb49-1617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1620"><a href="#cb49-1620" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1621"><a href="#cb49-1621" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1622"><a href="#cb49-1622" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb49-1623"><a href="#cb49-1623" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot317</span></span>
<span id="cb49-1624"><a href="#cb49-1624" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-1625"><a href="#cb49-1625" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-1626"><a href="#cb49-1626" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-1627"><a href="#cb49-1627" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "The hisotrgram of simulated wald test statistics (calculated using a sample size of 100) coincides with the asymptotic distribution given in Theorem 3.2"</span></span>
<span id="cb49-1628"><a href="#cb49-1628" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-1629"><a href="#cb49-1629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1630"><a href="#cb49-1630" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb49-1631"><a href="#cb49-1631" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(statistic)) <span class="sc">+</span> </span>
<span id="cb49-1632"><a href="#cb49-1632" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">colour =</span> <span class="dv">1</span>, <span class="at">fill =</span> <span class="st">"white"</span>, <span class="at">bins =</span> <span class="dv">50</span>) <span class="sc">+</span></span>
<span id="cb49-1633"><a href="#cb49-1633" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlab</span>(<span class="st">"Simulated Wald Test Statistics"</span>) <span class="sc">+</span></span>
<span id="cb49-1634"><a href="#cb49-1634" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb49-1635"><a href="#cb49-1635" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dchisq, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">df =</span> <span class="dv">3</span>), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb49-1636"><a href="#cb49-1636" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>,<span class="dv">15</span>)</span>
<span id="cb49-1637"><a href="#cb49-1637" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1638"><a href="#cb49-1638" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1639"><a href="#cb49-1639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1640"><a href="#cb49-1640" aria-hidden="true" tabindex="-1"></a>If we are only testing $\theta_j = \theta_0$ for one component of $\thet$, then we can use a general version of the $t-$test, which is a modified Wald test.</span>
<span id="cb49-1641"><a href="#cb49-1641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1642"><a href="#cb49-1642" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb49-1643"><a href="#cb49-1643" aria-hidden="true" tabindex="-1"></a>Given the hypotheses $H_0:\theta_j = \theta_{0}$ versus $H_1: \theta_j \neq \theta_{0}$, the &lt;span style="color:red"&gt;**_$t-$statistic_**&lt;/span&gt; is defined as </span>
<span id="cb49-1644"><a href="#cb49-1644" aria-hidden="true" tabindex="-1"></a>$$ t = \frac{\hat\theta_j-\theta_0}{\widehat{\text{se}}(\hat\theta_j)} = <span class="co">[</span><span class="ot">W(\X)</span><span class="co">]</span>^{1/2}.$$</span>
<span id="cb49-1645"><a href="#cb49-1645" aria-hidden="true" tabindex="-1"></a>Assuming \@ref(exr:assone) holds, the &lt;span style="color:red"&gt;**_$t-$test_**&lt;/span&gt; with size $\alpha$ takes the form </span>
<span id="cb49-1646"><a href="#cb49-1646" aria-hidden="true" tabindex="-1"></a>$$\delta(\X) = \begin{cases} \theta_j = \theta_0 &amp; \abs{t} \ge t_{n-1}^{-1}(1-\alpha/2)<span class="sc">\\</span></span>
<span id="cb49-1647"><a href="#cb49-1647" aria-hidden="true" tabindex="-1"></a>\theta_j \neq \theta_0 &amp; \abs{t} &lt; t_{n-1}^{-1}(1-\alpha/2)\end{cases}.$$</span>
<span id="cb49-1648"><a href="#cb49-1648" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1649"><a href="#cb49-1649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1650"><a href="#cb49-1650" aria-hidden="true" tabindex="-1"></a>Considering the $t-$test in the broader context of the Wald test highlights an important distinction -- there is a difference between the one hypothesis $\thet = \thet_0$, and the separate hypotheses $\theta_j = \theta_{0,j}$ for $j=1,\ldots,k$. The prior requires that $\theta_j = \theta_{0,j}$ for all $j$ *simultaneously*, while the latter hypotheses are completely independent. We can highlight this by comparing the $t-$test and the Wald test.</span>
<span id="cb49-1651"><a href="#cb49-1651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1652"><a href="#cb49-1652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1653"><a href="#cb49-1653" aria-hidden="true" tabindex="-1"></a>:::{#exm- name="t-test versus Wald test"}</span>
<span id="cb49-1654"><a href="#cb49-1654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1655"><a href="#cb49-1655" aria-hidden="true" tabindex="-1"></a>We will start by writing a function which performs the $t-$test just like we did with the Wald test.</span>
<span id="cb49-1656"><a href="#cb49-1656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1659"><a href="#cb49-1659" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1660"><a href="#cb49-1660" aria-hidden="true" tabindex="-1"></a>t_test <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, theta0, n, theta_hat, se_hat){</span>
<span id="cb49-1661"><a href="#cb49-1661" aria-hidden="true" tabindex="-1"></a>  <span class="co">#calculate test stat</span></span>
<span id="cb49-1662"><a href="#cb49-1662" aria-hidden="true" tabindex="-1"></a>  t <span class="ot">&lt;-</span> (theta_hat <span class="sc">-</span> theta0)<span class="sc">/</span>se_hat</span>
<span id="cb49-1663"><a href="#cb49-1663" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-1664"><a href="#cb49-1664" aria-hidden="true" tabindex="-1"></a>  <span class="co">#determine if we reject</span></span>
<span id="cb49-1665"><a href="#cb49-1665" aria-hidden="true" tabindex="-1"></a>  dof <span class="ot">&lt;-</span> n <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb49-1666"><a href="#cb49-1666" aria-hidden="true" tabindex="-1"></a>  c <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="dv">1</span> <span class="sc">-</span> alpha<span class="sc">/</span><span class="dv">2</span>, dof)</span>
<span id="cb49-1667"><a href="#cb49-1667" aria-hidden="true" tabindex="-1"></a>  reject <span class="ot">&lt;-</span> (<span class="fu">abs</span>(t) <span class="sc">&gt;=</span> c)</span>
<span id="cb49-1668"><a href="#cb49-1668" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-1669"><a href="#cb49-1669" aria-hidden="true" tabindex="-1"></a>  <span class="co">#Output information</span></span>
<span id="cb49-1670"><a href="#cb49-1670" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb49-1671"><a href="#cb49-1671" aria-hidden="true" tabindex="-1"></a>    <span class="at">parameter =</span> <span class="fu">paste0</span>(<span class="st">"θ"</span>, <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(t)),</span>
<span id="cb49-1672"><a href="#cb49-1672" aria-hidden="true" tabindex="-1"></a>    <span class="at">statistic =</span> t,</span>
<span id="cb49-1673"><a href="#cb49-1673" aria-hidden="true" tabindex="-1"></a>    <span class="at">critical_value =</span> c,</span>
<span id="cb49-1674"><a href="#cb49-1674" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> reject</span>
<span id="cb49-1675"><a href="#cb49-1675" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb49-1676"><a href="#cb49-1676" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-1677"><a href="#cb49-1677" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1678"><a href="#cb49-1678" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1679"><a href="#cb49-1679" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1680"><a href="#cb49-1680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1681"><a href="#cb49-1681" aria-hidden="true" tabindex="-1"></a>As defined, the function is able to perform multiple $t-$tests simultaneously. If we supply a matrix for <span class="in">`X`</span> along with vectors for <span class="in">`theta0`</span>, <span class="in">`theta_hat`</span>, and <span class="in">`se_hat`</span>, then<span class="in">`t`</span> will be a vector and <span class="in">`decision`</span> will record whether the components of <span class="in">`t`</span> exceed the critical value.  </span>
<span id="cb49-1682"><a href="#cb49-1682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1683"><a href="#cb49-1683" aria-hidden="true" tabindex="-1"></a>To compare <span class="in">`t_test()`</span> and <span class="in">`Wald_test()`</span>, suppose $\X \iid N(\boldsymbol\mu, \boldsymbol\Sigma)$ for </span>
<span id="cb49-1684"><a href="#cb49-1684" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb49-1685"><a href="#cb49-1685" aria-hidden="true" tabindex="-1"></a>\boldsymbol\mu &amp;=/ \begin{bmatrix}0&amp;0.5\end{bmatrix}',<span class="sc">\\</span></span>
<span id="cb49-1686"><a href="#cb49-1686" aria-hidden="true" tabindex="-1"></a>\boldsymbol\Sigma&amp;= \begin{bmatrix}1&amp;0<span class="sc">\\</span>0&amp;2 \end{bmatrix},</span>
<span id="cb49-1687"><a href="#cb49-1687" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb49-1688"><a href="#cb49-1688" aria-hidden="true" tabindex="-1"></a>and $n=2$. We will test $H_0:\boldsymbol\mu = \zer$ with <span class="in">`Wald_test()`</span> and the separate hypotheses $H_0:\mu_1 = 0$ (which is true) and $H_0:\mu_2 = 0$, all with $\alpha = 0.05$. We should reject $\mu_1 = 0$ with an approximate probability $\alpha$.</span>
<span id="cb49-1689"><a href="#cb49-1689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1692"><a href="#cb49-1692" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1693"><a href="#cb49-1693" aria-hidden="true" tabindex="-1"></a>wald_vs_t <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, h, mu0, n, dist, dist_params, t){</span>
<span id="cb49-1694"><a href="#cb49-1694" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">do.call</span>(dist, <span class="fu">append</span>(n, dist_params))</span>
<span id="cb49-1695"><a href="#cb49-1695" aria-hidden="true" tabindex="-1"></a>  t_test_results <span class="ot">&lt;-</span> <span class="fu">t_test</span>(alpha, mu0, n, <span class="fu">colMeans</span>(X), <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">var</span>(X)<span class="sc">/</span>n))) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1696"><a href="#cb49-1696" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">test =</span> <span class="st">"t-test"</span>)</span>
<span id="cb49-1697"><a href="#cb49-1697" aria-hidden="true" tabindex="-1"></a>  wald_test_results <span class="ot">&lt;-</span> <span class="fu">Wald_test</span>(alpha, h, n, <span class="fu">colMeans</span>(X), <span class="fu">cov</span>(X)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1698"><a href="#cb49-1698" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb49-1699"><a href="#cb49-1699" aria-hidden="true" tabindex="-1"></a>      <span class="at">parameter =</span> <span class="st">"θ"</span>,</span>
<span id="cb49-1700"><a href="#cb49-1700" aria-hidden="true" tabindex="-1"></a>      <span class="at">test =</span> <span class="st">"Wald test"</span></span>
<span id="cb49-1701"><a href="#cb49-1701" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb49-1702"><a href="#cb49-1702" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> t_test_results <span class="sc">%&gt;%</span> </span>
<span id="cb49-1703"><a href="#cb49-1703" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>(wald_test_results) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1704"><a href="#cb49-1704" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">iter_num =</span> t)</span>
<span id="cb49-1705"><a href="#cb49-1705" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1706"><a href="#cb49-1706" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1707"><a href="#cb49-1707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1708"><a href="#cb49-1708" aria-hidden="true" tabindex="-1"></a>draw_N_wald_vs_t <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha, h, mu0, n, dist, dist_params){</span>
<span id="cb49-1709"><a href="#cb49-1709" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">%&gt;%</span> </span>
<span id="cb49-1710"><a href="#cb49-1710" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(wald_vs_t, <span class="at">alpha =</span> alpha, <span class="at">h =</span> h, <span class="at">mu0 =</span> mu0, <span class="at">n =</span> n, <span class="at">dist =</span> dist, <span class="at">dist_params =</span> dist_params) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1711"><a href="#cb49-1711" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>() </span>
<span id="cb49-1712"><a href="#cb49-1712" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb49-1713"><a href="#cb49-1713" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1714"><a href="#cb49-1714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1715"><a href="#cb49-1715" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="cf">function</span>(t){</span>
<span id="cb49-1716"><a href="#cb49-1716" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(t[<span class="dv">1</span>], t[<span class="dv">2</span>]) <span class="sc">-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb49-1717"><a href="#cb49-1717" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-1718"><a href="#cb49-1718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1719"><a href="#cb49-1719" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">draw_N_wald_vs_t</span>(</span>
<span id="cb49-1720"><a href="#cb49-1720" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fl">1e5</span>,</span>
<span id="cb49-1721"><a href="#cb49-1721" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb49-1722"><a href="#cb49-1722" aria-hidden="true" tabindex="-1"></a>  <span class="at">h =</span> h,</span>
<span id="cb49-1723"><a href="#cb49-1723" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu0 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb49-1724"><a href="#cb49-1724" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">100</span>,</span>
<span id="cb49-1725"><a href="#cb49-1725" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist =</span> rmvnorm,</span>
<span id="cb49-1726"><a href="#cb49-1726" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist_params =</span> <span class="fu">list</span>(</span>
<span id="cb49-1727"><a href="#cb49-1727" aria-hidden="true" tabindex="-1"></a>    <span class="at">mean =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>),</span>
<span id="cb49-1728"><a href="#cb49-1728" aria-hidden="true" tabindex="-1"></a>    <span class="at">sigma =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb49-1729"><a href="#cb49-1729" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1730"><a href="#cb49-1730" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-1731"><a href="#cb49-1731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1732"><a href="#cb49-1732" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb49-1733"><a href="#cb49-1733" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(test, parameter) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1734"><a href="#cb49-1734" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob_reject =</span> <span class="fu">mean</span>(decision)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1735"><a href="#cb49-1735" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span>
<span id="cb49-1736"><a href="#cb49-1736" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1737"><a href="#cb49-1737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1738"><a href="#cb49-1738" aria-hidden="true" tabindex="-1"></a>We end up rejecting the null hypothesis $H_0:\boldsymbol\mu = \zer$ less than the null hypothesis $H_0:\mu_2 = 0$, as the Wald test also must incorporate evidence about $\mu_1$ in the form of $\bar X_1$. A large value of $\bar X_2$ (which is sufficient to reject $H_0:\mu_2 = 0$ with the $t-$test), is only one part of the story for the Wald test, as it also must consider $\bar X_1$. That being said, $\bar X_2$ is usually *so large* that the Wald test will still reject $H_0:\boldsymbol\mu = \zer$ even if $\bar X_1$ is not large enough for the $t-$test to reject $H_0:\mu_1= 0$. To see this, we can breakdown the simulated probabilities that we reject $H_0:\mu_1= 0$ and/or $H_0:\mu_2 = 0$.  </span>
<span id="cb49-1739"><a href="#cb49-1739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1742"><a href="#cb49-1742" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1743"><a href="#cb49-1743" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1744"><a href="#cb49-1744" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-1745"><a href="#cb49-1745" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-1746"><a href="#cb49-1746" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-1747"><a href="#cb49-1747" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "The QQ-plot for the simulated distribution of the adjusted sample mean"</span></span>
<span id="cb49-1748"><a href="#cb49-1748" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-1749"><a href="#cb49-1749" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb49-1750"><a href="#cb49-1750" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(test <span class="sc">==</span> <span class="st">"t-test"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1751"><a href="#cb49-1751" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(</span>
<span id="cb49-1752"><a href="#cb49-1752" aria-hidden="true" tabindex="-1"></a>    parameter,</span>
<span id="cb49-1753"><a href="#cb49-1753" aria-hidden="true" tabindex="-1"></a>    decision,</span>
<span id="cb49-1754"><a href="#cb49-1754" aria-hidden="true" tabindex="-1"></a>    iter_num</span>
<span id="cb49-1755"><a href="#cb49-1755" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1756"><a href="#cb49-1756" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(iter_num) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1757"><a href="#cb49-1757" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> parameter, <span class="at">values_from =</span> decision) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1758"><a href="#cb49-1758" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb49-1759"><a href="#cb49-1759" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_count</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb49-1760"><a href="#cb49-1760" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(θ1, θ2) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1761"><a href="#cb49-1761" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob =</span> <span class="fu">n</span>()<span class="sc">/</span><span class="fu">max</span>(n)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1762"><a href="#cb49-1762" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(θ1) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1763"><a href="#cb49-1763" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> θ2, <span class="at">values_from =</span> prob) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1764"><a href="#cb49-1764" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(</span>
<span id="cb49-1765"><a href="#cb49-1765" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at"> </span><span class="st">`</span> <span class="ot">=</span> <span class="dv">1</span>,</span>
<span id="cb49-1766"><a href="#cb49-1766" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">Fail to Reject θ2 = 0</span><span class="st">`</span> <span class="ot">=</span> <span class="dv">2</span>,</span>
<span id="cb49-1767"><a href="#cb49-1767" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">Reject θ2 = 0</span><span class="st">`</span> <span class="ot">=</span> <span class="dv">3</span></span>
<span id="cb49-1768"><a href="#cb49-1768" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1769"><a href="#cb49-1769" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb49-1770"><a href="#cb49-1770" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at"> </span><span class="st">`</span> <span class="ot">=</span> <span class="fu">ifelse</span>(<span class="st">`</span><span class="at"> </span><span class="st">`</span>, <span class="st">"Reject θ1 = 0"</span>, <span class="st">"Fail to Reject θ1 = 0"</span>)</span>
<span id="cb49-1771"><a href="#cb49-1771" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1772"><a href="#cb49-1772" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span>
<span id="cb49-1773"><a href="#cb49-1773" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1774"><a href="#cb49-1774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1775"><a href="#cb49-1775" aria-hidden="true" tabindex="-1"></a>We reject $H_0:\mu_1= 0$ and $H_0:\mu_2 = 0$ (simultaneously) with an approximate probability of $0.047$, far less than that calculated using the Wald test. Why does this happen? For our example, we reject $H_0:\boldsymbol\mu = \zer$ if $W \ge (\chi_2^2)^{-1}(1-0.05) \approx 6$. We reject $H_0:\mu_1 = 0$ if $|t_1| \ge  1.98$ and $H_0:\mu_2 = 0$ if $|t_2| \ge  1.98$. In terms of $\bar X$, we reject $H_0:\mu_1 = 0$ if $$\abs{\bar X_1} \ge 0 + 1.98\cdot\widehat{\text{se}}(\bar X_1) \approx 1.98\cdot\text{se}(\bar X_1) = 1.98\cdot(1/\sqrt{ 100}) = 0.198,$$ and we reject $H_0:\mu_2 = 0$ if $$\abs{\bar X_2} \ge 0 + 1.98\cdot\widehat{\text{se}}(\bar X_2) \approx 1.98\cdot\text{se}(\bar X_1) = 1.98\cdot(2/\sqrt{ 100}) \approx 0.28.$$ Because the Wald statistic is a function of $\bar X_1$ and $\bar X_2$, we can plot the values of $W$ over values of $<span class="sc">\{</span>\bar X_1,\bar X_2<span class="sc">\}</span>$ and compare this value to the rejection regions of the $t-$tests.</span>
<span id="cb49-1776"><a href="#cb49-1776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1777"><a href="#cb49-1777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1780"><a href="#cb49-1780" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1781"><a href="#cb49-1781" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1782"><a href="#cb49-1782" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-1783"><a href="#cb49-1783" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot318</span></span>
<span id="cb49-1784"><a href="#cb49-1784" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-1785"><a href="#cb49-1785" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-1786"><a href="#cb49-1786" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "The values of the Wald test statistic in relation to the decisions seperate t-tests make regarding the null hypotheses when considering each in one dimmension"</span></span>
<span id="cb49-1787"><a href="#cb49-1787" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-1788"><a href="#cb49-1788" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb49-1789"><a href="#cb49-1789" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span>.<span class="dv">40</span>, .<span class="dv">40</span>, <span class="at">length =</span> <span class="dv">500</span>),</span>
<span id="cb49-1790"><a href="#cb49-1790" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">seq</span>(<span class="sc">-</span>.<span class="dv">40</span>, .<span class="dv">40</span>, <span class="at">length =</span> <span class="dv">500</span>)</span>
<span id="cb49-1791"><a href="#cb49-1791" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1792"><a href="#cb49-1792" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb49-1793"><a href="#cb49-1793" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map2_vec</span>(x, y, \(x, y) <span class="fu">Wald_test</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">h =</span> h, <span class="at">n =</span> <span class="dv">100</span>, <span class="at">theta_hat =</span> <span class="fu">c</span>(x, y), <span class="at">V_hat =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">2</span>)))</span>
<span id="cb49-1794"><a href="#cb49-1794" aria-hidden="true" tabindex="-1"></a>  )  <span class="sc">%&gt;%</span> </span>
<span id="cb49-1795"><a href="#cb49-1795" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x, y, <span class="at">fill =</span> statistic)) <span class="sc">+</span></span>
<span id="cb49-1796"><a href="#cb49-1796" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>() <span class="sc">+</span></span>
<span id="cb49-1797"><a href="#cb49-1797" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_gradient2</span>(<span class="at">low =</span> <span class="st">"red"</span>, <span class="at">mid =</span> <span class="st">"white"</span>, <span class="at">high =</span> <span class="st">"green"</span>, <span class="at">midpoint =</span> <span class="fl">5.991465</span>) <span class="sc">+</span></span>
<span id="cb49-1798"><a href="#cb49-1798" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Estimate of μ1"</span>, <span class="at">y =</span> <span class="st">"Estimate of μ2"</span>, <span class="at">fill =</span> <span class="st">"Wald Statistic"</span>) <span class="sc">+</span></span>
<span id="cb49-1799"><a href="#cb49-1799" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb49-1800"><a href="#cb49-1800" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">198</span>,.<span class="dv">198</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb49-1801"><a href="#cb49-1801" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span>(<span class="fu">sqrt</span>(<span class="dv">2</span>)<span class="sc">/</span><span class="dv">10</span>)<span class="sc">*</span><span class="fl">1.98</span>,(<span class="fu">sqrt</span>(<span class="dv">2</span>)<span class="sc">/</span><span class="dv">10</span>)<span class="sc">*</span><span class="fl">1.98</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb49-1802"><a href="#cb49-1802" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>) <span class="sc">+</span></span>
<span id="cb49-1803"><a href="#cb49-1803" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">label =</span> <span class="st">"Don't Reject μ1 = 0, Don't Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb49-1804"><a href="#cb49-1804" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="sc">-</span>.<span class="dv">3</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Don't Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb49-1805"><a href="#cb49-1805" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> .<span class="dv">3</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Don't Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb49-1806"><a href="#cb49-1806" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> .<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Don't Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb49-1807"><a href="#cb49-1807" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> <span class="sc">-</span>.<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Don't Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb49-1808"><a href="#cb49-1808" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="sc">-</span>.<span class="dv">3</span>, <span class="at">y =</span> <span class="sc">-</span>.<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb49-1809"><a href="#cb49-1809" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> .<span class="dv">3</span>, <span class="at">y =</span> .<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb49-1810"><a href="#cb49-1810" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="sc">-</span>.<span class="dv">3</span>, <span class="at">y =</span> .<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb49-1811"><a href="#cb49-1811" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> .<span class="dv">3</span>, <span class="at">y =</span> <span class="sc">-</span>.<span class="dv">35</span>, <span class="at">label =</span> <span class="st">"Reject μ1 = 0, Reject μ2 = 0"</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb49-1812"><a href="#cb49-1812" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> (<span class="sc">-</span><span class="dv">4</span><span class="sc">:</span><span class="dv">4</span>)<span class="sc">/</span><span class="dv">10</span>, <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb49-1813"><a href="#cb49-1813" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> (<span class="sc">-</span><span class="dv">4</span><span class="sc">:</span><span class="dv">4</span>)<span class="sc">/</span><span class="dv">10</span>, <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb49-1814"><a href="#cb49-1814" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1815"><a href="#cb49-1815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1816"><a href="#cb49-1816" aria-hidden="true" tabindex="-1"></a>This illustrates that it's possible to reject $H_0:\boldsymbol\mu = \zer$ using the Wald test while not rejecting $H_0:\mu_1 = 0$ or not rejecting $H_1:\mu_1 = 0$. On the other hand, if we reject $H_0:\mu_1 = 0$ and $H_1:\mu_1 = 0$ using separate $t-$tests, we are guaranteed to reject $H_0:\boldsymbol\mu = \zer$ using the Wald test. This plot omits an important consideration -- the true distribution of $<span class="sc">\{</span>\bar X_1,\bar X_2<span class="sc">\}</span>$ which will determine how frequently our estimates fall in the various rejection regions. </span>
<span id="cb49-1817"><a href="#cb49-1817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1820"><a href="#cb49-1820" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1821"><a href="#cb49-1821" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1822"><a href="#cb49-1822" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-plot319</span></span>
<span id="cb49-1823"><a href="#cb49-1823" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb49-1824"><a href="#cb49-1824" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-asp: 0.7</span></span>
<span id="cb49-1825"><a href="#cb49-1825" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-1826"><a href="#cb49-1826" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "The joint density of the sample means"</span></span>
<span id="cb49-1827"><a href="#cb49-1827" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Show code which generates figure"</span></span>
<span id="cb49-1828"><a href="#cb49-1828" aria-hidden="true" tabindex="-1"></a><span class="fu">expand_grid</span>(</span>
<span id="cb49-1829"><a href="#cb49-1829" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span>.<span class="dv">35</span>, .<span class="dv">35</span>, <span class="at">length =</span> <span class="dv">500</span>),</span>
<span id="cb49-1830"><a href="#cb49-1830" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">seq</span>(<span class="sc">-</span>.<span class="dv">40</span>, <span class="dv">1</span>, <span class="at">length =</span> <span class="dv">500</span>)</span>
<span id="cb49-1831"><a href="#cb49-1831" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1832"><a href="#cb49-1832" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb49-1833"><a href="#cb49-1833" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map2_vec</span>(x, y, \(x, y) <span class="fu">Wald_test</span>(<span class="at">alpha =</span> <span class="fl">0.05</span>, <span class="at">h =</span> h, <span class="at">n =</span> <span class="dv">100</span>, <span class="at">theta_hat =</span> <span class="fu">c</span>(x, y), <span class="at">V_hat =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">2</span>))),</span>
<span id="cb49-1834"><a href="#cb49-1834" aria-hidden="true" tabindex="-1"></a>    <span class="at">density =</span> <span class="fu">map2_dbl</span>(x, y, \(x, y) <span class="fu">dmvnorm</span>(<span class="fu">c</span>(x,y), <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), <span class="fu">sqrt</span>(<span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">ncol =</span> <span class="dv">2</span>))<span class="sc">/</span><span class="dv">10</span>)),</span>
<span id="cb49-1835"><a href="#cb49-1835" aria-hidden="true" tabindex="-1"></a>    <span class="at">decision =</span> <span class="fu">ifelse</span>(decision, <span class="st">"Wald Test Rejects μ = 0"</span>, <span class="st">"Wald Test Fails to Reject μ = 0"</span>)</span>
<span id="cb49-1836"><a href="#cb49-1836" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1837"><a href="#cb49-1837" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x, y, <span class="at">fill =</span> density)) <span class="sc">+</span></span>
<span id="cb49-1838"><a href="#cb49-1838" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>() <span class="sc">+</span></span>
<span id="cb49-1839"><a href="#cb49-1839" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Estimate of μ1"</span>, <span class="at">y =</span> <span class="st">"Estimate of μ2"</span>, <span class="at">fill =</span> <span class="st">"Density"</span>) <span class="sc">+</span></span>
<span id="cb49-1840"><a href="#cb49-1840" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb49-1841"><a href="#cb49-1841" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">198</span>,.<span class="dv">198</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb49-1842"><a href="#cb49-1842" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span>(<span class="fu">sqrt</span>(<span class="dv">2</span>)<span class="sc">/</span><span class="dv">10</span>)<span class="sc">*</span><span class="fl">1.98</span>,(<span class="fu">sqrt</span>(<span class="dv">2</span>)<span class="sc">/</span><span class="dv">10</span>)<span class="sc">*</span><span class="fl">1.98</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb49-1843"><a href="#cb49-1843" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>, <span class="at">panel.spacing.x =</span> <span class="fu">unit</span>(<span class="dv">2</span>, <span class="st">"lines"</span>)) <span class="sc">+</span></span>
<span id="cb49-1844"><a href="#cb49-1844" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_gradient</span>(<span class="at">low =</span> <span class="st">"white"</span>, <span class="at">high =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb49-1845"><a href="#cb49-1845" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>decision) <span class="sc">+</span></span>
<span id="cb49-1846"><a href="#cb49-1846" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> (<span class="sc">-</span><span class="dv">4</span><span class="sc">:</span><span class="dv">10</span>)<span class="sc">/</span><span class="dv">5</span>, <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb49-1847"><a href="#cb49-1847" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> (<span class="sc">-</span><span class="dv">35</span><span class="sc">:</span><span class="dv">35</span>)<span class="sc">/</span><span class="dv">4</span>, <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb49-1848"><a href="#cb49-1848" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1849"><a href="#cb49-1849" aria-hidden="true" tabindex="-1"></a>The majority of the density is concentrated in a region where the Wald test rejects $H_0:\boldsymbol\mu = \zer$, the $t-$test does not reject $H_0:\mu_1 = 0$, and the $t-$test rejects $H_0:\mu_2 = 0$. This is why our Wald test rejected $H_0:\boldsymbol\mu = \zer$ so often, despite $\mu_1 = 0$ being true. Finally, note that we've assumed $\cov{X_1,X_2} = 0$. In the event that $\cov{X_1,X_2} \neq 0$, things become even more interesting, as the Wald test considers this covariance, whereas the $t-$tests do not. If you play around with this example by changing $\boldsymbol\Sigma =\var{\X}$, the elliptical rejection region of the Wald test will rotate/shrink/expand, thereby affecting how its results relate to those of the separate $t-$tests.</span>
<span id="cb49-1850"><a href="#cb49-1850" aria-hidden="true" tabindex="-1"></a>:::</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>